<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom"><generator uri="https://gohugo.io/" version="0.90.0">Hugo</generator><title type="html">Startwords</title><link href="https://startwords.cdh.princeton.edu/" rel="alternate" type="text/html" title="HTML"/><link href="https://startwords.cdh.princeton.edu/index.xml" rel="alternate" type="application/rss+xml" title="RSS"/><link href="https://startwords.cdh.princeton.edu/atom.xml" rel="self" type="application/atom+xml" title="Atom"/><updated>2022-02-07T18:56:27+00:00</updated><rights>This work is licensed under a Creative Commons Attribution 4.0 International License.</rights><author><name>Center for Digital Humanities at Princeton</name><email>cdh-info@princeton.edu</email></author><id>https://startwords.cdh.princeton.edu/</id><entry><title type="html">Creating and Recreating Virtual Community on Douglass Day</title><link href="https://startwords.cdh.princeton.edu/issues/2/creating-and-recreating-virtual-community/?utm_source=atom_feed" rel="alternate" type="text/html"/><id>https://startwords.cdh.princeton.edu/issues/2/creating-and-recreating-virtual-community/</id><author><name>Justin Smith</name></author><author><name>Courtney Murray</name></author><author><name>Jim Casey</name></author><published>2021-12-01T00:00:00+00:00</published><updated>2022-02-07T13:54:19-05:00</updated><content type="html"><![CDATA[<blockquote class="twitter-tweet"><p lang="en" dir="ltr">Save the Date for Douglass Day 2022!<br><br>Help us find the names of Black women in the Colored Conventions. Where did they go?<br><br>Registration is now open. Sign up for updates &amp; more!  <a href="https://t.co/nbxI9l1lGT">https://t.co/nbxI9l1lGT</a> <a href="https://t.co/5bz5fRQVLR">pic.twitter.com/5bz5fRQVLR</a></p>&mdash; Douglass Day (@DouglassDayorg) <a href="https://twitter.com/DouglassDayorg/status/1446478999287439372?ref_src=twsrc%5Etfw">October 8, 2021</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

<div class="tweet-group print-only-preview">
<a href="https://twitter.com/DouglassDayorg/status/1446478999287439372"><img loading="lazy" src="images/tweet1.png" alt="screenshot of tweet from Douglass Day"></a>
</div>
<div class="txt-only">
<pre><code>Save the Date for Douglass Day 2022!

Help us find the names of Black women in the Colored Conventions. Where did they go?

Registration is now open. Sign up for updates &amp; more! https://t.co/nbxI9l1lGT pic.twitter.com/5bz5fRQVLR
— Douglass Day (@DouglassDayorg) October 8, 2021
</code></pre>

</div>
<h2 id="douglass-days-annual-celebrations-before-the-pandemic">Douglass Day’s annual celebrations before the pandemic</h2>
<p>In 2017 we began to hold an event celebrating Frederick Douglass’s chosen birthday of February 14. Our event invites people to help transcribe digitized collections of African American history and culture, and to host transcribe-a-thon parties with their friends, classmates, or colleagues. Thousands have participated over the years.<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup></p>
<p>Each year, we listen to the melodies of “Lift Every Voice and Sing” and eat birthday cake. Our livestreamed broadcast and social media posts go out to thousands. We share photos on Twitter and Instagram of libraries, community centers, and churches where people transcribe shoulder to shoulder. At our local events, we enjoy seeing strangers chat about what they found or learned. Our events expand who gets to help preserve and commemorate Black history.</p>
<p>We started this event from scratch in 2017. By the time we held our events at Howard University in 2020, we felt like we’d attained some momentum with our team members at the University of Delaware, Princeton’s Center for Digital Humanities, and the Center for Black Digital Research at Pennsylvania State University.<sup id="fnref:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup></p>

<div class="video-embed-wrapper">
    
  
<div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
  <iframe src="https://www.youtube.com/embed/-SpanvQZhVI" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" allowfullscreen title="Douglass Day 2020 - Highlights"></iframe>
</div>


    <figure class="preview">
        
            <img loading="lazy" src="https://i.ytimg.com/vi/-SpanvQZhVI/hqdefault.jpg" alt="still image from video"/>
        
        <figcaption><p>The online version of this essay contains an embedded video, represented here by a still frame.</p></figcaption>
    </figure>
</div>

<div class="txt-only">
⩩&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;⟩
| VIDEO. Embedded video of highlights from Douglass Day 2020. <a href="https://www.youtube.com/watch?v=-SpanvQZhVI">https://www.youtube.com/watch?v=-SpanvQZhVI</a>
⩩&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;⟩
</div>
<h2 id="adjusting-during-the-covid-19-pandemic">Adjusting During the COVID-19 Pandemic</h2>
<p>Then the COVID-19 pandemic arrived. We had lessons for building community from years past. Yet even though we had been livestreaming and tweeting since 2017, we had few models for building a virtual, distanced community. We spent months of difficult planning to adapt our previous model into a virtual format.</p>
<p>Crucially, we connected with Lauren Algee and Carlyn Osborn at <em><a href="https://crowd.loc.gov/">By the People</a></em>—a Library of Congress project—to feature their campaign transcribing the papers of Mary Church Terrell, a groundbreaking Black feminist educator, activist, intellectual, and writer.</p>
<p>In the end, we managed to hold an event in February 2021 that retained the best parts of our past celebrations through lots of perseverance and creativity.</p>
<p>This snippet serves as a reflection on that transition. We’re sharing our hard-won lessons to help any others who might face similar challenges while hosting virtual and accessible events that foster ethical communities.</p>
<h2 id="redefining-our-digital-connections">Redefining our (digital) connections</h2>
<p>One of our principles is to create communal spaces that engage Black communities in remembering Black history.<sup id="fnref:3"><a href="#fn:3" class="footnote-ref" role="doc-noteref">3</a></sup> As we struggled with the constraints of pandemic isolation, we saw opportunity in our collective digital shifts. Could we use this opportunity to reimagine how we connect with our diverse audiences, spread the word about our events, and adapt our previous community engagements?</p>
<p>This process of rethinking our outreach transformed our use of online communications (social media, newsletter, and tutorial videos). We found new ways to connect with our audiences using tools in novel ways.</p>
<h2 id="transforming-outreach">Transforming Outreach</h2>
<p>Launching our social media campaign early on helped attract attention to the event and prepare our audiences for the redesigned event. We also created new hashtags, such as our <a href="https://twitter.com/search?q=%23GreatDouglassDayBakeoff&amp;src=typed_query">#GreatDouglassDayBakeoff</a>.</p>
<hr>
<p><blockquote class="twitter-tweet"><p lang="en" dir="ltr">Picked <a href="https://twitter.com/joythebaker?ref_src=twsrc%5Etfw">@joythebaker</a> ‘s excellent chocolate-peanut butter pretzel layer cake for <a href="https://twitter.com/hashtag/TheGreatDouglassDayBakeOff?src=hash&amp;ref_src=twsrc%5Etfw">#TheGreatDouglassDayBakeOff</a> <a href="https://twitter.com/hashtag/DouglassDay?src=hash&amp;ref_src=twsrc%5Etfw">#DouglassDay</a> <a href="https://twitter.com/CCP_org?ref_src=twsrc%5Etfw">@CCP_org</a> <a href="https://twitter.com/DouglassDayorg?ref_src=twsrc%5Etfw">@DouglassDayorg</a> <a href="https://twitter.com/DigBlk?ref_src=twsrc%5Etfw">@DigBlk</a> <a href="https://t.co/lElhFccO1f">pic.twitter.com/lElhFccO1f</a></p>&mdash; Anna Lacy (@Anna_E_Lacy) <a href="https://twitter.com/Anna_E_Lacy/status/1360301729451962376?ref_src=twsrc%5Etfw">February 12, 2021</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

<blockquote class="twitter-tweet"><p lang="en" dir="ltr">Here’s our family’s little <a href="https://twitter.com/hashtag/DouglassDay?src=hash&amp;ref_src=twsrc%5Etfw">#DouglassDay</a> cake (and art project). <a href="https://t.co/azzJnIReHv">pic.twitter.com/azzJnIReHv</a></p>&mdash; Dr. Brigitte Fielder (@BrigField) <a href="https://twitter.com/BrigField/status/1360976957337456641?ref_src=twsrc%5Etfw">February 14, 2021</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

<blockquote class="twitter-tweet"><p lang="en" dir="ltr"><a href="https://twitter.com/hashtag/DouglassDay?src=hash&amp;ref_src=twsrc%5Etfw">#DouglassDay</a> bakeoff! This flourless  chocolate wave cake by <a href="https://twitter.com/clairesaffitz?ref_src=twsrc%5Etfw">@clairesaffitz</a> pairs really well with a good book like <a href="https://twitter.com/AlisonMParker1?ref_src=twsrc%5Etfw">@alisonmparker1</a>’s <a href="https://twitter.com/hashtag/MaryChurchTerrell?src=hash&amp;ref_src=twsrc%5Etfw">#MaryChurchTerrell</a> bio UNCEASING MILITANT. <a href="https://t.co/02RCvBZQ9n">pic.twitter.com/02RCvBZQ9n</a></p>&mdash; Debbie Gershenowitz (@DGershenowitz) <a href="https://twitter.com/DGershenowitz/status/1361014486589706249?ref_src=twsrc%5Etfw">February 14, 2021</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

<blockquote class="twitter-tweet"><p lang="en" dir="ltr"><a href="https://twitter.com/hashtag/DouglassDay?src=hash&amp;ref_src=twsrc%5Etfw">#DouglassDay</a> <a href="https://twitter.com/hashtag/GreatDouglassDayBakeoff?src=hash&amp;ref_src=twsrc%5Etfw">#GreatDouglassDayBakeoff</a> got a little carried away this year <a href="https://t.co/inppgsFemp">pic.twitter.com/inppgsFemp</a></p>&mdash; Hannah Alpert-Abrams 🤖✊🔮 (@hralperta) <a href="https://twitter.com/hralperta/status/1361039589914382344?ref_src=twsrc%5Etfw">February 14, 2021</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

<blockquote class="twitter-tweet"><p lang="en" dir="ltr">“Power concedes nothing without a demand.” Happy <a href="https://twitter.com/hashtag/DouglassDay?src=hash&amp;ref_src=twsrc%5Etfw">#DouglassDay</a>! <a href="https://twitter.com/CCP_org?ref_src=twsrc%5Etfw">@CCP_org</a> <a href="https://twitter.com/librarycongress?ref_src=twsrc%5Etfw">@librarycongress</a> “If there is no struggle, there is no freedom.” -FD <a href="https://t.co/EM9CtUxDwq">pic.twitter.com/EM9CtUxDwq</a></p>&mdash; Pierce Stanley (@piercestanley) <a href="https://twitter.com/piercestanley/status/1361042468469432321?ref_src=twsrc%5Etfw">February 14, 2021</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
</p>
<div class="tweet-group print-only-preview">
<a href="https://twitter.com/Anna_E_Lacy/status/1360301729451962376"><img loading="lazy" src="images/tweetA1.png" alt="screenshot of tweet from Anna Lacy"></a>
<a href="https://twitter.com/BrigField/status/1360976957337456641"><img loading="lazy" src="images/tweetA2.png" alt="screenshot of tweet from Dr. Brigitte Fielder"></a>
<a href="https://twitter.com/DGershenowitz/status/1361014486589706249"><img loading="lazy" src="images/tweetA3.png" alt="screenshot of tweet from Debbie Gershenowitz"></a>
<a href="https://twitter.com/hralperta/status/1361039589914382344"><img loading="lazy" src="images/tweetA4.png" alt="screenshot of tweet from Hannah Alpert-Abrams"></a>
<a href="https://twitter.com/piercestanley/status/1361042468469432321"><img loading="lazy" src="images/tweetA5.png" alt="screenshot of tweet from Pierce Stanley"></a>
</div>
<div class="txt-only">
<pre><code>Picked @joythebaker ‘s excellent chocolate-peanut butter pretzel layer cake for #TheGreatDouglassDayBakeOff #DouglassDay @CCP_org @DouglassDayorg @DigBlk pic.twitter.com/lElhFccO1f
— Anna Lacy (@Anna_E_Lacy) February 12, 2021

Here’s our family’s little #DouglassDay cake (and art project). pic.twitter.com/azzJnIReHv
— Dr. Brigitte Fielder (@BrigField) February 14, 2021

#DouglassDay bakeoff! This flourless chocolate wave cake by @clairesaffitz pairs really well with a good book like @alisonmparker1’s #MaryChurchTerrell bio UNCEASING MILITANT. pic.twitter.com/02RCvBZQ9n
— Debbie Gershenowitz (@DGershenowitz) February 14, 2021

#DouglassDay #GreatDouglassDayBakeoff got a little carried away this year pic.twitter.com/inppgsFemp
— Hannah Alpert-Abrams 🤖✊🔮 (@hralperta) February 14, 2021

“Power concedes nothing without a demand.” Happy #DouglassDay! @CCP_org @librarycongress “If there is no struggle, there is no freedom.” -FD pic.twitter.com/EM9CtUxDwq
— Pierce Stanley (@piercestanley) February 14, 2021
</code></pre>

</div>
<hr>
<p>Amid the pandemic, we recognized that not all of our participants used social media so we expanded our newsletter. Our response rate was higher than on social media. We sent out regular reminders and resources, including a consistent timeline, visual aesthetic, and recurring thematic framing.</p>
<p>Our newsletters provide links to resources on our website and YouTube page.<sup id="fnref:4"><a href="#fn:4" class="footnote-ref" role="doc-noteref">4</a></sup> While we made tutorial videos before the pandemic, we expanded them to reinforce our event’s virtual presence. We added a video for FAQs to anticipate the questions that we might otherwise answer quickly in-person.</p>
<p>Below is a tutorial video with instructions about how to transcribe and review documents using the <em>By the People</em> platform.</p>

<div class="video-embed-wrapper">
    
    
<div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
  <iframe src="https://www.youtube.com/embed/1yXr9w_rZQw" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" allowfullscreen title="What is transcription? What is reviewing?"></iframe>
</div>


    <figure class="preview">
        
            <img loading="lazy" src="https://i.ytimg.com/vi/1yXr9w_rZQw/hqdefault.jpg" alt="still image from video"/>
        
        <figcaption><p>The online version of this essay contains an embedded video, represented here by a still frame.</p></figcaption>
    </figure>
</div>

<div class="txt-only">
⩩&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;⟩
| VIDEO. An embedded video tutorial for transcribing and reviewing documents <a href="https://www.youtube.com/watch?v=1yXr9w_rZQw">https://www.youtube.com/watch?v=1yXr9w_rZQw</a>
⩩&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;⟩
</div>
<p><blockquote class="twitter-tweet"><p lang="en" dir="ltr"><a href="https://twitter.com/hashtag/DouglassDay?src=hash&amp;ref_src=twsrc%5Etfw">#DouglassDay</a>. I am transcribing Terrell&#39;s introduction to Phillis Wheatley as part of her fundraising effort to build a campsite for Black girls. Love to see familiar names coming across in her writing. <a href="https://t.co/YX5tL2qmDP">pic.twitter.com/YX5tL2qmDP</a></p>&mdash; Jewon Woo 우제원 (@ClevelandKimchi) <a href="https://twitter.com/ClevelandKimchi/status/1360291342245638144?ref_src=twsrc%5Etfw">February 12, 2021</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

<blockquote class="twitter-tweet"><p lang="en" dir="ltr">Delighted that I got to transcribe some praise for Mary Church Terrell&#39;s work on behalf of Black students for <a href="https://twitter.com/hashtag/DouglassDay?src=hash&amp;ref_src=twsrc%5Etfw">#DouglassDay</a> <a href="https://t.co/Nx9Q1pK4M4">pic.twitter.com/Nx9Q1pK4M4</a></p>&mdash; Dr. Brigitte Fielder (@BrigField) <a href="https://twitter.com/BrigField/status/1360300654254825476?ref_src=twsrc%5Etfw">February 12, 2021</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

<blockquote class="twitter-tweet"><p lang="en" dir="ltr">Helping transcribe the papers of Mary Church Terrell for the <a href="https://twitter.com/hashtag/DouglassDay?src=hash&amp;ref_src=twsrc%5Etfw">#DouglassDay</a> Transcribe-A-Thon with other folks from <a href="https://twitter.com/FIULibraries?ref_src=twsrc%5Etfw">@FIULibraries</a> / <a href="https://twitter.com/FIU_Digital_Lib?ref_src=twsrc%5Etfw">@FIU_Digital_Lib</a> <a href="https://t.co/Jl0w61avP3">pic.twitter.com/Jl0w61avP3</a></p>&mdash; Dan Royles🗽 (@danroyles) <a href="https://twitter.com/danroyles/status/1360287523004706821?ref_src=twsrc%5Etfw">February 12, 2021</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

<blockquote class="twitter-tweet"><p lang="en" dir="ltr">I celebrated <a href="https://twitter.com/hashtag/DouglassDay?src=hash&amp;ref_src=twsrc%5Etfw">#DouglassDay</a> by transcribing this very sweet acrostic poem written about Mary Church Terrell by Revered Walter H. Brooks &lt; 3 <a href="https://twitter.com/DouglassDayorg?ref_src=twsrc%5Etfw">@DouglassDayorg</a> <a href="https://t.co/GOmygO2gLX">pic.twitter.com/GOmygO2gLX</a></p>&mdash; Dr. Kristin Moriah is on Academic Leave (@DarkStars__) <a href="https://twitter.com/DarkStars__/status/1361075881662443526?ref_src=twsrc%5Etfw">February 14, 2021</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

<blockquote class="twitter-tweet"><p lang="en" dir="ltr">A joy to be participating in <a href="https://twitter.com/hashtag/DouglassDay?src=hash&amp;ref_src=twsrc%5Etfw">#DouglassDay</a> today with <a href="https://twitter.com/DouglassDayorg?ref_src=twsrc%5Etfw">@DouglassDayorg</a> <a href="https://twitter.com/DigBlk?ref_src=twsrc%5Etfw">@DigBlk</a> and <a href="https://twitter.com/ihr_asu?ref_src=twsrc%5Etfw">@ihr_asu</a> — Here is a screenshot of the work I&#39;m transcribing from Mary Church Terrell&#39;s papers about the Textbook Controversy. My favorite line is highlighted. <a href="https://twitter.com/hashtag/digitalhumanities?src=hash&amp;ref_src=twsrc%5Etfw">#digitalhumanities</a> <a href="https://twitter.com/hashtag/ASUhumanities?src=hash&amp;ref_src=twsrc%5Etfw">#ASUhumanities</a> <a href="https://t.co/aOTwT1CH8z">pic.twitter.com/aOTwT1CH8z</a></p>&mdash; celina.osuna (@celina_osuna_) <a href="https://twitter.com/celina_osuna_/status/1360300366256955392?ref_src=twsrc%5Etfw">February 12, 2021</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
</p>
<div class="tweet-group print-only-preview">
<a href="https://twitter.com/ClevelandKimchi/status/1360291342245638144"><img loading="lazy"  src="images/tweetB1.png" alt="screenshot of tweet from Jewon Woo 우제원"></a>
<a href="https://twitter.com/BrigField/status/1360300654254825476"><img loading="lazy"  src="images/tweetB2.png" alt="screenshot of tweet from Dr. Brigitte Fielder"></a>
<a href="https://twitter.com/danroyles/status/1360287523004706821"><img loading="lazy"  src="images/tweetB3.png" alt="screenshot of tweet from Dan Royles"></a>
<a href="https://twitter.com/DarkStars__/status/1361075881662443526"><img loading="lazy"  src="images/tweetB4.png" alt="screenshot of tweet from Dr. Kristin Moriah"></a>
<a href="https://twitter.com/celina_osuna_/status/1360300366256955392"><img loading="lazy"  src="images/tweetB5.png" alt="screenshot of tweet from celina.osuna"></a>
</div>
<div class="txt-only">
<pre><code>#DouglassDay. I am transcribing Terrell's introduction to Phillis Wheatley as part of her fundraising effort to build a campsite for Black girls. Love to see familiar names coming across in her writing. pic.twitter.com/YX5tL2qmDP
— Jewon Woo 우제원 (@ClevelandKimchi) February 12, 2021

Delighted that I got to transcribe some praise for Mary Church Terrell's work on behalf of Black students for #DouglassDay pic.twitter.com/Nx9Q1pK4M4
— Dr. Brigitte Fielder (@BrigField) February 12, 2021

Helping transcribe the papers of Mary Church Terrell for the #DouglassDay Transcribe-A-Thon with other folks from @FIULibraries / @FIU_Digital_Lib pic.twitter.com/Jl0w61avP3
— Dan Royles🗽 (@danroyles) February 12, 2021

I celebrated #DouglassDay by transcribing this very sweet acrostic poem written about Mary Church Terrell by Revered Walter H. Brooks &lt; 3 @DouglassDayorg pic.twitter.com/GOmygO2gLX
— Dr. Kristin Moriah (@DarkStars__) February 14, 2021

A joy to be participating in #DouglassDay today with @DouglassDayorg @DigBlk and @ihr_asu — Here is a screenshot of the work I'm transcribing from Mary Church Terrell's papers about the Textbook Controversy. My favorite line is highlighted. #digitalhumanities #ASUhumanities pic.twitter.com/aOTwT1CH8z
— celina.osuna (@celina_osuna_) February 12, 2021
</code></pre>

</div>
<div class="force-page-break">
<h2 id="our-results">Our Results</h2>
<p>Making Douglass Day more accessible resulted in our largest Douglass Day audience ever. We had over 7,000 attendees, including K–12 teachers, students, professors, librarians, local organizers, graduate students, community groups, historic Black sororities, civic groups, and individual participants. It would not have been possible if we had not integrated the needs of our communities into our process of creating a virtual community. We will take these lessons to our future celebrations to expand the hybrid possibilities for developing our communities around these digital projects.
</div>
<hr>
<blockquote class="twitter-tweet"><p lang="en" dir="ltr">One week of <a href="https://twitter.com/hashtag/DouglassDay?src=hash&amp;ref_src=twsrc%5Etfw">#DouglassDay</a> 2021 celebrations down: <br><br>How it started             How it’s going <a href="https://t.co/QiVBzriEu6">pic.twitter.com/QiVBzriEu6</a></p>&mdash; Douglass Day (@DouglassDayorg) <a href="https://twitter.com/DouglassDayorg/status/1362815605502541828?ref_src=twsrc%5Etfw">February 19, 2021</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

<div class="tweet-group print-only-preview">
<a href="https://twitter.com/DouglassDayorg/status/1362815605502541828"><img src="images/tweetC1.png" alt="screenshot of tweet from Douglass Day"></a>
</div>
<div class="txt-only">
<pre><code>One week of #DouglassDay 2021 celebrations down:

How it started How it’s going pic.twitter.com/QiVBzriEu6
— Douglass Day (@DouglassDayorg) February 19, 2021
</code></pre>

</div>
<section class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1" role="doc-endnote">
<p>For more about the history of these Douglass Day celebrations, see <a href="https://douglassday.org/history-of-douglass-day/">https://douglassday.org/history-of-douglass-day/</a>.&#160;<a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:2" role="doc-endnote">
<p>The Douglass Day team is listed at <a href="https://douglassday.org/about/">https://douglassday.org/about/</a>.&#160;<a href="#fnref:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:3" role="doc-endnote">
<p>Our collective principles are online at <a href="https://douglassday.org/about/principles/">https://douglassday.org/about/principles/</a>.&#160;<a href="#fnref:3" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:4" role="doc-endnote">
<p>Our newsletters are available at <a href="https://us4.campaign-archive.com/home/?u=1d63c6a6816200ef6e1e4991b&amp;id=e8791087d3">https://us4.campaign-archive.com/home/?u=1d63c6a6816200ef6e1e4991b&amp;id=e8791087d3</a>.&#160;<a href="#fnref:4" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</section>
]]></content></entry><entry><title type="html">Data's Destinations: Three Case Studies in Crowdsourced Transcription Data Management and Dissemination</title><link href="https://startwords.cdh.princeton.edu/issues/2/datas-destinations/?utm_source=atom_feed" rel="alternate" type="text/html"/><id>https://startwords.cdh.princeton.edu/issues/2/datas-destinations/</id><author><name>Victoria Anne Van Hyning</name></author><author><name>Mason A. Jones</name></author><published>2021-12-01T00:00:00+00:00</published><updated>2022-02-07T13:54:19-05:00</updated><content type="html"><![CDATA[<h2 id="introduction">Introduction</h2>
<p>Online crowdsourcing—a series of methods for engaging volunteers with STEM, humanities, and cultural heritage research—has rapidly matured between 2000 and 2021. These efforts have been led by research groups and platform designers like <a href="https://www.zooniverse.org/">Zooniverse</a>, platform designers like <a href="https://fromthepage.com/">FromThePage</a>, <a href="https://omeka.org/">Omeka</a>, <a href="https://pybossa.com/">PYBOSSA </a>and <a href="https://scripto.org/">Scripto</a>, and cultural heritage institutions like the <a href="https://www.archives.gov/">National Archives and Records Administration</a> (NARA) and <a href="https://www.si.edu/">Smithsonian Institution</a>. Volunteers help researchers, journalists, conservationists, cultural heritage practitioners, and one another to gather data that contributes to real research, original art, policy, community health, and more. In this essay, we will focus on cultural heritage crowdsourcing, and transcription projects in particular. Typically, these projects invite volunteers to transcribe handwritten or printed materials produced with ornate type or typewriter documents that—due to slight irregularities of the type, faint ink, or use of thin papers like onion skin—are not amenable to handwritten text recognition (HTR) or optical character recognition (OCR).</p>
<p>
<div class="video-embed-wrapper">
    
<figure>
  <video autoplay loop muted playsinline>
    <source src="images/ShaxW_Step4_Transcribe.webm" type="video/webm">
    <source src="images/ShaxW_Step4_Transcribe.mp4" type="video/mp4">
  </video>
  <figcaption>
  <p>Example of the transcription process in one crowdsourced cultural heritage project. A user transcribes an early modern letter. <span class="attribution"><a href="https://www.zooniverse.org/projects/zooniverse/shakespeares-world">Shakespeare’s World</a></span>
  </p>
  </figcaption>
</figure>

    <figure class="preview">
        
            <img loading="lazy" src="images/datas-destinations-social.png" alt="still image from video"/>
        
        <figcaption><p>The online version of this essay contains an embedded video, represented here by a still frame.</p></figcaption>
    </figure>
</div>

<div class="txt-only">
#&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;
| FIGURE.  Screen recording of a user transcribing an early modern letter as part of the Shakespeare&rsquo;s World project.
|
| CAPTION: Example of the transcription process in one crowdsourced cultural heritage project. A user transcribes an early modern letter.
| ATTRIBUTION: Shakespeare&rsquo;s World
| LINK: <a href="https://www.zooniverse.org/projects/zooniverse/shakespeares-world">https://www.zooniverse.org/projects/zooniverse/shakespeares-world</a>
#&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;
</div></p>
<p>Crowdsourced transcription projects generally fall into one of two categories: those that are structured around a particular research problem or question, and those that gather data to enhance search and discovery of materials for open-ended and ongoing purposes. Whereas many researchers want to extract particular pieces of information from datasets, such as water salinity and temperature from old ships logs to feed data into climate change models (<a href="https://www.oldweather.org/"><em>Old Weather</em></a>), most cultural heritage crowdsourcing projects gather transcriptions of entire documents to support as-yet-unstipulated research purposes. Their goal is to create pathways for discovery in one or more content management systems (CMS), the catalogs and/or other platforms that make metadata and images of original materials discoverable.</p>
<p>Transcriptions that reproduce the text on the page (as opposed to select pieces of data) have a variety of applications across numerous disciplines, and also have the power to solve two common challenges for researchers and the librarians and archivists who support them: 1) transcriptions speed up discovery, and 2) transcriptions can (if presented properly online) increase accessibility for those who cannot read the original handwriting, including those who are Blind or cognitively impaired and use a screen reader. Before we delve into a few case studies of organizations that have used crowdsourcing methods to generate text transcriptions for these purposes, we want to emphasize that while researchers and archivists alike want to foster discovery and accessibility, the barriers to achieving these goals through crowdsourcing are complex and not yet widely discussed.</p>

<blockquote class="pull left">
    it’s not right to invite people to help researchers and increase accessibility … if the resulting data aren’t made widely available
</blockquote>
<p>The number of galleries, libraries, archives, and museums (GLAM) institutions that have successfully integrated their crowdsourced transcription data into their core CMSs is far outweighed by those that have not yet found a workable solution, and many who have found solutions have used workarounds that are a stop-gap until better alternatives emerge. For example, a common workaround is to publish bulk data in an online repository on GitHub or a university library or research repository, while GLAM practitioners try to determine how to integrate data into their core CMS. Lucinda Blaser of Royal Museums Greenwich identified the absence of appropriate metadata fields in her institution’s CMS as a major barrier to integrating the <em>Old Weather</em> transcriptions.<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup> She and her colleagues were eager to use the data, but the metadata field they hoped to use had a character limit set by the vendor. Anne Bowser et al. expose the absence of norms and ongoing funding for data integration across citizen science crowdsourcing domains more broadly (including transcription projects), and highlight the ethical problems of not releasing crowdsourced data. They aver, and we agree, that it’s not right to invite people to “help researchers,” “increase accessibility,” and achieve other goals if the resulting data aren’t made widely available, as well as understandable—meaning that the methods of collection are well described.<sup id="fnref:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup></p>
<p>Ina-Maria Jansson and Chern Li Liew explore anxieties about crowdsourcing data quality among GLAM practitioners as well as members of the public, some of whom are anxious about whether crowdsourced data deserves a place in the authoritative record.<sup id="fnref:3"><a href="#fn:3" class="footnote-ref" role="doc-noteref">3</a></sup> Jansson and Liew’s findings are particularly disturbing, because they reveal that many institutions are actively engaged in crowdsourcing but still deeply uncomfortable with their own stated aims. These institutions are thus unlikely to hold up their end of the bargain with volunteers—namely making the data that volunteers produce available for research and enabling access. More work is needed to address concerns about data quality. Current approaches include:</p>
<ol>
<li>overcoming barriers to data publication and integration when people can see examples from peer institutions or trusted sources, they are likely to be reassured;</li>
<li>data quality analysis studies that provide solid information about the transcription outcomes from different projects, and</li>
<li>real talk about the quality of other data that is already in the authoritative record. For example, Victoria Van Hyning and her teammates at the Library of Congress (LOC) frequently pointed out to colleagues that the Library already publishes low-quality OCR in the authoritative record (often provided by vendors as part of their digitization package), and that crowdsourced transcriptions are typically of a much higher quality than this OCR.</li>
</ol>
<p>If we can all more openly discuss and address these challenges and ways of meeting them, we will make better progress in supporting collections discovery and use, research, and novel applications of crowdsourced data.</p>

<blockquote class="pull right">
    data management planning is a necessary part of crowdsourcing
</blockquote>
<p>Crowdsourcing platform designers Ben and Sara Brumfield are also drawing attention to these issues as they affect scholarly editors and cultural heritage practitioners, and are working on some new solutions to data unification, publication, and discovery. In a recorded talk to the International Interoperable Image Framework (IIIF) conference in 2021, they demonstrate how content from digital scholarly editions can move between multiple systems like Fedora or ContentDM to FromThePage, where the images are transcribed by volunteers and/or an editorial team, and then back to a scholarly editing platform such as Omeka-S, all with the help of IIIF-compliant metadata and images. They discuss how scholarly edition materials might then feed back into the original CMS via the same IIIF metadata, in order to enhance the materials and increase discovery on the host institution’s CMS. They conclude their piece by announcing work on a new feature that will “allow editors to export stand-alone web-pages for minimal computing needs and digital preservation” in cases where there isn’t an institutional CMS amenable to this kind of roundtripping of the data.<sup id="fnref:4"><a href="#fn:4" class="footnote-ref" role="doc-noteref">4</a></sup></p>
<h3 id="case-studies">Case Studies</h3>
<p>The remainder of this essay offers three case studies of projects that showcase different successes and challenges in crowdsourced transcription data integration. Our early-stage research reveals that the challenges facing these projects are more widely shared by a range of crowdsourcing stakeholders, including platform designers, academics, cultural heritage practitioners and the vendors who create CMSs for cultural heritage organizations. Van Hyning was directly involved in each project. These case studies include <a href="https://www.zooniverse.org/projects/zooniverse/shakespeares-world"><em>Shakespeare’s World</em></a> (SW), which launched on the Zooniverse platform in 2015 and was sunset in 2019. It was a partnership between Zooniverse, the Folger Shakespeare Library and the <em>Oxford English Dictionary</em> (OED). The <a href="https://crowd.loc.gov/"><em>By the People</em></a> project (BTP) was launched by the Library of Congress (LOC) on a bespoke platform called <a href="https://github.com/LibraryOfCongress/concordia">Concordia</a> in 2018, and the <em>David C. Driskell Papers Project</em> was created by Van Hyning, six MLIS students, and their colleagues at the <a href="https://driskellcenter.umd.edu/">David C. Driskell Center</a> at the University of Maryland on the FromThePage platform in 2020, and launched in 2021. All of these were produced by multidisciplinary teams involving cultural heritage practitioners such as archivists, metadata specialists, curators, and academics from STEM and/or humanities backgrounds. Some projects involved students, while others involved formal project managers, web developers and database engineers (system designers). The projects were built on three different crowdsourcing platforms, all of which are separate “pass-through” applications that are not directly connected to the relevant cultural heritage institution’s CMS. The datasets in each case require some dedicated effort to move the content out of the crowdsourcing platform and into the CMS to appear alongside the digital images of the original documents, and thus make them searchable down to the page level.</p>
<h2 id="shakespeares-world"><em>Shakespeare’s World</em></h2>
<p>In this case study we’ll outline some successes of <em>SW</em> before coming on to the challenges of data aggregation that arose on the Zooniverse side, and the data integration challenges that arose on the Folger side. The quality of the research and engagement outcomes are significant, and bring home the ways in which the <em>SW</em> team’s struggles with data wrangling curtailed our overall rate of discovery. However, the data challenges the team encountered, and the enormous efforts that collaborators have spent to address these (including major updates to the Zooniverse platform and the development of numerous codebases and processes to clean the data) are important research activities and outcomes in their own right.</p>
<p>The goals of <em>Shakespeare’s World</em> (<em>SW</em>) were to:</p>
<ol>
<li>Engage a broad volunteer base to transcribe digitized Folger manuscripts from the sixteenth and seventeenth centuries, to make the manuscript contents amenable to full-text search;</li>
<li>Engage early modern literature and history scholars, especially those with strengths in women’s history, history of science, food, and medicine, with crowdsourcing as a means to help them identify new materials for their research;</li>
<li>Identify previously unrecorded words, variants, and older usages of words for the <em>Oxford English Dictionary</em> (<em>OED</em>), and</li>
<li>Try out new approaches to transcription on the Zooniverse platform.</li>
</ol>
<p>The project achieved these goals to varying degrees. It exceeded our expectations in terms of engagement, particularly regarding how volunteers engaged with researchers and the <em>OED</em> team. Thousands of volunteers transcribed, discussed, and conducted research about early modern manuscripts, history, language, and culture, thereby gaining or enhancing research and paleographical skills they might not otherwise have had the opportunity to develop. Together with volunteers, the team helped advance the research agendas of six scholars, resulting in a half dozen publications that cite the contributions of volunteers. The team also encountered unexpected challenges relating to the data outputs of the project, which in turn led to new avenues of research at Zooniverse from 2016 to the time of writing, as well as a long-running effort to make the <em>SW</em> data usable.</p>
<p>





















<figure ><img loading="lazy" alt="Volunteer transcription of an early modern creame cheese recipe." src="/issues/2/datas-destinations/images/Aggregated%20Data-ShaxWorld.png"
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset="/issues/2/datas-destinations/images/Aggregated%20Data-ShaxWorld_hue63b1972d48a1ce608a915f2767de879_1804370_500x0_resize_box_3.png 500w,
    /issues/2/datas-destinations/images/Aggregated%20Data-ShaxWorld_hue63b1972d48a1ce608a915f2767de879_1804370_800x0_resize_box_3.png 800w,/issues/2/datas-destinations/images/Aggregated%20Data-ShaxWorld_hue63b1972d48a1ce608a915f2767de879_1804370_1200x0_resize_box_3.png 1200w,/issues/2/datas-destinations/images/Aggregated%20Data-ShaxWorld_hue63b1972d48a1ce608a915f2767de879_1804370_1500x0_resize_box_3.png 1500w,/issues/2/datas-destinations/images/Aggregated%20Data-ShaxWorld.png 1535w" 
     class="landscape"
     ><figcaption>
        <p>Volunteer transcription of an early modern creame cheese recipe.<span class="attribution"><a href="https://www.zooniverse.org/projects/zooniverse/shakespeares-world">Shakespeare&rsquo;s World</a></span>
        </p>
    </figcaption>
</figure>
<div class="txt-only">
#&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;
| FIGURE.  To make a Creame Cheese: Take .8. quarts of new milke from the cowe, and put to it .2. quarts of creame that is sweet, &amp;; some .3. or .4. spoonfulls of runnett if it be quicke, if it be milde you maye put in 9. or .10. spoonfulls, and cor it it with a double cloathe, if the weather be colde more, and when it is harde come take it up as carefullye as you can with a floing dishe, (that you doe not breake the curde) and put it in a cloathe laide on the chse fatt, when halfe the curde is in crosse the corners of the
|
| CAPTION: Volunteer transcription of an early modern creame cheese recipe.
| ATTRIBUTION: Shakespeare&rsquo;s World
| LINK: <a href="https://www.zooniverse.org/projects/zooniverse/shakespeares-world">https://www.zooniverse.org/projects/zooniverse/shakespeares-world</a>
#&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;
</div></p>
<h3 id="engagement-successes-volunteers-scholars-and-the-oed">Engagement Successes: Volunteers, Scholars, and the <em>OED</em></h3>
<p><em>Shakespeare’s World</em> attracted 3,926 registered volunteers, as well as anonymous participants (numbers unknown), who transcribed 11,490 digital images of manuscript pages (single and double page spreads) over a period of nearly four years (2015-2019). These included letters, recipes, and newsletters, an early form of manuscript newspaper delivery service that was curated for particular recipients.</p>

<blockquote class="pull left">
    major updates to the Zooniverse platform and the development of numerous codebases and processes to clean the data are important research activities and outcomes in their own right.
</blockquote>
<p>Volunteers identified several words that were not previously included in the <em>OED</em>, as well as a ninety-year antedating of “partner” in the sense of spouse or lover, and a nearly two-hundred-year antedating of “white lie.” The <em>Shakespeare’s World</em> Talk board (a discussion forum for the project) was a vital space for what guest researcher Lisa Smith described as a form of collective close reading (close reading is a widely used form of literary analysis typically conducted by solo researchers).<sup id="fnref:5"><a href="#fn:5" class="footnote-ref" role="doc-noteref">5</a></sup> To take just one example of collective close reading and research from <em>SW</em> Talk, the team present the case of “taffytie tartes.”<sup id="fnref:6"><a href="#fn:6" class="footnote-ref" role="doc-noteref">6</a></sup> This phrase was identified by volunteer @kodemunkey just eight days into the project. Lively discussion as to its exact meaning blossomed on Talk, as volunteers, early modern recipe researchers including Smith, Folger and Zooniverse staff, as well as <em>OED</em> Deputy Editor Philip Durkin shared evidence from the <em>OED</em>, other <em>SW</em> recipes, and their own research.<sup id="fnref:7"><a href="#fn:7" class="footnote-ref" role="doc-noteref">7</a></sup> Durkin described our community process in a blog post, offering etymological starting points for the meaning of Taffytie (linking it to taffeta fabric), and a reflection on the value of our endeavor. He wrote:</p>
<blockquote>
<p>The sources featured in Shakespeare’s World are particularly interesting and valuable for OED lexicographers. We have relatively easy access to a good deal of printed material from this period, now increasingly searchable in electronic collections. It is much harder for OED’s lexicographers to survey patterns of use in manuscript sources from this period, which often differ in interesting ways from printed sources—this can be in small features like spelling (as for instance taffytie), as well as in reflecting aspects of life (such as culinary recipes) that are relatively under-represented in the printed sources, or only appear there in a rather different light. This project therefore offers a new way in to some material that has previously been underexploited in tracing the history of English.<sup id="fnref:8"><a href="#fn:8" class="footnote-ref" role="doc-noteref">8</a></sup></p>
</blockquote>
<p>In order for “taffytie tartes” to be included in the <em>OED</em> the editorial team needed additional evidence, and in particular dated evidence, which can be harder to derive from manuscript sources like recipe books that created for everyday practical use in family homes for ongoing use. Volunteers kept up their search on <em>Shakespeare’s World</em> and a few years later Van Hyning expanded the hunt for additional sources by reaching out to Mary-Anne Boermans, a finalist on the <em>Great British Bake Off</em> Season 2. Van Hyning was intrigued by Boermans’s historically informed baking practice, and had a hunch that Boermans might have come across taffety tartes in her research, and whether she’d be interested in the recipes from Folger.<sup id="fnref:9"><a href="#fn:9" class="footnote-ref" role="doc-noteref">9</a></sup> Boermans <em>had</em> come across several recipes and had already included one in her first cookbook <em>Great British Bakes: Forgotten Treasures for Modern Bakers</em> (2013), but, as she wrote in a blog post for the Folger in 2019, many of the recipes she’d found were missing crucial information as to what made a Taffety Tart a Taffety Tart. The presence of thirteen recipes at the Wellcome confirmed that taffety tarts “were very much a ‘thing’ in seventeenth-century food fashion. Trying to define what exactly this ‘thing’ was, however, was more complicated than I first imagined.” The Folger examples provide crucial missing evidence about the fillings, pastry type, shape, bake time, temperature and decorative features:</p>
<blockquote>
<p>It is almost a ‘complete package’ in terms of the details supplied, needing only to have been dated and include a drawing of the pastry shape in order to complete the picture. It might not be the jigsaw box cover image, but it’s definitely the four corner pieces of the puzzle, because it reveals that what this Jacobean pastry most resembles, with its thin, rectangular shape, fruit filling and icing is… a pop-tart. A seventeenth-century pop-tart.<sup id="fnref:10"><a href="#fn:10" class="footnote-ref" role="doc-noteref">10</a></sup></p>
</blockquote>
<p>Boermans kindly baked four different examples and shared images of her work:</p>
<p>





















<figure ><img loading="lazy" alt="Image of four taffytie tartes, a seventeenth-century dish baked by Mary-Anne Boermans." src="/issues/2/datas-destinations/images/taffety-tarts.jpg"
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset="/issues/2/datas-destinations/images/taffety-tarts_hu6165b8a72dc313e18147516d31c33329_1108777_500x0_resize_q75_box.jpg 500w,
    /issues/2/datas-destinations/images/taffety-tarts_hu6165b8a72dc313e18147516d31c33329_1108777_800x0_resize_q75_box.jpg 800w,/issues/2/datas-destinations/images/taffety-tarts_hu6165b8a72dc313e18147516d31c33329_1108777_1200x0_resize_q75_box.jpg 1200w,/issues/2/datas-destinations/images/taffety-tarts_hu6165b8a72dc313e18147516d31c33329_1108777_1500x0_resize_q75_box.jpg 1500w,/issues/2/datas-destinations/images/taffety-tarts.jpg 1728w" 
     class="landscape"
     >
</figure>
<div class="txt-only">
⩩&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;⟩
| FIGURE. Image of four taffytie tartes, a seventeenth-century dish baked by Mary-Anne Boermans.
|
| ATTRIBUTION: Mary-Anne Boermans
| LINK: <a href="https://shakespeareandbeyond.folger.edu/2019/03/26/taffety-tarts-folger-manuscript-recipes-17th-century-pastry-oxford-english-dictionary/">https://shakespeareandbeyond.folger.edu/2019/03/26/taffety-tarts-folger-manuscript-recipes-17th-century-pastry-oxford-english-dictionary/</a>
⩩&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;⟩
</div></p>
<p>Boermans also supplied dated manuscript evidence, which means that “Taffety” was added to the OED in 2018.<sup id="fnref:11"><a href="#fn:11" class="footnote-ref" role="doc-noteref">11</a></sup></p>
<h3 id="shakespeares-world-data-cleaning-and-release"><em>Shakespeare’s World</em> Data Cleaning and Release</h3>
<p><em>SW</em> was always meant to be fun and inclusive: a place where people could learn about subjects and people they might never have considered. The <em>SW</em> team very consciously emphasized that volunteers could take part in—and even lead—discovery and research impact through the <em>OED</em> partnership, and also tried to make the transcription task itself as accessible to beginners as possible. The team hypothesized that by letting people choose to transcribe as little as a word or line they would only contribute what they felt confident reading, and that, in keeping with the broader Zooniverse methods of promoting nonspecialist engagement and multiple independent classifications followed by aggregation, the project would make crowdsourced transcription accessible and welcoming in new ways. This proved true, based on the feedback via Talk and other venues, but unfortunately the complexities of transcription—the slight differences of interpretation from one user to another, stemming from genuine ambiguities present in most documents rather than user mistakes—combined with the imprecision of clustering closely written lines of text, rendered much of the output data very difficult to use.</p>
<p>Each word on each page was independently transcribed by three or more people, and their transcriptions were compared and combined using a clustering algorithm and a genetic sequencing algorithm.<sup id="fnref:12"><a href="#fn:12" class="footnote-ref" role="doc-noteref">12</a></sup> Our early aggregation testing was based on gold standard data produced by project staff at Folger, against which they compared transcriptions produced by Zooniverse staff, who included an early modernist with paleography expertise (Van Hyning) as well as folks without paleography training, including astronomers and developers, many of whom hold higher degrees in other fields including philosophy, ecology, and computer science. The project team also gathered transcription data from the pool of Zooniverse beta tester volunteers, a subset of the wider Zooniverse user community who test projects under development. Early aggregation results were promising, showing approximately 98 percent agreement between transcribers in many cases. But as the project went public and the heterogeneity of both the participants and the documents increased, clustering accuracy dipped, which negatively impacted text string comparison. In retrospect, it’s clear that our beta testing sample was too skewed towards people with higher degrees, relevant subject knowledge, and/or existing familiarity with the Zooniverse platform.</p>

<blockquote class="pull right">
    Thousands of volunteers transcribed, discussed, and conducted research about early modern manuscripts, history, language, and culture … [in] a form of collective close reading
</blockquote>
<p>From 2016 to 2018, the team made several attempts to improve aggregation for <em>SW</em> and the numerous transcription projects that also used similar methods of transcription (i.e. <em>AnnoTate</em> with Tate Britain, and <em>Decoding the Civil War</em> with the Huntington). The project had some success, but the overall results still require significant editing. For three years this was done by grant-funded staff at Folger. In 2021, <em>SW</em> Co-Investigators Heather Wolfe and Van Hyning worked with colleagues at Folger and the University of Maryland iSchool’s iConsultancy undergraduate capstone students on a <em>SW</em> data cleaning project.<sup id="fnref:13"><a href="#fn:13" class="footnote-ref" role="doc-noteref">13</a></sup> The students used the most recent iteration of aggregated data provided by Zooniverse, and focused on stripping out duplicate lines of text, which was one of the most common errors introduced by aggregation (this is based on visual inspection by former Folger palaeographer Sarah Powell, and <em>SW</em> Co-Is Wolfe and Van Hyning, rather than a full formal analysis of the data. Further quantitative analysis of different stages of <em>SW</em> data is planned for the future).</p>
<p>This level of intervention certainly allays any anxieties about quality control, and can be seen as the gold standard for cultural heritage practitioners wishing to present accurate and highly authoritative information to their patrons. However, this level of transformation and encoding is prohibitively labor intensive even without unexpected data-cleaning challenges. For this reason, since February 2019, Folger has started making plain text transcriptions available on their main discovery platform, a lightly customized off-the-shelf instance of Luna (<a href="luna.folger.edu">luna.folger.edu</a>). According to Folger metadata librarian Emily Whal, they added a transcription “‘Facet Search’ button on the collection home page [that] take[s] you to a list of the call numbers available in the collection.”<sup id="fnref:14"><a href="#fn:14" class="footnote-ref" role="doc-noteref">14</a></sup>  On Luna, <em>SW</em> transcriptions join approximately 19,000 transcriptions produced on Folger’s in-house transcription system called Dromio, which was developed over fifteen years ago by Folger developer Mike Poston for Wolfe’s palaeography classes. Dromio continues to support pedagogy, as well as transcribathon events. As of October 2021, 7,271 <em>SW</em> transcriptions have been edited into these three presentations, encoded with TEI P-4 markup and published for search and download on the <em>Early Modern Manuscripts Online</em> (EMMO) platform (emmo.folger.edu). <a href="https://luna.folger.edu/luna/servlet/FOLGER~3~3">Over 12,500 transcriptions have been incorporated into Luna</a>.<sup id="fnref:15"><a href="#fn:15" class="footnote-ref" role="doc-noteref">15</a></sup> To get to Luna, <em>SW</em> transcriptions that have been tidied up by the UMD students, but that haven’t gone through the <em>EMMO</em> treatment, are uploaded to the <a href="https://fromthepage.com/folger">FromThePage crowdsourcing platform</a> and edited by Folger docents, volunteers, and staff. In other words, the crowdsourced data are going through a further phase of crowdsourced editing. The <em>SW</em> transcriptions in Luna are not the same documents (yet) as those in <em>EMMO</em>.</p>

<blockquote class="pull left">
    Each word on each page was independently transcribed by three or more people, and their transcriptions were compared and combined using a clustering algorithm and a genetic sequencing algorithm.
</blockquote>
<p>Both the successes and the challenges of Zooniverse transcription approaches on <em>SW</em> and its sister project <em>AnnoTate</em> led to important developments for the platform. The first was a successful grant bid to the IMLS in 2016 to develop new approaches to text transcription, explicitly to test whether collaborative or independent methods were more accurate. This supported the development of <em>Scribes of the Cairo Geniza</em> and <em>Anti-Slavery Manuscripts</em>, and subsequent publications about data quality and volunteer engagement in independent versus collaborative methods of transcription.<sup id="fnref:16"><a href="#fn:16" class="footnote-ref" role="doc-noteref">16</a></sup> Additional grant-funded work led by Samantha Blickhan resulted in a new text aggregation editing tool called <a href="https://alice.zooniverse.org/">ALI/CE</a>.</p>
<h2 id="by-the-people"><em>By the People</em></h2>
<p>Our next case study is the Library of Congress (LOC) <em>By the People</em> (<em>BTP</em>) crowdsourced transcription project. <em>BTP</em> features materials from across the LOC’s Special Collections divisions (Manuscript, Rare Book, Folklife, and others). These are arranged into “Campaigns” and presented to volunteers along with transcription conventions, a discussion platform, and explanatory material to help folks learn a bit about the subjects of the documents. These range from the papers of Rosa Parks, to those of presidents Abraham Lincoln and Theodore Roosevelt, and ethnomusicologist Alan Lomax. Despite the heterogeneity of the documents that pass through the platform, and indeed the heterogeneity of metadata models within the LOC, the data outputs from the project are fairly easy to work with, and the rate of data publication has been fairly fast. <em>BTP</em> relies on volunteers being able to peer-review one another’s transcriptions. Pages can be transcribed and edited by multiple volunteers before being marked as “complete.” This review system enables collaboration between transcribers, and between transcribers and the LOC staff who support <em>BTP</em>.</p>
<p>Thanks to the foresight and advocacy of various stakeholders at the LOC, the project was well staffed and resourced from the outset and included provision for full-time community managers, a team of developers, user experience specialists, metadata specialists, and accessibility experts. The project&rsquo;s transition from a “pilot” effort funded through gift money, to “core infrastructure” funded through congressional appropriations, more than a year ahead of schedule, has been cited by Ben Brumfield of FromThePage as evidence for the “maturity of the [crowdsourcing transcription] methodology.”<sup id="fnref:17"><a href="#fn:17" class="footnote-ref" role="doc-noteref">17</a></sup></p>

<blockquote class="pull right">
    Although the project was built on a separate transcription platform, the expectation from the start was that the data should return to loc.gov
</blockquote>
<p>Part of the success of <em>BTP</em> stems from LOC staff’s ability to publish the transcriptions. Although the project was built on a separate transcription platform, the expectation from the start was that the data should return to loc.gov (the Library’s main web property and discovery system) early and often. Our first data round-trip occurred less than three months after launch, and consisted of 781 pages from across the five original campaigns.<sup id="fnref:18"><a href="#fn:18" class="footnote-ref" role="doc-noteref">18</a></sup> The <em>BTP</em> team and stakeholders worked together to identify a data pathway, including relevant metadata fields, on-screen presentation, appropriate language to describe and acknowledge volunteer efforts, and important internal questions about custodial responsibility for the data over time. The project team went into this process aware of the challenges, but also aware of possible workarounds and solutions. The incorporation of OCR into loc.gov was a helpful precedent, as was the fact loc.gov is a bespoke system maintained by a team of internal engineers and developers.</p>
<p>Though glad of this early success, the team quickly learned from users who consulted manuscripts online that it was confusing when some pages in a letter or journal were transcribed and others were not. The team thought it was best to publish any data when it became available, but user feedback revealed it was best to wait until full documents are done. So the team changed their approach from March 2019 onward, waiting until entire Campaigns of documents (i.e. the Branch Rickey papers or Rosa Parks’s papers) are completed, before the results are ingested into loc.gov.<sup id="fnref:19"><a href="#fn:19" class="footnote-ref" role="doc-noteref">19</a></sup></p>
<p>





















<figure ><img loading="lazy" alt="Screenshot from By the People transcription project, showing a manuscript page from the Mary Church Terrell Papers and a user&#39;s transcription of that document&#39;s text." src="/issues/2/datas-destinations/images/ByThePeople-PublishedTranscriptionPage.png"
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset="/issues/2/datas-destinations/images/ByThePeople-PublishedTranscriptionPage_hu85d7db1ee8495c5a3efa12fdac180d3d_351696_500x0_resize_box_3.png 500w,
    /issues/2/datas-destinations/images/ByThePeople-PublishedTranscriptionPage_hu85d7db1ee8495c5a3efa12fdac180d3d_351696_800x0_resize_box_3.png 800w,/issues/2/datas-destinations/images/ByThePeople-PublishedTranscriptionPage_hu85d7db1ee8495c5a3efa12fdac180d3d_351696_1200x0_resize_box_3.png 1200w,/issues/2/datas-destinations/images/ByThePeople-PublishedTranscriptionPage.png 1471w" 
     class="landscape"
     ><figcaption>
        <p>Screenshot of By the People, showing transcription of a document from the Mary Church Terrell Papers.<span class="attribution"><a href="https://www.loc.gov/resource/mss42549.mss42549-020_00197_00285/?sp=9&amp;st=text&amp;r=0.05,1.033,0.289,0.285,0">Library of Congress</a></span>
        </p>
    </figcaption>
</figure>
<div class="txt-only">
#&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;
| FIGURE.  Screenshot from By the People transcription project, showing a manuscript page from the Mary Church Terrell Papers and a user&rsquo;s transcription of that document&rsquo;s text.
|
| CAPTION: Screenshot of By the People, showing transcription of a document from the Mary Church Terrell Papers.
| ATTRIBUTION: Library of Congress
| LINK: <a href="https://www.loc.gov/resource/mss42549.mss42549-020_00197_00285/?sp=9&amp;st=text&amp;r=0.05,1.033,0.289,0.285,0">https://www.loc.gov/resource/mss42549.mss42549-020_00197_00285/?sp=9&amp;st=text&amp;r=0.05,1.033,0.289,0.285,0</a>
#&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;
</div></p>
<p>Of the over 620,000 documents made available on <em>BTP</em> since October 2018, roughly 392,000 pages have been transcribed, reviewed, and marked as complete by volunteers, and 63,400 have been incorporated into loc.gov. The data are published in two ways. First, <a href="https://www.loc.gov/search/?in=&amp;q=%22volunteers+participating+in+the+By%22&amp;new=true">the transcriptions</a> are embedded in the metadata for individual pages as well as full documents. They appear alongside the images of the original manuscripts, thus creating pathways to individual pages. These transcriptions can be downloaded as .txt files either one page at a time or as whole documents. An attribution to the volunteers appears in two places, first as an overlay in the on-screen display for each page, and embedded in the .txt transcription file itself: “Transcribed and reviewed by volunteers participating in the <em>By The People</em> project at crowd.loc.gov.” The second way that LOC makes the transcriptions available is as <a href="https://www.loc.gov/search/?fa=contributor:by+the+people+(program)">bulk datasets</a> consisting of a .CSV file and README file detailing the context in which the data were originally collected on <em>BTP</em>. Bulk datasets have different affordances from individual .txt files.</p>
<p>





















<figure ><img loading="lazy" alt="Screenshot of bulk dataset from Rosa Parks Papers in By the People project." src="/issues/2/datas-destinations/images/RosaParksBulkDataSnapshot.png"
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset="/issues/2/datas-destinations/images/RosaParksBulkDataSnapshot_hu7ee926be32ad5fcc3ec36618a6f153c6_120851_500x0_resize_box_3.png 500w,
    /issues/2/datas-destinations/images/RosaParksBulkDataSnapshot_hu7ee926be32ad5fcc3ec36618a6f153c6_120851_800x0_resize_box_3.png 800w,/issues/2/datas-destinations/images/RosaParksBulkDataSnapshot_hu7ee926be32ad5fcc3ec36618a6f153c6_120851_1200x0_resize_box_3.png 1200w,/issues/2/datas-destinations/images/RosaParksBulkDataSnapshot.png 1347w" 
     class="landscape"
     ><figcaption>
        <p>Screenshot of bulk dataset from Rosa Parks Papers in By the People project.<span class="attribution"><a href="https://crowd.loc.gov/">By the People (LOC)</a></span>
        </p>
    </figcaption>
</figure>
<div class="txt-only">
#&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;
| FIGURE.  Screenshot of bulk dataset from Rosa Parks Papers in By the People project.
|
| ATTRIBUTION: By the People (LOC)
| LINK: <a href="https://crowd.loc.gov/">https://crowd.loc.gov/</a>
#&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;
</div></p>
<h2 id="the-david-c-driskell-papers-project"><em>The David C. Driskell Papers Project</em></h2>
<p>Our final case study features a project devoted to the legacy of the late David C. Driskell, professor emeritus of art and art history at the University of Maryland. The University of Maryland’s <a href="https://driskellcenter.umd.edu/">David C. Driskell Center</a> (DCDC) is an art gallery, archive, and educational center founded with the central mission of celebrating Black artists and art history. It was founded by colleagues of Driskell after his retirement, as a mark of respect and admiration for his incredible contributions to art history, education, and artistic production. Driskell was an American artist and educator who was instrumental in establishing Black art as a scholarly field of study: he generated a significant correspondence with leading artists including Alan Porter and Georgia O’Keefe, as well as his students and mentees.</p>
<p>Professor Driskell died due to complications of Covid-19 on April 1, 2020. In order to celebrate and remember this fixture of both the University of Maryland and of the art community, Van Hyning collaborated with colleagues at the Driskell Center, and six MLIS students to create a crowdsourcing project on the From the Page platform featuring his archives, such as letters and journals. <a href="https://fromthepage.com/umdtranscription/david-c-driskell-papers"><em>The David C. Driskell Papers Project</em></a> (<em>DCDPP</em>) is hosted within the Driskell Center as an online crowdsourced transcription project hosted in the FromThePage platform. The transcription project exists alongside an exhibit of Driskell’s papers also hosted by the DCDC. While not immediately related, both the transcription project and the exhibition existed to celebrate the life of Driskell and invite the public to share in the memory of his life and legacy.</p>

<blockquote class="pull left">
    Driskell was an American artist and educator who was instrumental in establishing Black art as a scholarly field of study
</blockquote>
<p>The transcription project focuses predominantly on the written documents contained within the curated collection of personal papers. The team endeavored to make Driskell’s personal papers and the accompanying transcriptions easily accessible to best serve both an informational role and an accessibility role for researchers attempting to learn more about his life and the impact of his efforts to raise awareness of the quality, quantity, and vibrancy of Black art in America and abroad. The project launched in February 2021 with a corpus of over 1,200 documents, and additional materials have been uploaded since. Volunteers and some of the original project team have transcribed over 1,300 pages of documents and staff have begun work on indexing these transcriptions following review and OCR corrections.</p>
<p>





















<figure ><img loading="lazy" alt="Screenshot of a transcribed letter from the David C. Driskell Papers Project, using the From the Page platform." src="/issues/2/datas-destinations/images/DavidCDriskellPapersTranscriptionInterface.png"
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset="/issues/2/datas-destinations/images/DavidCDriskellPapersTranscriptionInterface_hue142e1a56949cb87843e39a7e7c1e236_744311_500x0_resize_box_3.png 500w,
    /issues/2/datas-destinations/images/DavidCDriskellPapersTranscriptionInterface_hue142e1a56949cb87843e39a7e7c1e236_744311_800x0_resize_box_3.png 800w,/issues/2/datas-destinations/images/DavidCDriskellPapersTranscriptionInterface_hue142e1a56949cb87843e39a7e7c1e236_744311_1200x0_resize_box_3.png 1200w,/issues/2/datas-destinations/images/DavidCDriskellPapersTranscriptionInterface.png 1208w" 
     class="landscape"
     ><figcaption>
        <p><span class="attribution"><a href="https://fromthepage.com/umdtranscription/david-c-driskell-papers/ms01-05-00-box-19-folder-05-jones-lois-mailou-correspondence-1969-2004/display/1560243">David C. Driskell Papers Project</a></span>
        </p>
    </figcaption>
</figure>
<div class="txt-only">
#&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;
| FIGURE.  Screenshot of a transcribed letter from the David C. Driskell Papers Project, using the From the Page platform.
|
| ATTRIBUTION: David C. Driskell Papers Project
| LINK: <a href="https://fromthepage.com/umdtranscription/david-c-driskell-papers/ms01-05-00-box-19-folder-05-jones-lois-mailou-correspondence-1969-2004/display/1560243">https://fromthepage.com/umdtranscription/david-c-driskell-papers/ms01-05-00-box-19-folder-05-jones-lois-mailou-correspondence-1969-2004/display/1560243</a>
#&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;
</div></p>
<p>But for all the ease of using FTP to produce usable transcription data for the digitized objects in the collection, there were known issues from the outset when it came to the storage and presentation of the transcription data on the DCDC’s existing CMS. The DCDC employs PastPerfect, a CMS that is typically used by museums and galleries to catalog and describe physical objects rather than archives. This software is designed with the stated intent to be used in all manner of cultural heritage institutions, not just galleries or museums. PastPerfect’s own website says that “over 11,000 museums, historical societies, archives, libraries, and other collecting institutions worldwide have purchased PastPerfect Museum Software since its first release in 1998”; however, the fundamental structure of PastPerfect is not ideal for archival metadata structures and arrangement.<sup id="fnref:20"><a href="#fn:20" class="footnote-ref" role="doc-noteref">20</a></sup> The system assumes that each record pertains to one physical item such as a painting or sculpture, for which a few photos will suffice, but an archival item might consist of hundreds of pages, and there might be numerous items in a given folder or box which are not described at the item much less the page level. The record structure isn’t granular enough. Furthermore, other than a notes field, there is no space within the PastPerfect CMS to represent transcription data. To use a notes field in this system, the DCDC archivist would have to manually upload each transcription, which is too labor intensive for this organization.</p>
<p>The project team knew about these issues prior to creating the <em>DCDPP</em> crowdsourced transcription project, as they are common in the GLAM community. Even highly specialized repositories tend to have a mixture of formats that most CMSs don’t quite cater to. The Zooniverse project <a href="https://anno.tate.org.uk/#/"><em>AnnoTate</em></a> (2015–2019), with Tate Archive, was designed to produce transcription data for a <a href="https://www.tate.org.uk/art/archive/collections">bespoke CMS</a> that unites object and archival records. They embarked on <em>DCDPP</em> in part to gain insights and data for our ongoing conversations about how best to serve the heterogeneous materials housed at the DCDC. Crowdsourcing projects, especially smaller scale pilot projects, can empower cultural heritage institutions to experiment with incorporating more diverse and nontraditional data into their CMSs, and hopefully also give them the data they need to advocate for their needs to vendors who supply those systems. While the larger questions of CMS type unfold, the team can publish the Driskell data in a number of venues, including the DCDC’s main website or the <a href="https://www.lib.umd.edu/dbfinder/id/UMD05542">Digital Repository of the University of Maryland</a> (DRUM).</p>
<h2 id="integrating-solutions-for-transcription-data">Integrating Solutions for Transcription Data</h2>
<p>Regardless of how crowdsourced data are managed and made available, data management planning is a necessary part of crowdsourcing, and conversations about how to achieve data publication or integration should start as early as possible. Solving these questions ahead of launch, and preparing for potential content management issues, can ensure that projects meet the institutional or individual’s vision more effectively. If you’re a GLAM practitioner using an off-the-shelf CMS, talk to your vendor. Find out if your license or product level includes a capacious enough field for transcriptions. Find out whether you can import content in bulk or whether you have to cut and paste transcriptions one at a time. Be up front with your volunteers about your ambitions for the data, as well as current limitations.</p>

<blockquote class="pull right">
    Archives typically arrange and describe materials at the level of items (the journal, the letter) or boxes (a collection of folders with letters from various correspondents) rather than pages, whereas transcriptions bring us right down to the page level.
</blockquote>
<p>As institutions such as the Folger have begun ingesting their data, we’ve learned more about the widespread challenges of ingesting long runs of text into CMSs—no matter how clean the data from crowdsourcing platforms are—whether these are off-the-shelf products or bespoke systems created by institutions. Sometimes metadata managers can shoehorn transcriptions into a field without a character count limit, but the status of the transcriptions within archival description is uncertain and still emerging. Archives typically arrange and describe materials at the level of items (the journal, the letter) or boxes (a collection of folders with letters from various correspondents) rather than pages, whereas transcriptions bring us right down to the page level. The technical fixes may be relatively simple, but there’s a much more significant shift that needs to happen at the level of archival practice and cultural norms.</p>
<p>Data publication can take a wide variety of forms in order to meet the varying demands for different projects and the visions of different institutions hosting a crowdsourced transcription project. There may not be a one-size-fits-all solution, especially when we consider that most institutions have quirky ways of describing rare materials in the first place—quirks that are shaped by the materials themselves, the many layers of metadata that accrue to objects over time, and the affordances and limitations of different CMSs. Whatever the quirks, though, crowdsourced data deserves a place in the authoritative record. Data can be posted in bulk as .CSV files on institutional webpages, GitHub, Internet Archive or other repositories, and/or in metadata fields that connect the transcription directly to the image in question. Data should also, ideally, be publicized and described in articles and blog posts where they may reach a wide range of potential users—the <a href="https://openhumanitiesdata.metajnl.com/"><em>Journal of Open Humanities Data</em></a> is one such venue (Van Hyning serves on the editorial board of the Journal, Jones as a copyeditor). Collaborators on the <em>Scribes of the Cairo Geniza</em> project do a blend of several of these approaches for the <a href="https://genizalab.princeton.edu/resources/datasets"><em>Scribes of the Cairo Geniza</em> data</a>. A stopgap to these solutions would be a simple note in a metadata field, a finding aid, and/or on an institution’s website saying that transcription data for a given page, document, or collection can be made available upon request. This would enable institutions to better meet the needs of Blind users or others who use screen reader technologies to access web-based written content. This would be a move towards 508 compliance, specifically making projects and their outputs more accessible to people who use screen readers.<sup id="fnref:21"><a href="#fn:21" class="footnote-ref" role="doc-noteref">21</a></sup> If organizations doing crowdsourced transcription have concrete plans for data storage and accessibility at the outset of the project, they will be in a stronger position to achieve Web Content Accessibility Guide (WCAG 2.0 or 2.1) compliance in the transcription data display.</p>
<h2 id="bibliography">Bibliography</h2>
<p>Blaser, Lucinda. &ldquo;Old weather: Approaching collections from a different angle.&rdquo; In <em>Crowdsourcing Our Cultural Heritage</em> edited by Mia Ridge, 45-56. Routledge: New York, 2014.</p>
<p>Blickhan, Samantha, Andrea Simenstad, Amy Boyer, Daniel Hanson, Coleman Krawczyk, and Victoria Van Hyning. “Individual vs. Collaborative Methods of Crowdsourced Transcription.” <em>Journal of Data Mining &amp; Digital Humanities</em> Special Issue on Collecting, Preserving, and Disseminating Endangered Cultural Heritage for New Understandings through Multilingual Approaches (December 3, 2019). <a href="https://jdmdh.episciences.org/5759/pdf">https://jdmdh.episciences.org/5759/pdf</a>.</p>
<p>Boermans, Mary-Anne. “Taffety Tarts: How a 17th-Century Pastry Made It into the OED.” Blog. Shakespeare &amp; Beyond, March 26, 2019. <a href="https://shakespeareandbeyond.folger.edu/2019/03/26/taffety-tarts-folger-manuscript-recipes-17th-century-pastry-oxford-english-dictionary/">https://shakespeareandbeyond.folger.edu/2019/03/26/taffety-tarts-folger-manuscript-recipes-17th-century-pastry-oxford-english-dictionary/</a>.</p>
<p>Bowser, Anne et al. “Still in Need of Norms: The State of the Data in Citizen Science.” <em>Citizen Science: Theory and Practice</em> 5, no. 1 (September 4, 2020): 18. <a href="https://doi.org/10.5334/cstp.303">https://doi.org/10.5334/cstp.303</a>.</p>
<p>Brumfield, Ben. “The Decade in Crowdsourcing Transcription” <em>From the Page</em> (blog). January 9, 2020. <a href="https://content.fromthepage.com/decade-in-crowdsourcing/">https://content.fromthepage.com/decade-in-crowdsourcing/</a>.</p>
<p>Brumfield, B., &amp; Brumfield, S. (August 30, 2021). More Than Round Trip: Using Transcription for Scholarly Editions and Library Discovery. <a href="https://content.fromthepage.com/using-transcription-for-scholarly-editions-and-library-discovery/">https://content.fromthepage.com/using-transcription-for-scholarly-editions-and-library-discovery/</a></p>
<p>Concordia Codebase, <a href="https://github.com/LibraryOfCongress/concordia">https://github.com/LibraryOfCongress/concordia</a></p>
<p>Durkin, P., 2017. <em>Release notes: a big antedating for white lie - and introducing Shakespeare’s world</em>. Oxford English Dictionary, 28 September 2017. Available at <a href="https://public.oed.com/blog/september-2017-update-release-notes-white-lie-and-shakespeares-world/">https://public.oed.com/blog/september-2017-update-release-notes-white-lie-and-shakespeares-world/</a> [Last accessed 30 June 2021].</p>
<p>Durkin, P., 2015. Our First Discovery! And a brief history of the Oxford English Dictionary. <em>Shakespeare’s World</em>. Available at <a href="https://blog.shakespearesworld.org/2015/12/17/our-first-discovery-and-a-brief-history-of-the-oxford-english-dictionary/">https://blog.shakespearesworld.org/2015/12/17/our-first-discovery-and-a-brief-history-of-the-oxford-english-dictionary/</a> [Last accessed 30 June 2021].</p>
<p>Jansson, Ina-Maria. “Organization of User-Generated Information in Image Collections and Impact of Rhetorical Mechanisms.” Knowledge Organization 44, no. 7 (September 30, 2017): 515–28.</p>
<p>Liew, Chern Li. “Social Metadata and Public-Contributed Contents in Memory Institutions: ‘Crowd Voice’ Versus ‘Authenticated Heritage’?” Preservation, Digital Technology &amp; Culture 45, no. 3 (October 1, 2016): 122–33. <a href="https://doi.org/10.1515/pdtc-2016-0017">https://doi.org/10.1515/pdtc-2016-0017</a>.</p>
<p>Oxford English Dictionary. “December 2018 Update: Taffety Tarts Enter the OED,” December 13, 2018. <a href="https://public.oed.com/blog/december-2018-update-taffety-tarts-enter-oed/">https://public.oed.com/blog/december-2018-update-taffety-tarts-enter-oed/</a>.</p>
<p>Van Hyning, Victoria. “Finding By the People Transcriptions in the Library’s Digital Collections,” <em>The Signal</em>,” July 9, 2020. <a href="https://blogs.loc.gov/thesignal/2020/07/finding-by-the-people-transcriptions-in-the-librarys-digital-collections/">https://blogs.loc.gov/thesignal/2020/07/finding-by-the-people-transcriptions-in-the-librarys-digital-collections/</a> .</p>
<p>Van Hyning, Victoria. “Harnessing Crowdsourcing for Scholarly and GLAM Purposes.” <em>Literature Compass</em> 16, no. 3–4 (2019): e12507. <a href="https://doi.org/10.1111/lic3.12507">https://doi.org/10.1111/lic3.12507</a>.</p>
<section class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1" role="doc-endnote">
<p>Lucinda Blaser, “Old Weather: Approaching Collections from a different angle,” in <em>Crowdsourcing Our Cultural Heritage</em>, ed. Mia Ridge (New York: Routledge, 2014), 45–56.&#160;<a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:2" role="doc-endnote">
<p>Anne Bowser et al., “Still in Need of Norms: The State of the Data in Citizen Science,” <em>Citizen Science: Theory and Practice</em> 5, no. 1 (September 4, 2020): 18, <a href="https://doi.org/10.5334/cstp.303">https://doi.org/10.5334/cstp.303</a>.&#160;<a href="#fnref:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:3" role="doc-endnote">
<p>Ina-Maria Jansson, “Organization of User-Generated Information in Image Collections and Impact of Rhetorical Mechanisms,” Knowledge Organization 44, no. 7 (September 30, 2017): 515–28, <a href="https://www.ergon-verlag.de/isko_ko/downloads/ko_44_2017_7_f.pdf;">https://www.ergon-verlag.de/isko_ko/downloads/ko_44_2017_7_f.pdf;</a> Chern Li Liew, “Social Metadata and Public-Contributed Contents in Memory Institutions: ‘Crowd Voice’ Versus ‘Authenticated Heritage’?” Preservation, Digital Technology &amp; Culture 45, no. 3 (October 1, 2016): 122–33, <a href="https://doi.org/10.1515/pdtc-2016-0017">https://doi.org/10.1515/pdtc-2016-0017</a>.&#160;<a href="#fnref:3" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:4" role="doc-endnote">
<p>Sara Carlstead Brumfield and Ben Brumfield, “More Than ‘Round Trip’: Using Transcription for Scholarly Editions and Library Discovery,” July 20, 2021, video, 2021 IIIF Conference, June 22, 2021, <a href="https://www.youtube.com/watch?v=mlYvbOX4K5g&amp;t=8s">https://www.youtube.com/watch?v=mlYvbOX4K5g&amp;t=8s</a>.&#160;<a href="#fnref:4" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:5" role="doc-endnote">
<p>Smith, Lisa. “On Close Reading and Teamwork.” <em>Shakespeare’s World</em> (blog), February 3, 2016. <a href="https://blog.shakespearesworld.org/2016/02/03/on-close-reading-and-teamwork/">https://blog.shakespearesworld.org/2016/02/03/on-close-reading-and-teamwork/</a>.&#160;<a href="#fnref:5" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:6" role="doc-endnote">
<p>Because there was no completely standardized spelling in English before the eighteenth century, multiple spellings of the word “taffytie tartes” appear in this paper as a reflection of the various ways the authors of the manuscripts referred to them. Manuscript spelling tended to be even more varied than print. For a brief history of English spelling and pronunciation see <em>Oxford English Dictionary</em>. “Early Modern English Pronunciation and Spelling,” August 16, 2012. <a href="https://public.oed.com/blog/early-modern-english-pronunciation-and-spelling/">https://public.oed.com/blog/early-modern-english-pronunciation-and-spelling/</a>.&#160;<a href="#fnref:6" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:7" role="doc-endnote">
<p>“Taffytie,” Shakespeare’s World Talk (forum), Zooniverse, <a href="https://www.zooniverse.org/projects/zooniverse/shakespeares-world/talk/search?query=taffytie">https://www.zooniverse.org/projects/zooniverse/shakespeares-world/talk/search?query=taffytie</a>.&#160;<a href="#fnref:7" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:8" role="doc-endnote">
<p>Philip Durkin, “Our First Discovery! And a brief history of the Oxford English Dictionary,” Shakespeare’s World (blog), Zooniverse, May 8, 2018, <a href="https://blog.shakespearesworld.org/2015/12/17/our-first-discovery-and-a-brief-history-of-the-oxford-english-dictionary/">https://blog.shakespearesworld.org/2015/12/17/our-first-discovery-and-a-brief-history-of-the-oxford-english-dictionary/</a>.&#160;<a href="#fnref:8" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:9" role="doc-endnote">
<p>Victoria Van Hyning, May 31, 2018, comment on Mary-Anne Boermans, “Me,” Time to Cook–Online (blog), <a href="https://timetocookonline.com/title/#comment-39337">https://timetocookonline.com/title/#comment-39337</a>.&#160;<a href="#fnref:9" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:10" role="doc-endnote">
<p>Mary-Anne Boermans, “Taffety Tarts: How a 17th-Century Pastry Made It into the OED,” <em>Shakespeare &amp; Beyond</em> (blog), Folger Shakespeare Library, March 26, 2019, <a href="https://shakespeareandbeyond.folger.edu/2019/03/26/taffety-tarts-folger-manuscript-recipes-17th-century-pastry-oxford-english-dictionary/">https://shakespeareandbeyond.folger.edu/2019/03/26/taffety-tarts-folger-manuscript-recipes-17th-century-pastry-oxford-english-dictionary/</a>.&#160;<a href="#fnref:10" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:11" role="doc-endnote">
<p>Philip Durkin, “December 2018 Update: Taffety Tarts Enter the OED,” <em>OED Blog</em>, December 13, 2018, <a href="https://public.oed.com/blog/december-2018-update-taffety-tarts-enter-oed/">https://public.oed.com/blog/december-2018-update-taffety-tarts-enter-oed/</a>.&#160;<a href="#fnref:11" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:12" role="doc-endnote">
<p>Victoria Van Hyning, “Harnessing Crowdsourcing for Scholarly and GLAM Purposes.” <em>Literature Compass</em> 16, no. 3–4 (2019): e12507, <a href="https://doi.org/10.1111/lic3.12507">https://doi.org/10.1111/lic3.12507</a>.&#160;<a href="#fnref:12" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:13" role="doc-endnote">
<p>That project is available at <a href="https://github.com/nisaputri/The-Shakespeares-UMD">https://github.com/nisaputri/The-Shakespeares-UMD</a>&#160;<a href="#fnref:13" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:14" role="doc-endnote">
<p>Emily Whal, email message to Van Hyning, October 14, 2021.&#160;<a href="#fnref:14" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:15" role="doc-endnote">
<p>Ibid.&#160;<a href="#fnref:15" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:16" role="doc-endnote">
<p>Samantha Blinkhan et al., “Individual vs. Collaborative Methods of Crowdsourced Transcription,” in “Collecting, Preserving, and Disseminating Endangered Cultural Heritage for New Understandings through Multilingual Approaches,” eds. Amel Fraisse, Ronald Jenn, and Shelley Fisher Fishkin, special issue, Journal of Data Mining and Digital Humanities (2019), <a href="https://doi.org/10.46298/jdmdh.5759">https://doi.org/10.46298/jdmdh.5759</a>.&#160;<a href="#fnref:16" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:17" role="doc-endnote">
<p>Ben Brumfield, “The Decade in Crowdsourcing Transcription,” FromThePage (blog), January 9, 2020, <a href="https://content.fromthepage.com/decade-in-crowdsourcing/">https://content.fromthepage.com/decade-in-crowdsourcing/</a>.&#160;<a href="#fnref:17" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:18" role="doc-endnote">
<p>Victoria Van Hyning, “Finding By the People Transcriptions in the Library’s Digital Collections,” The Signal (blog), Library of Congress, July 9, 2020. <a href="https://blogs.loc.gov/thesignal/2020/07/finding-by-the-people-transcriptions-in-the-librarys-digital-collections/">https://blogs.loc.gov/thesignal/2020/07/finding-by-the-people-transcriptions-in-the-librarys-digital-collections/</a>.&#160;<a href="#fnref:18" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:19" role="doc-endnote">
<p>Stats are updated monthly at <a href="https://crowd.loc.gov/about/">https://crowd.loc.gov/about/</a>.&#160;<a href="#fnref:19" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:20" role="doc-endnote">
<p>“PastPerfect Museum Software” PastPerfect Museum Software. 2021. <a href="https://museumsoftware.com/">https://museumsoftware.com/</a>.&#160;<a href="#fnref:20" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:21" role="doc-endnote">
<p>Section 508 of the Americans with Disabilities Act “establishes requirements for electronic and information technology developed, maintained, procured, or used by the Federal government. Section 508 requires Federal electronic and information technology to be accessible to people with disabilities, including employees and members of the public.” - <a href="https://www.ada.gov/cguide.htm">https://www.ada.gov/cguide.htm</a>&#160;<a href="#fnref:21" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</section>
]]></content></entry><entry><title type="html">Serendipity in the Cairo Geniza</title><link href="https://startwords.cdh.princeton.edu/issues/2/serendipity-in-the-cairo-geniza/?utm_source=atom_feed" rel="alternate" type="text/html"/><id>https://startwords.cdh.princeton.edu/issues/2/serendipity-in-the-cairo-geniza/</id><author><name>Matthew Dudley</name></author><author><name>Steffy Reader</name></author><published>2021-12-01T00:00:00+00:00</published><updated>2022-02-07T13:54:19-05:00</updated><content type="html"><![CDATA[<p>Matthew Dudley is a PhD candidate at Yale University where he is completing a dissertation on the early modern Cairo Geniza of the sixteenth through nineteenth centuries. Steffy Reader, a retired psychotherapist, has contributed to the <em>Scribes of the Cairo Geniza</em> and a number of other Zooniverse projects since 2018. In the clip below, they meet for the first time during the conference <em>Crowdsourcing and the Humanities</em> and discover that they had already been collaborating anonymously via the <em>Scribes of the Cairo Geniza</em> site. What follows is a dialogue between them about this moment and the results of their serendipitous collaboration in analyzing communal register fragments from the late eighteenth and early nineteenth centuries.</p>

<div class="video-embed-wrapper">
    
<script src="https://cdnapisec.kaltura.com/p/1449362/sp/144936200/embedIframeJs/uiconf_id/14292362/partner_id/1449362"></script>
<div id="kaltura_player_1621444219" class="kaltura" defer></div>
<script>
kWidget.embed({
  "targetId": "kaltura_player_1621444219",
  "wid": "_1449362",
  "uiconf_id": 14292362,
  "flashvars": {
    "mediaProxy.mediaPlayFrom" : "2670",
"mediaProxy.mediaPlayTo" : "2940",
},
  "cache_st": 1621444219,
  "entry_id": "1_w2r5byk1"
});
</script>

    <figure class="preview">
        
            <img loading="lazy" src="images/video-preview.png" alt="still image from video"/>
        
        <figcaption><p>The online version of this essay contains an embedded video, represented here by a still frame.</p></figcaption>
    </figure>
</div>

<div class="txt-only">
⩩&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;⟩
| VIDEO. Embedded video of the panel. Timestamped to bring viewers to 44:30-48:17. <a href="https://www.kaltura.com/index.php/extwidget/preview/partner_id/1449362/uiconf_id/14292362/entry_id/1_w2r5byk1/">https://www.kaltura.com/index.php/extwidget/preview/partner_id/1449362/uiconf_id/14292362/entry_id/1_w2r5byk1/</a>
⩩&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;⟩
</div>
<p><strong>Matthew:</strong> In this piece Steffy and I continue the conversation from our April 2021 panel in order to explain the basis of our collaboration, the processes by which we analyze Geniza texts and, most importantly, the stakes of crowdsourcing projects for historical research. Steffy’s work in compiling collections of Geniza fragments with similar formatting, scribal hands, and ink stamps alerted me to the existence of document types that could have otherwise taken months or years to locate. Her individual contributions speak volumes for the ways in which a vast network of <em>Scribes</em> contributors has accelerated the accessibility of Geniza texts. Contributors like Steffy are tackling foundational questions in the field of Cairo Geniza Studies that have never been pursued on such a mass scale. From the moment I happened upon the <em>Scribes</em> discussion boards in the summer of 2020, I was struck by the abundance of user collections and comments regarding the distinctions between genres of literary and documentary fragments.<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup> Steffy, in your volunteer work and collections, what are the core features within the layout of texts that you focus on in order to distinguish between fragment types?</p>
<p><strong>Steffy:</strong> Since I can’t read Arabic or Hebrew, I take skilled handwriting in straight lines with justified margins as signs of the work of professional scribes. Many, but not all, literary texts are neatly written by professional scribes using “square” Hebrew letters, with strictly justified margins. Liturgical poetry, for example, whether written by a scribe or not, might have an unjustified left margin, with a pattern of longer and shorter lines, like poetry in English, but read from right to left. Careful layout, good margins, and straight lines of beautiful script indicate to me that a fragment is “literary,” but other literary fragments (sermons, for example) may lack these features. I’m often unsure what type of fragment I’m looking at, so I like to read the notes on a fragment from the library that holds it, and any comments at the <em>Scribes of the Cairo Geniza</em> site. This slows my volunteer work, but greatly enriches my experience.</p>
<p>The documentary texts are widely varied. Many legal documents, for example, look like the work of professional scribes. Letters from one merchant to another, some with margins crammed full of text written at an angle to the main text, look urgent rather than orderly. Still others are scrawled on re-used scraps of paper in handwriting that is far from well trained. That was true of the “communal register” which you mentioned during our panel last April. In those fragments, a less skilled writer kept dated weekly records that always included some simple math sums. What might these fragments be?</p>
<p><strong>Matthew:</strong> Just as you have noted, Steffy, besides the layout of texts and the economical usage of paper, some other features for assessing the genre of Geniza fragments lie in script usage and the distribution of numerical figures. Square Hebrew letters, or “ מרובע / merūbaʿ,” are indeed a helpful indicator for tracing sacred literary texts. In the period I work on, between the sixteenth and nineteenth centuries, many Geniza texts begin to bear the influence of Sephardi <em>rashi</em> and <em>solitreo</em> scripts. As a result of the immigration of Sephardi refugees into Egypt across the fourteenth through sixteenth centuries—but especially after the Spanish expulsion of the 1492 CE—Geniza fragments portray the increased influence of Iberian systems of Hebrew script.<sup id="fnref:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup></p>
<p>Studying <em>solitreo</em> letter forms—which were more commonly used in writing Judeo-Spanish—can also be helpful for understanding how a variety of documents from the sixteenth to nineteenth centuries incorporate cursive writing. So, for example, in the Judeo-Arabic communal register I referenced during our panel, on occasion, there are interconnected letters in repeating words such as “berakha / blessing / ברכה” (in purple), “fiḍḍa / silver / פצה” (in green), and “seder / order / סדר” (in red).<sup id="fnref:3"><a href="#fn:3" class="footnote-ref" role="doc-noteref">3</a></sup> These cursive forms give the initial impression of messiness and lack of scribal skill yet it’s crucial to recognize the pragmatic significance of this writing method. Connecting letters and abbreviating Judeo-Arabic words such as “ת׳׳ע / t[asāwī] ʿa[la]” (in blue) increased the speed at which a scribe could record notes when calligraphic aesthetics were not the objective.<sup id="fnref:4"><a href="#fn:4" class="footnote-ref" role="doc-noteref">4</a></sup></p>
<p>





















<figure ><img loading="lazy" alt="Manuscript image showing Hebrew letterforms in cursive script" src="/issues/2/serendipity-in-the-cairo-geniza/images/Startwords_Matthew_Steffy_ENA624_22%20cropped.jpg"
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset="/issues/2/serendipity-in-the-cairo-geniza/images/Startwords_Matthew_Steffy_ENA624_22%20cropped_hu5d4d4af13a53f9dee6df2227e73445ae_1931159_500x0_resize_q75_box.jpg 500w,
    /issues/2/serendipity-in-the-cairo-geniza/images/Startwords_Matthew_Steffy_ENA624_22%20cropped_hu5d4d4af13a53f9dee6df2227e73445ae_1931159_800x0_resize_q75_box.jpg 800w,/issues/2/serendipity-in-the-cairo-geniza/images/Startwords_Matthew_Steffy_ENA624_22%20cropped.jpg 981w" 
     class="portrait"
     ><figcaption>
        <p>Image 1. <a href="https://www.zooniverse.org/projects/judaicadh/scribes-of-the-cairo-geniza/talk/subjects/12499256">Subject 12499256</a> (ENA 624.22, Library of the Jewish Theological Seminary): Color-coded annotations of solitreo cursive letter forms and abbreviations, October 1798 CE.<span class="attribution">Library of the Jewish Theological Seminary</span>
        </p>
    </figcaption>
</figure>
<div class="txt-only">
⩩&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;⟩
| FIGURE. Manuscript image showing Hebrew letterforms in cursive script
|
| CAPTION: Image 1. Subject 12499256 (ENA 624.22, Library of the Jewish Theological
|  Seminary): Color-coded annotations of solitreo cursive letter forms and
|  abbreviations, October 1798 CE.
|  <a href="https://www.zooniverse.org/projects/judaicadh/scribes-of-the-cairo-geniza/talk/subjects/12499256">https://www.zooniverse.org/projects/judaicadh/scribes-of-the-cairo-geniza/talk/subjects/12499256</a>
| ATTRIBUTION: Library of the Jewish Theological Seminary
⩩&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;⟩
</div></p>
<p>The headings of this fragment from Steffy’s collection<sup id="fnref:5"><a href="#fn:5" class="footnote-ref" role="doc-noteref">5</a></sup> were recorded during the weeks of October 7–20 1798 CE–just before the Revolt of Cairo unfolded on October 21–22nd when the city&rsquo;s residents fought to eject the French occupation under the leadership of Napoleon Bonaparte. The Jewish calendar dating appears in the heading of each list and it follows a shared formula throughout this type of communal register:<sup id="fnref:6"><a href="#fn:6" class="footnote-ref" role="doc-noteref">6</a></sup></p>
<p>





















<figure class="force-page-break"><img loading="lazy" alt="The image above, cropped to highlight the translation." src="/issues/2/serendipity-in-the-cairo-geniza/images/Startwords_Matthew_Steffy_ENA624_22_croppedheading.jpg"
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset="/issues/2/serendipity-in-the-cairo-geniza/images/Startwords_Matthew_Steffy_ENA624_22_croppedheading_hu7fba9da1679ce4a56c592454604cb9c1_808702_500x0_resize_q75_box.jpg 500w,
    /issues/2/serendipity-in-the-cairo-geniza/images/Startwords_Matthew_Steffy_ENA624_22_croppedheading_hu7fba9da1679ce4a56c592454604cb9c1_808702_800x0_resize_q75_box.jpg 800w,/issues/2/serendipity-in-the-cairo-geniza/images/Startwords_Matthew_Steffy_ENA624_22_croppedheading_hu7fba9da1679ce4a56c592454604cb9c1_808702_1200x0_resize_q75_box.jpg 1200w,/issues/2/serendipity-in-the-cairo-geniza/images/Startwords_Matthew_Steffy_ENA624_22_croppedheading_hu7fba9da1679ce4a56c592454604cb9c1_808702_1500x0_resize_q75_box.jpg 1500w,/issues/2/serendipity-in-the-cairo-geniza/images/Startwords_Matthew_Steffy_ENA624_22_croppedheading_hu7fba9da1679ce4a56c592454604cb9c1_808702_1800x0_resize_q75_box.jpg 1800w,/issues/2/serendipity-in-the-cairo-geniza/images/Startwords_Matthew_Steffy_ENA624_22_croppedheading.jpg 2558w" 
     class="landscape"
     ><figcaption>
        <p>Image 1.2. Translation of the Upper Heading in Subject 12499256 (ENA 624.22) “עלם מקבוץ סדר נח שנת התקנט לברכה” “Account from [the] collection [during the week] of the seder Noaḥ [biblical reading in] the year 5559, may it be a blessing”
        </p>
    </figcaption>
</figure>
<div class="txt-only">
⩩&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;⟩
| FIGURE. The image above, cropped to highlight the translation.
|
| CAPTION: Image 1.2. Translation of the Upper Heading in Subject 12499256
|  (ENA 624.22) “עלם מקבוץ סדר נח שנת התקנט לברכה” “Account from [the] collection
|  [during the week] of the seder Noaḥ [biblical reading in] the year 5559, may it
|  be a blessing”
⩩&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;⟩
</div></p>
<p>The surnames mentioned in each list–such as Vialobos, Ḥadād, and Skenderī –embody the lives of individuals and families who experienced one of the most turbulent periods in Egyptian political history. Between 1798–1801 CE, the Egyptian populace withstood immense hardship in their efforts to defeat the French occupation and then between 1801–1805 as Ottoman military factions fought to assert their control over the province (a process which resulted in Muḥammad ʿAlī&rsquo;s rise to power as Pasha/Governor). What makes these register entries so significant, then, is that they offer a continuous internal perspective on how Cairene Jews supported their communal institutions during a period of harrowing instability.<sup id="fnref:7"><a href="#fn:7" class="footnote-ref" role="doc-noteref">7</a></sup> In my dissertation, I am working to compile the donation data from the many page fragments of these registers. This line of investigation may have never emerged in my research had it not been for my chance encounter with Steffy’s collection in the <em>Scribes</em> database.</p>
<p><strong>Steffy:</strong> Shortly after I began volunteering in early 2018, a batch of these oddly similar fragment images started to pop up. Volunteers could tell these Hebrew script fragments were the work of a single less skilled writer but not why he had written so many similar-looking notes. They did not look like religious texts, legal documents, or letters.</p>
<p>A basic task for the “citizen humanists” who volunteer in the <em>Scribes of the Cairo Geniza</em> project is to try to sort images of the fragments which accumulated in the Geniza for nearly a thousand years into two piles: those in Hebrew script, and those which display some Arabic script. Even for volunteers who, like me, cannot read these scripts, this is usually easy to do.</p>
<p>As I wondered what these fragments were, I realized that each one had areas which showed math sums done in Eastern Arabic numerals.<sup id="fnref:8"><a href="#fn:8" class="footnote-ref" role="doc-noteref">8</a></sup> Perhaps these fragments were entries in a ledger recording an activity which might interest an historian someday?</p>
<p>I had just begun keeping a list on paper of these fragments when one with an Arabic seal (a rare feature which volunteers are asked to report) and large, beautiful Arabic writing on one side appeared on my computer screen. Startled, I decided to make a digital collection of these fragments, hoping that they might be useful to someone’s scholarly research.</p>
<p>But I never imagined that I would meet that person.</p>
<p>Meanwhile, as more and more of these fragments turned up and added to my collection, <em>Scribes</em> project researchers Jasmin Shinohara and Professor Marina Rustow provided information about the dates and partial translation of the text of the fragments.<sup id="fnref:9"><a href="#fn:9" class="footnote-ref" role="doc-noteref">9</a></sup> I am very grateful to them both for that information, and for giving time and attention to the curiosity of a new volunteer at <em>Scribes</em> who wondered what she was looking at.</p>
<p><strong>Matthew:</strong> Likewise, when I mentioned the <em>Scribes</em> user &ldquo;Citsci-Rancho'' during our panel discussion I had hoped they might be watching the panel or eventually see the recording. The serendipity of being able to collaborate on and to answer these questions is a rare opportunity. The seal you included in the register collection is crucial for two reasons. Its significance lies, firstly, in the dating– where the Hijrī year ١١٧٧/1177 AH or 1763/64 CE is visible (in purple):<sup id="fnref:10"><a href="#fn:10" class="footnote-ref" role="doc-noteref">10</a></sup></p>
<p>





















<figure ><img loading="lazy" alt="A faded ink stamp behind script" src="/issues/2/serendipity-in-the-cairo-geniza/images/Startwords_Matthew_Steffy_ENA624_20%20cropped.jpg"
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset="/issues/2/serendipity-in-the-cairo-geniza/images/Startwords_Matthew_Steffy_ENA624_20%20cropped_hu7fba9da1679ce4a56c592454604cb9c1_208246_500x0_resize_q75_box.jpg 500w,
    /issues/2/serendipity-in-the-cairo-geniza/images/Startwords_Matthew_Steffy_ENA624_20%20cropped_hu7fba9da1679ce4a56c592454604cb9c1_208246_800x0_resize_q75_box.jpg 800w,/issues/2/serendipity-in-the-cairo-geniza/images/Startwords_Matthew_Steffy_ENA624_20%20cropped.jpg 1190w" 
     class="landscape"
      style="max-height: 250px"><figcaption>
        <p>Image 2. <a href="https://www.zooniverse.org/projects/judaicadh/scribes-of-the-cairo-geniza/talk/subjects/12499254">Subject 12499254</a> (ENA 624.20, Library of the Jewish Theological Seminary) Ink stamp on recycled paper includes Hijrī year ١١٧٧/1177AH.
        </p>
    </figcaption>
</figure>
<div class="txt-only">
⩩&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;⟩
| FIGURE. A faded ink stamp behind script
|
| CAPTION: Image 2. Subject 12499254 (ENA 624.20, Library of the Jewish Theological
| Seminary) Ink stamp on recycled paper includes Hijrī year ١١٧٧/1177AH.
| <a href="https://www.zooniverse.org/projects/judaicadh/scribes-of-the-cairo-geniza/talk/subjects/12499254">https://www.zooniverse.org/projects/judaicadh/scribes-of-the-cairo-geniza/talk/subjects/12499254</a>
⩩&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;⟩
</div></p>
<p>When we read the Hijrī year 1177 AH on the recycled paper against the dating of the upper layer of usage (September 29–October 5, 1799)– a difference of roughly 35 years emerges.<sup id="fnref:11"><a href="#fn:11" class="footnote-ref" role="doc-noteref">11</a></sup> This timespan marks the initial lifecycle of a piece of paper that lost its utility but was later cut up and bound within a communal register. As Rustow has shown with medieval Geniza sources, early modern ones too can help us analyze the periodicity of paper recycling in Egypt.<sup id="fnref:12"><a href="#fn:12" class="footnote-ref" role="doc-noteref">12</a></sup></p>
<p>The other point of significance with this seal is that the register entries recorded over it reference a specific congregation and synagogue in Cairo: “ק׳׳ק תורקייה / K[ehillat] K[odesh] Tūrkīya.”<sup id="fnref:13"><a href="#fn:13" class="footnote-ref" role="doc-noteref">13</a></sup> This connection is critical because it frames one of the communal settings in which these sources were recorded. When we collect in-text locational references, our opportunities multiply for studying the lives of individuals: more specifically, in tracing their donorship activities and congregational membership.</p>
<p>Steffy’s and my own initial encounters with these fragments have yielded a chain of shared findings that ties back into a broader web of individual contributions in the <em>Scribes</em> database. The initial results of this network of collaboration and those on the horizon underscore the stakes of crowdsourcing in historical research. Moreover, our findings capture the continued resonance of Solomon Schechter’s words when he stated:</p>
<p>“<em>The Geniza is a world, with all its religious and secular aspirations, longings and disappointments, and it requires a world to interpret a world, or at least a large staff of workers</em>.”<sup id="fnref:14"><a href="#fn:14" class="footnote-ref" role="doc-noteref">14</a></sup></p>
<section class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1" role="doc-endnote">
<p>Jessica L. Goldberg and Eve Krakowski offer a helpful overview of the distinctions between literary and documentary fragments: “forms of <em>geniza</em> practice varied not only among communities but also over time, with some periods during which the Ben Ezra Geniza was in use seeing significant deposits of non-sacred material. Most of the Geniza papers–about 380,000 folio pages in all–are fragments of literary manuscripts, largely on religious subjects. But somewhere between thirty and fifty thousand fragments are what is usually termed <em>documentary material</em>; that is, they are everyday writings, texts written not to convey ideas to an anonymous and long-lasting audience but to communicate with specific recipients for immediate practical purposes.” Jessica L. Goldberg and Eve Krakowski, “Introduction: A Handbook for Documentary Geniza Research in the Twenty-First Century,” in “Documentary Geniza Research in the Twenty-First Century,” eds. Goldberg and Krakowski, special issue, <em>Jewish History</em> 32 (2019): 118, <a href="https://doi.org/10.1007/s10835-019-09338-y">https://doi.org/10.1007/s10835-019-09338-y</a>.&#160;<a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:2" role="doc-endnote">
<p>S. D. Goitein already recognized the effects of this acculturative process on Cairo Geniza texts in the 1960s. S. D. Goitein, <em>A Mediterranean Society: The Jewish Communities of the Arab World as Portrayed in the Documents of the Cairo Genizah</em> (Berkeley: University of California Press, 1967), 1: 19.&#160;<a href="#fnref:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:3" role="doc-endnote">
<p>When “berakha” (blessing) does not appear in the heading of these specific entries it can refer to the week of the final parsha reading “[Ve-Zot Ha-]Berakha.”&#160;<a href="#fnref:3" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:4" role="doc-endnote">
<p>The abbreviation “ת׳׳ע / t[asāwī] ʿa[la]” in Judeo-Arabic translates as “amounting to” and thus precedes many numerical values (in this case to introduce monetary contributions).&#160;<a href="#fnref:4" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:5" role="doc-endnote">
<p>See Steffy’s collection of Judeo-Arabic register fragments on the Scribes of the Cairo Geniza site: <a href="https://www.zooniverse.org/projects/judaicadh/scribes-of-the-cairo-geniza/collections/citsci-rancho/multi-page-arabic-document-with-seal">https://www.zooniverse.org/projects/judaicadh/scribes-of-the-cairo-geniza/collections/citsci-rancho/multi-page-arabic-document-with-seal</a>.&#160;<a href="#fnref:5" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:6" role="doc-endnote">
<p>I thank my colleague at the Princeton Geniza Lab, Alan Elbaum, for his comments on this translation.&#160;<a href="#fnref:6" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:7" role="doc-endnote">
<p>For insight onto the precarious position of Cairo’s Jewish and other minority communities during the French occupation, see especially: Gabriel Baer, “Popular Revolt in Ottoman Cairo,” <em>Der Islam</em> 52, no. 2 (1977): 221–26.&#160;<a href="#fnref:7" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:8" role="doc-endnote">
<p>Unlike the Western Arabic numerals that we use today in English, early modern Geniza fragments make extensive use of Eastern Arabic numerals. The latter system first developed across the Indian subcontinent and passed into Persian, Arabic, and Turkish recordkeeping practices in Late Antiquity and during the Middle Ages.&#160;<a href="#fnref:8" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:9" role="doc-endnote">
<p>For example, see ENA 330.3, Subject 12498819: <a href="https://www.zooniverse.org/projects/judaicadh/scribes-of-the-cairo-geniza/talk/1029/536401?comment=1575953&amp;page=1">https://www.zooniverse.org/projects/judaicadh/scribes-of-the-cairo-geniza/talk/1029/536401?comment=1575953&amp;page=1</a>.&#160;<a href="#fnref:9" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:10" role="doc-endnote">
<p>This seal clearly incorporates the name “Ibrāhīm / ابراهيم.” One possible reading of the letters below it is the surname “ʿAbīd / عبيد.” Much of the upper half of the seal is obscured by entries in the communal register but may contain an official and/or honorific title. The seal may have belonged to the same person who signed the verso of ENA 624.20, dated 29 Muḥarram, 1181 AH (which is June 6, 1767 CE).&#160;<a href="#fnref:10" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:11" role="doc-endnote">
<p>The entry written over this stamp was recorded in the week of the Va-Yelekh parsha reading in the Jewish calendar year 5559 AM, which was September 29–October 5, 1799.&#160;<a href="#fnref:11" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:12" role="doc-endnote">
<p>Marina Rustow, <em>The Lost Archive: Traces of a Caliphate in a Cairo Synagogue</em> (Princeton: Princeton University Press, 2020), 73–82.&#160;<a href="#fnref:12" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:13" role="doc-endnote">
<p>This reference appears in line three of the second entry of ENA 624.20. MuḥsinʻAlī Shūmān cites the existence of this congregation by the early seventeenth century. MuḥsinʻAlī Shūmān, <em>The Jews in Ottoman Egypt Until the Beginning of the Nineteenth Century / al-Yahūd fī Miṣr al-ʻUthmānīyah ḥatta awāʾil al-qarn al-tāsiʻ ʻashar,</em> vol. 2 (Cairo: al-Hayʼah al-Miṣrīyah al-ʻĀmmah lil-Kitāb, 2000) 70, 102. Maurice Fargeon confirms that the “Torkia” synagogue still existed in Cairo in the 1930s. Maurice Fargeon, <em>Les Juifs en Egypte: Depuis les Origines jusqu&rsquo;à ce jour</em> (Cairo: Imprimerie Paul Barbey, 1938), 200.&#160;<a href="#fnref:13" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:14" role="doc-endnote">
<p>Solomon Schechter, “Miscellany,” (lecture, <em>The Genizah and Jewish Learning</em>, Dropsie College, May 5, 1910), qtd. in Norman Bentwich, <em>Solomon Schechter: A Biography</em> (Philadelphia: Jewish Publication Society of America, 1938), 161.&#160;<a href="#fnref:14" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</section>
]]></content></entry><entry><title type="html">“Strangers in the Landscape”: On Research Development and Making Things for Making</title><link href="https://startwords.cdh.princeton.edu/issues/2/strangers-in-the-landscape/?utm_source=atom_feed" rel="alternate" type="text/html"/><id>https://startwords.cdh.princeton.edu/issues/2/strangers-in-the-landscape/</id><author><name>Samantha Blickhan</name></author><author><name>Will Granger</name></author><author><name>Shaun A. Noordin</name></author><author><name>Becky Rother</name></author><published>2021-12-01T00:00:00+00:00</published><updated>2022-02-07T13:54:19-05:00</updated><content type="html"><![CDATA[<h2 id="introduction">Introduction</h2>
<p>This piece is about making in support of making. It is about projects born from myriad goals that gather new objectives along their lifecycle, through evaluation and iteration.</p>
<p>This piece is about translating: from concept to design to product; from fragment to image to text; from high-level goal to incremental steps. It is about workflows and spin-offs and objectives; it is about unraveling a tapestry to learn how to spin its yarn.</p>
<p>In <em>Data Feminism</em>, Catherine D’Ignazio and Lauren F. Klein use the example of the proliferation of street signs to make a point about making: <em>“One does not need street names for navigation until one has strangers in the landscape</em>” (italics in the original).<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup> In D’Ignazio and Klein’s usage, the “strangers” here are data scientists, digging through data with which they are not intimately familiar. In this piece, we use our experience as platform maintainers to illustrate how all collaborators and participants are “strangers” at one point or another in the process of research development;<sup id="fnref:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup> it is only through collective building that we can successfully name our streets.</p>
<p>The framework for our discussion will be <a href="https://www.scribesofthecairogeniza.org"><em>Scribes of the Cairo Geniza</em></a>, a crowdsourcing project hosted on the Zooniverse platform.<sup id="fnref:3"><a href="#fn:3" class="footnote-ref" role="doc-noteref">3</a></sup> <em>Scribes</em> invites members of the public to engage deeply with the Cairo Geniza corpus: hundreds of thousands of manuscript fragments written in Hebrew and Arabic script, found in an Egyptian synagogue and dating mostly from the tenth to thirteenth centuries CE.<sup id="fnref:4"><a href="#fn:4" class="footnote-ref" role="doc-noteref">4</a></sup> The project is a collaboration between the Zooniverse team and a group of specialists from the Judaica Digital Humanities program at the University of Pennsylvania Libraries (as well as a consortium of partner institutions).<sup id="fnref:5"><a href="#fn:5" class="footnote-ref" role="doc-noteref">5</a></sup> Though a collaborative effort, each of the lead institutions brought their own goals to this project.<sup id="fnref:6"><a href="#fn:6" class="footnote-ref" role="doc-noteref">6</a></sup> For the Penn team, the original goal was to fully digitize the Geniza corpus through transcription of the fragment texts by a nonspecialist audience. The Zooniverse team came to the <em>Scribes</em> partnership as part of a larger research and development effort, “Transforming Libraries and Archives through Crowdsourcing,” which aimed to expand the resources available on the Zooniverse platform to better support galleries, libraries, archives, and museums in their efforts to create and run crowdsourcing projects.<sup id="fnref:7"><a href="#fn:7" class="footnote-ref" role="doc-noteref">7</a></sup></p>
<p>This piece will trace the history of this partnership, focusing on the interplay between often-competing elements of Digital Humanities (henceforth DH) collaboration: optimization and engagement, experience and outcome. In our attempts to balance the demands of infrastructure against the practice of paleography, what can we, as collaborators, learn about the process?</p>
<p>Throughout the piece, we have provided interludes in which we will walk you through the process of creating clickable keyboards for transcribing Hebrew script. Please feel free to interact with the example keyboards. You can try the full version by visiting <a href="https://www.scribesofthecairogeniza.org"><em>Scribes of the Cairo Geniza</em></a> and choosing the Easy Hebrew transcription workflow.<sup id="fnref:8"><a href="#fn:8" class="footnote-ref" role="doc-noteref">8</a></sup> You can read the interludes in their entirety and view the source code on <a href="https://shaunanoordin.github.io/zooniverse-startwords/">GitHub</a>.</p>
<div class="interlude">
<div class="center">
<h3 id="kb1">01. The Basics: A Form With Some Text Input</h3>
<p>Let&rsquo;s start by setting up a very basic web form. It has one text input field, one submit button, and one output panel.</p>
<iframe title="Basic Input Form" id="kb-s01" src="/issues/2/strangers-in-the-landscape/zooniverse-interludes/section-01.html"></iframe>
<p>Everything we build from this point onwards is meant to solve one very simple problem: <strong>how do we allow users to type, into that text input field, in a language that&rsquo;s not native to their keyboard?</strong> For example, how do we help a user type in the text &ldquo;ごはんを食べる&rdquo; when they only have a US-International QWERTY keyboard, and we don’t want to ask them to futz about in their computer settings to install a Japanese language pack?</p>
<div class="print-only-preview">
<em>The online version of this essay includes interactive keyboards threaded throughout the text.</em>
</div>
</div>

</div>
<div class="txt-only">
⩩&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;⟩
| INTERACTIVE COMPONENT.
| SOURCE CODE: <a href="https://github.com/shaunanoordin/zooniverse-startwords/blob/master/section-01.html">https://github.com/shaunanoordin/zooniverse-startwords/blob/master/section-01.html</a>
⩩&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;⟩
</div>
<h2 id="communal-making-and-collective-building">Communal Making and Collective Building</h2>
<p>When we build public crowdsourcing projects, the work we do as platform builders/maintainers is intended to facilitate research goals without sacrificing the experience of the people who will be engaging with what we build. This means taking the ideas our collaborators bring to the table (“What do you want to do with this project?”) and creating tools and interfaces that support their needs (“What do we need to build/adapt to facilitate the realization of these goals?”) while simultaneously supporting public audiences by allowing them to engage with the project content with no assumption of previously-held knowledge (“How do we need to adjust these goals—and, by extension, the supporting tools/infrastructure—to make this project inclusive of a broad, public audience?”).</p>

<blockquote class="pull left">
    …bridging concepts as varied as paleography and pull requests requires time and patience
</blockquote>
<p>Bill Endres writes that “building faces the challenge of not being writing.”<sup id="fnref:9"><a href="#fn:9" class="footnote-ref" role="doc-noteref">9</a></sup> For Endres, “building” is a practice typically excluded from institutional decisions on tenure and promotion in humanities departments. Much of the discourse around building in DH acknowledges this disparate treatment between the creation of tools and the production of traditional research, but Endres’s phrase also reminds us that writing is the medium by and around which scholarly communication has also primarily taken place. We write, we peer review, we give written feedback. When we talk about the Things We Are Building, the role of translator or mediator is often assumed by team members who have spent time in both “worlds.” Learning how to communicate across varying disciplinary backgrounds or via unfamiliar mediums (in our case, bridging concepts as varied as paleography and pull requests) requires time and patience.</p>
<div class="interlude">
<div class="center">
<h3 id="02-a-simple-on-screen-keyboard">02. A Simple On-screen Keyboard</h3>
<p>A straightforward solution is to create an on-screen keyboard for the user. In this example, we create a Japanese keyboard with 5 characters. Clicking on each button/“keyboard key” adds the corresponding character to the end of the text input field.</p>
<p><em>Note: we’re using the Japanese hiragana characters あいうえお here because they map easily to the English characters AIUEO, and are written left to right. We’ll build up to more complex alphabets, such as Hebrew and its right-to-left layout, in later sections.</em></p>
<iframe title="Simple On-screen Keyboard" id="kb-s02" src="/issues/2/strangers-in-the-landscape/zooniverse-interludes/section-02.html"></iframe>
<div class="txt-only">
⩩&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;⟩
| INTERACTIVE COMPONENT.
| SOURCE CODE: <a href="https://github.com/shaunanoordin/zooniverse-startwords/blob/master/section-02.html">https://github.com/shaunanoordin/zooniverse-startwords/blob/master/section-02.html</a>
⩩&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;⟩
</div>
<p>The code here is simple, but we already come across a problem: what if the user wants to add a Japanese character in the middle (instead of at the end) of the text box? This is, after all, a very basic function for a normal text box—you can place the text cursor/caret at any part of the existing text and then start typing.</p>
</div>

</div>
<p>It can help to identify shared frames of reference early in the collaboration. The original proposal for the project that would become <em>Scribes of the Cairo Geniza</em> envisioned a public transcription effort that would teach volunteers “without any prerequisite knowledge” how to transcribe the Arabic and Hebrew scripts found in the Geniza. It cited a previous Zooniverse project, <a href="https://www.ancientlives.org"><em>Ancient Lives</em></a> (2011),<sup id="fnref:10"><a href="#fn:10" class="footnote-ref" role="doc-noteref">10</a></sup> which featured a clickable keyboard that allowed users to transcribe ancient Greek papyri from the <a href="https://www.classics.ox.ac.uk/oxyrhynchus-papyri">Oxyrhynchus Collection</a> at the University of Oxford&rsquo;s Sackler Library through the process of character matching. <em>Ancient Lives</em> became an important reference for the entire Geniza project team because it allowed a group of people with a variety of professional backgrounds to engage in referential communication around a shared goal, rather than fumbling together toward an abstract concept. Starting with a critique of an existing resource allowed us to determine the features that were applicable for the context in which we were working—what we wanted to recreate (or revamp) as well as what components were missing that would be key to working with Geniza fragments.</p>
<p>To approach the transcription of a large, multilingual corpus by a nonspecialist audience, we needed to think about scaffolding. We began by considering the goals, translating those goals into actionable tasks, then breaking those tasks down to their very smallest unit. This is particularly useful from a project management perspective, where it’s necessary to get a sense of the total effort required—no matter how small the task—to see what can realistically be completed within the available time frame. Additionally, this process can help identify potential conflict in the design and development stages. There will often be overlap in the translation from goals into tasks: the goal of transcribing the Geniza corpus and the goal of making the project accessible by a public, nonspecialist audience are not separate things; indeed, each will significantly impact how the other is carried out. Breaking down the goals helps to identify the places where that overlap will create tension in the work.</p>

<blockquote class="pull right">
    Of those in our audience who could read Arabic and/or Hebrew, a significant subset would not have experience reading or transcribing Aramaic, Judeo-Persian, or any of the other languages known to be found among the Geniza fragments.
</blockquote>
<p>During the brainstorming process for <em>Scribes</em>, we discussed how the <em>Ancient Lives</em> approach (presenting users with a clickable keyboard to use while transcribing) was desirable because it provides support for audiences who don’t use an Arabic or Hebrew keyboard at home and may not be familiar with each script’s characters. We know through Google Analytics and user surveys that the majority of registered Zooniverse volunteers are from the United States and the United Kingdom. As a result, we could safely assume that a significant portion of our audience would use an English-language keyboard, and a significant subset would not be able to read Arabic and/or Hebrew. Of those in our audience who <em>could</em> read Arabic and/or Hebrew, a significant subset would not have experience reading or transcribing Aramaic, Judeo-Persian, or any of the other languages known to be found among the Geniza fragments.<sup id="fnref:11"><a href="#fn:11" class="footnote-ref" role="doc-noteref">11</a></sup> While clickable keyboards would help with the specific task of transcription within the overall project workflow, we also knew a translatable interface would be necessary to support a multilingual community of volunteers. So we decided early on that the entire project would need to be available in Arabic, English, and Hebrew, adding an additional layer of complexity to the design and development process in order to support right-to-left (RTL) as well as left-to-right (LTR) text.</p>
<div class="interlude">
<div class="center">
<h3 id="03-text-selection">03. Text Selection</h3>
<p>This is actually a solved problem: we use the standard <code>HTMLInputElement</code>’s <code>selectionStart</code>, <code>selectionEnd</code>, and <code>setSelectionRange</code> to interact with the “text cursor” on the text input field.</p>
<iframe title="Text Selection Feature" id="kb-s03" src="/issues/2/strangers-in-the-landscape/zooniverse-interludes/section-03.html"></iframe>
<div class="txt-only">
⩩&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;⟩
| INTERACTIVE COMPONENT.
| SOURCE CODE: <a href="https://github.com/shaunanoordin/zooniverse-startwords/blob/master/section-03.html">https://github.com/shaunanoordin/zooniverse-startwords/blob/master/section-03.html</a>
⩩&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;⟩
</div>
<p>In the example above, we’ve done two things in the code: 1. we ensure the Japanese characters are inserted at the position of the text cursor/caret, and 2. we ensure the text input maintains focus after the insertion. These may seem like minor coding considerations, but they’re important to <strong>ensure a consistent User Experience (UX), since users often have pre-set expectations on how User Interface (UI) elements should behave.</strong></p>
</div>

</div>
<p>Based on institutional knowledge—held by our Zooniverse colleagues who built the <em>Ancient Lives</em> project—and early technical experiments, we knew that a basic version of the clickable keyboard feature would be technically feasible to create. However, the breadth of scripts, languages, layouts, and physical deterioration among the vast Geniza corpus meant that there would be varying levels of difficulty in the fragments’ transcription. To be immediately presented with a random Geniza fragment and asked to transcribe it would be overwhelming for most users. To that end, we considered ways to harness existing information about the fragments (metadata) to break down the corpus into smaller groups. The problem with this approach was that the fragments came from multiple institutions, each with its own metadata system. Some of those systems were more robust (and more recently updated) than others.</p>
<p>The team agreed that this method would be helpful in creating pathways for participation for nonspecialists, but we were concerned that not all of the datasets we were working with had robust, reliable metadata. What was the taxonomy we were hoping to draw on—an existing framework for classifying fragments? A new one? How would we apply consistent metadata to so many fragments within a limited amount of time? <em>Is this something that the project volunteers could help with?</em></p>
<p>Once we determined that metadata enhancement could be its own crowdsourced task, we considered how to add that task to the project in a meaningful way.<sup id="fnref:12"><a href="#fn:12" class="footnote-ref" role="doc-noteref">12</a></sup> We wanted to make transcription accessible. But we also wondered: Could the <em>classification</em> of fragments proceed in a way that did not require previous knowledge of the materials? Would it be interesting for our audience? How would they benefit from taking part?</p>

<blockquote class="pull left">
    Could the classification of fragments proceed in a way that did not require previous knowledge of the materials?
</blockquote>
<p>To break down the necessary metadata fields into accessible tasks, we decided to map our desired classification types onto easily identifiable visual characteristics.<sup id="fnref:13"><a href="#fn:13" class="footnote-ref" role="doc-noteref">13</a></sup> The Geniza experts determined several pieces of information they might ask for at the pre-transcription stage, and were then challenged to teach the team members who weren’t familiar with the Geniza—or even manuscript studies in the broader sense—how to recognize these features when viewing a fragment. For example, in order to ask users whether a fragment was written in Hebrew script or Arabic script (or both), the content experts needed to determine what information is necessary to successfully answer the question.</p>
<p>





















<figure ><img loading="lazy" alt="Two columns of screenshots from Geniza fragments displaying Hebrew and Arabic script examples." src="/issues/2/strangers-in-the-landscape/images/01_script-examples.png"
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset="/issues/2/strangers-in-the-landscape/images/01_script-examples_hu3da65b61b419604a55e3823b10c0f42e_2038119_500x0_resize_box_3.png 500w,
    /issues/2/strangers-in-the-landscape/images/01_script-examples_hu3da65b61b419604a55e3823b10c0f42e_2038119_800x0_resize_box_3.png 800w,/issues/2/strangers-in-the-landscape/images/01_script-examples_hu3da65b61b419604a55e3823b10c0f42e_2038119_1200x0_resize_box_3.png 1200w,/issues/2/strangers-in-the-landscape/images/01_script-examples_hu3da65b61b419604a55e3823b10c0f42e_2038119_1500x0_resize_box_3.png 1500w,/issues/2/strangers-in-the-landscape/images/01_script-examples.png 1698w" 
     class="landscape"
     ><figcaption>
        <p>Script examples from the Geniza corpus, intended to help volunteers answer the question of whether a fragment they are viewing is written in Hebrew or Arabic script.
        </p>
    </figcaption>
</figure>
<div class="txt-only">
⩩&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;⟩
| FIGURE. Two columns of screenshots from Geniza fragments displaying Hebrew and Arabic script examples.
|
| CAPTION: Script examples from the Geniza corpus, intended to help volunteers answer the question of whether a fragment they are viewing is written in Hebrew or Arabic script.
⩩&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;⟩
</div></p>
<p>We were then able to use our own expertise as platform maintainers to design and build resources for volunteers (including the Help Text, shown above) that allowed the content experts to communicate that information to project volunteers as efficiently as possible.<sup id="fnref:14"><a href="#fn:14" class="footnote-ref" role="doc-noteref">14</a></sup> The resulting effort is known as the <a href="https://www.zooniverse.org/projects/judaicadh/scribes-of-the-cairo-geniza/classify?workflow=4712">Sorting workflow</a>.</p>
<div class="interlude">
<div class="center">
<h3 id="04-physical-keyboard-key-capture">04. Physical Keyboard Key Capture</h3>
<p>Alright, so we now have an on-screen keyboard. But what about the user’s physical keyboard? A user might find it easier to use their physical keyboard to do text transcription, compared to clicking each on-screen keyboard button individually. With that in mind, let’s try to translate those physical key presses into our custom character input.</p>
<p>In this example, when the user presses the &ldquo;A&rdquo; key on their keyboard, the Japanese character あ is inserted into the text field instead. Same for the other characters: A -&gt; あ , I -&gt; い, U -&gt; う, E -&gt; え, O -&gt; お</p>
<iframe title="Keyboard Key Capture" id="kb-s04" src="/issues/2/strangers-in-the-landscape/zooniverse-interludes/section-04.html"></iframe>
<div class="txt-only">
⩩&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;⟩
| INTERACTIVE COMPONENT.
| SOURCE CODE: <a href="https://github.com/shaunanoordin/zooniverse-startwords/blob/master/section-04.html">https://github.com/shaunanoordin/zooniverse-startwords/blob/master/section-04.html</a>
⩩&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;⟩
</div>
<p><em>If you have an on-screen keyboard AND you&rsquo;re capturing physical key input, it’s a good idea to label those on-screen keyboard buttons with the corresponding physical keys.</em></p>
<p>One of the biggest considerations here is <strong>what kind of physical keyboard does your user have?</strong> In our examples, we’re making a very hard assumption that all our users have US-International QWERTY keyboards, and we choose to map <em>physical keyboard keys</em> to their replacement characters.</p>
<p><em>Note: there are different ways to get what the user typed into a text field. keyboardEvent.code corresponds to the PHYSICAL key on the keyboard. keyboardEvent.key corresponds to the TEXT VALUE of the key. If a user presses the “A” key on a US-International QWERTY keyboard, we get code=‘KeyA,’ and key=‘a’ (if shift and caps lock are off) or key=‘A’ (if shift and caps lock are on).</em></p>
<p><strong>WARNING:</strong> Now that we know how to capture and replace keyboard input, we also need to learn when not to do so. Sometimes, when a user presses the “A” key, they just want to type in the character “A,” not “あ”! <strong>Always allow your users the option to disable your on-screen keyboard.</strong> The example above has no such option, but we&rsquo;ll explore how we can do this once we jump into the “multi-language” functionality of our onscreen keyboard.</p>
</div>

</div>
<p>This was a turning point in the collaboration, as we began to understand the real value of having multiple kinds of “strangers” and their perspectives in the room. Speaking to diverse perspectives—even within our planning meetings—prevented us from sharing ideas and information without considering how those concepts might be broken down into simpler components. Rather than being a barrier to communication, it gave us the opportunity to observe a version of the volunteer experience we were building in real time, through our interactions with one another.</p>
<h2 id="designing-scribes-of-the-cairo-geniza-for-public-access">Designing Scribes of the Cairo Geniza for Public Access</h2>
<p>As the content specialists solidified their goals and worked with our team to determine the best way to accomplish those goals, two design needs became clear: first, that we could utilize existing Zooniverse project builder infrastructures to make a pre-transcription task that would produce useful metadata; and second, that a custom transcription interface would be necessary to support the on-screen keyboards.</p>

<blockquote class="pull right">
    User experience (UX) design relies on common behavioral patterns to help a user feel comfortable in an interface, even when faced with a completely novel situation
</blockquote>
<p>We didn’t need to start from scratch. <em>Ancient Lives</em> provided a shared reference on which to build. Which parts of that interface were successful? What made the use cases in <em>Scribes</em> unique and therefore required a rethinking of the user experience? What other transcription projects existed online that could provide inspiration for our task? These questions helped shape initial design sketches for the transcription workflow and text input area.</p>
<p>





















<figure ><img loading="lazy" alt="A photo of an open notebook showing sketches of a web page, toolbar icons, and handwritten notes." src="/issues/2/strangers-in-the-landscape/images/02_CG-interface3.jpeg"
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset="/issues/2/strangers-in-the-landscape/images/02_CG-interface3_hu5d933f6ebe9c4c50c7755f0ec17eb888_2433924_500x0_resize_q75_box.jpeg 500w,
    /issues/2/strangers-in-the-landscape/images/02_CG-interface3_hu5d933f6ebe9c4c50c7755f0ec17eb888_2433924_800x0_resize_q75_box.jpeg 800w,/issues/2/strangers-in-the-landscape/images/02_CG-interface3_hu5d933f6ebe9c4c50c7755f0ec17eb888_2433924_1200x0_resize_q75_box.jpeg 1200w,/issues/2/strangers-in-the-landscape/images/02_CG-interface3_hu5d933f6ebe9c4c50c7755f0ec17eb888_2433924_1500x0_resize_q75_box.jpeg 1500w,/issues/2/strangers-in-the-landscape/images/02_CG-interface3_hu5d933f6ebe9c4c50c7755f0ec17eb888_2433924_1800x0_resize_q75_box.jpeg 1800w,/issues/2/strangers-in-the-landscape/images/02_CG-interface3.jpeg 4032w" 
     class="landscape"
     ><figcaption>
        <p>An early sketch of the Scribes of the Cairo Geniza transcription interface.<span class="attribution">By designer Becky Rother.</span>
        </p>
    </figcaption>
</figure>
<div class="txt-only">
⩩&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;⟩
| FIGURE. A photo of an open notebook showing sketches of a web page, toolbar icons, and handwritten notes.
|
| CAPTION: An early sketch of the Scribes of the Cairo Geniza transcription interface.
| ATTRIBUTION: By designer Becky Rother.
⩩&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;⟩
</div></p>
<p>User experience (UX) design relies on common behavioral patterns to help a user feel comfortable in an interface, even when faced with a completely novel situation (such as transcribing an ancient manuscript written in an unfamiliar language). UX designers also rely heavily on direct user feedback to ensure that the interface both functions as it should and feels natural to those users. To that end, we first identified a few key groups of user personas to envision our target audience. These personas served as guides throughout the design process. Would a grad student in Massachusetts be able to quickly understand how to transcribe a line of text? Would a pensioner in Brighton? What about a modern native speaker? By keeping in mind these different experience levels, we were able to focus our design efforts and keep scope creep to a minimum.<sup id="fnref:15"><a href="#fn:15" class="footnote-ref" role="doc-noteref">15</a></sup></p>
<div class="interlude">
<div class="center">
<h2 id="multi-language-keyboards">Multi-Language Keyboards</h2>
<h3 id="05-code-cleanup">05. Code Cleanup</h3>
<p>Before we proceed with the advanced considerations of creating an on-screen keyboard with multiple languages, let’s clean up our code.</p>
<p>In the example below, you won’t see many changes in terms of UI functionality, but a lot of the source code was altered. Notably:</p>
<ul>
<li>The Japanese characters have now been compiled into a “Japanese keyboard” data object, setting the stage for <strong>dynamically generated keyboards</strong> for different languages.</li>
<li>Similarly, we now have “English keyboard” and “QWERTY layout” data objects that help ensure <strong>the visual layout of the on-screen keyboard matches the user’s physical keyboard.</strong></li>
</ul>
<iframe title="Full Keyboard Implementation" id="kb-s05" src="/issues/2/strangers-in-the-landscape/zooniverse-interludes/section-05.html"></iframe>
<div class="txt-only">
⩩&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;⟩
| INTERACTIVE COMPONENT.
| SOURCE CODE: <a href="https://github.com/shaunanoordin/zooniverse-startwords/blob/master/section-05.html">https://github.com/shaunanoordin/zooniverse-startwords/blob/master/section-05.html</a>
⩩&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;⟩
</div>
</div>

</div>
<p>As we worked through the design, it was essential that we also speak to real users of the platform in order to validate our assumptions and test that the task we were designing was easy to understand. We reached out to our list of Zooniverse beta reviewers as well as personal networks to find native Hebrew and Arabic speakers who were willing to test the platform in translation. Through these conversations, we were able to see how a RTL interface would differ from English or other LTR language interfaces, and make adjustments accordingly.</p>
<p>We also realized that because the subject matter could be intimidating, it was important to craft an interface that would straddle the line between friendly and knowledgeable. This was accomplished through the use of typography and color. First, we looked for a typeface that could be both friendly and trustworthy: both are attributes of a family of sans-serifs called Grotesque. These simple, clean typefaces are easy to read and add a friendly personality to the interface.</p>
<p>





















<figure ><img loading="lazy" alt="Three font examples that read “Scribes of the Cairo Geniza” in English, Arabic, and Hebrew." src="/issues/2/strangers-in-the-landscape/images/03_Geniza-type-samples.png"
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset="/issues/2/strangers-in-the-landscape/images/03_Geniza-type-samples_hu8ae879167bf73d5a88e46157d2a99319_55208_500x0_resize_box_3.png 500w,
    /issues/2/strangers-in-the-landscape/images/03_Geniza-type-samples_hu8ae879167bf73d5a88e46157d2a99319_55208_800x0_resize_box_3.png 800w,/issues/2/strangers-in-the-landscape/images/03_Geniza-type-samples_hu8ae879167bf73d5a88e46157d2a99319_55208_1200x0_resize_box_3.png 1200w,/issues/2/strangers-in-the-landscape/images/03_Geniza-type-samples_hu8ae879167bf73d5a88e46157d2a99319_55208_1500x0_resize_box_3.png 1500w,/issues/2/strangers-in-the-landscape/images/03_Geniza-type-samples.png 1734w" 
     class="landscape"
     ><figcaption>
        <p>The three Grotesque typefaces used for Scribes of the Cairo Geniza in English, Arabic, and Hebrew.
        </p>
    </figcaption>
</figure>
<div class="txt-only">
⩩&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;⟩
| FIGURE. Three font examples that read “Scribes of the Cairo Geniza” in English, Arabic, and Hebrew.
|
| CAPTION: The three Grotesque typefaces used for Scribes of the Cairo Geniza in English, Arabic, and Hebrew.
⩩&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;⟩
</div></p>
<p>It was also important that the experience remain similar across all three languages, so typefaces were chosen and vetted with native speakers to ensure parity.</p>
<div class="interlude">
<div class="center">
<h3 id="06-language-selection">06. Language Selection</h3>
<p>Now that we have cleaned up the code so that the English and Japanese keyboards are stored data objects, we see that it’s very simple to add new languages/keyboards to the system, and to allow the user to switch between those languages/keyboards.</p>
<p>To illustrate this point, we’ve added a joke &ldquo;Emoji keyboard&rdquo; that maps QWERTY keys to arbitrary emoji characters. Typing in “Hello world” into input text field will result in the emoji “text” of “🐟🤣🦋🦋😍 😅😍🥰🦋🐒.”</p>
<iframe title="Emoji Keyboard" id="kb-s06" src="/issues/2/strangers-in-the-landscape/zooniverse-interludes/section-06.html" class="force-page-break"></iframe>
<div class="txt-only">
⩩&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;⟩
| INTERACTIVE COMPONENT.
| SOURCE CODE: <a href="https://github.com/shaunanoordin/zooniverse-startwords/blob/master/section-06.html">https://github.com/shaunanoordin/zooniverse-startwords/blob/master/section-06.html</a>
⩩&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;⟩
</div>
<p><em>Note: there is an option to select “(No keyboard)” here, which disables the on-screen keyboard as well as key capture. As mentioned earlier, <strong>always allow your users the option to disable your on-screen keyboard.</strong></em></p>
<p>At this point, you might realize one limitation to our solution: our code simply re-maps the QWERTY keyboard, so we can only have one character for one key.</p>
<p>While we started our examples with a very simple five-character Japanese keyboard, we unfortunately have to discard it since a proper, fully functional Japanese keyboard is beyond the scope of this work. The Japanese <em>hiragana</em> writing system alone has 48 common base characters, which can be further modified with diacritics, character size, etc.</p>
<p>In the next section, we’ll start adding a Hebrew keyboard. The Hebrew alphabet has 22 characters, which will map very easily to English/QWERTY’s 26 characters. However, the Hebrew alphabet will introduce a new wrinkle: <strong>right-to-left text</strong>, which we’ll need to solve.</p>
</div>

</div>
<p>After the typography was chosen, we created a color palette that was inspired by the Geniza fragments themselves. A contrasting purple was chosen for the background to allow the subjects to visually pop. Even the help text was closely considered: because of the wide reach of the project, help text needed to be clear, concise, and easy to understand. Our baseline was a fifth-grade reading level using the Flesch-Kincaid scale.<sup id="fnref:16"><a href="#fn:16" class="footnote-ref" role="doc-noteref">16</a></sup></p>
<p>While most of the design used common user-interface patterns—a toolbar, iconography, other resources familiar to Zooniverse volunteers—the project goals called for the creation of a few novel or less frequently seen elements. These included the transcription mechanism itself and the interactive, on-screen keyboards.</p>
<p>In order to create useful transcription data, the team needed to ensure consistent line placement that an algorithm would be able to parse correctly.<sup id="fnref:17"><a href="#fn:17" class="footnote-ref" role="doc-noteref">17</a></sup> We looked both within and outside of Zooniverse for inspiration and found a variety of transcription methods, from single- to multi-track. We considered what to use as the basic unit of transcription: how would we ask users to break down the text on the page, e.g. by character, word, line? From our experience with other crowdsourced transcription projects, we knew that line-by-line transcription would be the optimal blend of user effort to manageable data output. And from testing, we found that it was most intuitive to click once at the start of a line and then again at the end of the line. From there, the project tutorial as well as pop-up directions guided the user through the transcription process and the use of the on-screen clickable keyboards.</p>
<div class="interlude">
<div class="center">
<h3 id="07-hebrew-and-right-to-left-languages">07. Hebrew and Right-to-Left languages</h3>
<p>With the given assumption that English is the “default” language of web code (yes, we know, that discussion is a can of worms), it’s unsurprising that that layout of most web pages default to left-to-right (LTR), top-to-bottom.</p>
<p>As a result, we must be conscientious when we create on-screen keyboards for languages to read right-to-left (RTL), such as Hebrew and Arabic. In the example below, we’ve done two things:</p>
<ul>
<li>We’ve upgraded the keyboard data objects so each language, in addition to having characters, also has an <strong>explicit “direction” value.</strong> (Either “ltr” or “rtl”)</li>
<li>The text input field has an explicit CSS direction value that changes depending on the active keyboard.</li>
</ul>
<iframe title="Hebrew, English, and Emoji Keyboard" id="kb-s07" src="/issues/2/strangers-in-the-landscape/zooniverse-interludes/section-07.html"></iframe>
<div class="txt-only">
⩩&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;⟩
| INTERACTIVE COMPONENT.
| SOURCE CODE: <a href="https://github.com/shaunanoordin/zooniverse-startwords/blob/master/section-07.html">https://github.com/shaunanoordin/zooniverse-startwords/blob/master/section-07.html</a>
⩩&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;⟩
</div>
<p>Since we’re only interested in creating a functional on-screen keyboard, we only modified the CSS direction of the text input field. On the other hand, if you’re creating, for example, a whole website that supports both LTR and RTL languages, then you need to be conscientious about the layout of your entire website, and whether that layout needs to be flipped along the horizontal axis to make sense to RTL readers.</p>
<p><em>Fun(?) Note: mixing LTR text with RTL text can lead to extremely confusing UI interactions. For example, in the text input field below, using your mouse, try to highlight the word APPLE plus one character before it and one character after it, i.e. &ldquo;הAPPLEן&rdquo;. Good luck!</em></p>
<input id="tricky-text-selector" type="text" value="הגדלAPPLEהקטןBANANAסובב" style="font-size: 1.5em; color: #666; width:80%; margin: 0 auto; display: block;">
<p><label for="tricky-text-selector" class="sr-only">Tricky text selector</label></p>
<div class="txt-only">
⩩&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;⟩
| INTERACTIVE COMPONENT.
| SOURCE CODE: <a href="https://github.com/shaunanoordin/zooniverse-startwords/blob/master/index.html">https://github.com/shaunanoordin/zooniverse-startwords/blob/master/index.html</a>
⩩&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;⟩
</div>
</div>

</div>
<h3 id="creating-clickable-keyboards">Creating clickable keyboards</h3>
<p>With the basic functionality of the clickable keyboards in place, we wanted to consider how we might further expand this resource for the context of <em>Scribes of the Cairo Geniza</em>. To support volunteers in the paleographic elements of transcribing Geniza fragments written in Hebrew script (again, the vast majority of the corpus), Penn team member Laura Newman Eckstein created a series of twenty script-based Hebrew “Alephbets” to be used as interchangeable skins on the clickable keyboard, to complement the modern Hebrew keyboard modeled after the <em>Ancient Lives</em> approach.</p>
<p>





















<figure ><img loading="lazy" alt="A chart showing square, minuscule, and cursive Hebrew character examples." src="/issues/2/strangers-in-the-landscape/images/04_alephbet.png"
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset="/issues/2/strangers-in-the-landscape/images/04_alephbet_hu4722e4fda57175f589f054ac216c609b_399528_500x0_resize_box_3.png 500w,
    /issues/2/strangers-in-the-landscape/images/04_alephbet_hu4722e4fda57175f589f054ac216c609b_399528_800x0_resize_box_3.png 800w,/issues/2/strangers-in-the-landscape/images/04_alephbet_hu4722e4fda57175f589f054ac216c609b_399528_1200x0_resize_box_3.png 1200w,/issues/2/strangers-in-the-landscape/images/04_alephbet_hu4722e4fda57175f589f054ac216c609b_399528_1500x0_resize_box_3.png 1500w,/issues/2/strangers-in-the-landscape/images/04_alephbet_hu4722e4fda57175f589f054ac216c609b_399528_1800x0_resize_box_3.png 1800w,/issues/2/strangers-in-the-landscape/images/04_alephbet.png 2000w" 
     class="landscape"
     ><figcaption>
        <p>The “Alephbets” chart which formed the basis of the interchangeable keyboard skins, created for <em>Scribes of the Cairo Geniza</em> by Laura Newman Eckstein. Downloadable via <a href="https://github.com/judaicadh/cairogeniza/tree/master/_docs/Eckstein%20Alephbet%20Chart">GitHub</a>.
        </p>
    </figcaption>
</figure>
<div class="txt-only">
⩩&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;⟩
| FIGURE. A chart showing square, minuscule, and cursive Hebrew character examples.
|
| CAPTION: The “Alephbets” chart which formed the basis of the interchangeable keyboard skins, created for Scribes of the Cairo Geniza by Laura Newman Eckstein. Downloadable via GitHub: <a href="https://github.com/judaicadh/cairogeniza/tree/master/_docs/Eckstein%20Alephbet%20Chart">https://github.com/judaicadh/cairogeniza/tree/master/_docs/Eckstein%20Alephbet%20Chart</a>.
⩩&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;⟩
</div></p>
<p>Because of the variation in the way that individual characters are composed across the variety of hands in the Geniza, these skins are essential to helping nonexpert transcribers feel more confident submitting a transcription. Users can view alternate ways of writing a particular character, and choose the keyboard that most closely matches the script type of the fragment they’re currently transcribing. The option to return to modern characters is always available, too.</p>
<p>





















<figure ><img loading="lazy" alt="A text input box with keyboard displaying handwritten Hebrew script." src="/issues/2/strangers-in-the-landscape/images/05_hebrew-keyboard-interface.png"
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset="/issues/2/strangers-in-the-landscape/images/05_hebrew-keyboard-interface_hu16bf5c95fb3d3dcec7326973c6e93e83_814086_500x0_resize_box_3.png 500w,
    /issues/2/strangers-in-the-landscape/images/05_hebrew-keyboard-interface_hu16bf5c95fb3d3dcec7326973c6e93e83_814086_800x0_resize_box_3.png 800w,/issues/2/strangers-in-the-landscape/images/05_hebrew-keyboard-interface_hu16bf5c95fb3d3dcec7326973c6e93e83_814086_1200x0_resize_box_3.png 1200w,/issues/2/strangers-in-the-landscape/images/05_hebrew-keyboard-interface_hu16bf5c95fb3d3dcec7326973c6e93e83_814086_1500x0_resize_box_3.png 1500w,/issues/2/strangers-in-the-landscape/images/05_hebrew-keyboard-interface.png 1518w" 
     class="landscape"
     ><figcaption>
        <p>The <em>Scribes of the Cairo Geniza</em> transcription modal, including the Hebrew keyboard, showing the Sephardi Square script type.
        </p>
    </figcaption>
</figure>
<div class="txt-only">
⩩&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;⟩
| FIGURE. A text input box with keyboard displaying handwritten Hebrew script.
|
| CAPTION: The Scribes of the Cairo Geniza transcription modal, including the Hebrew keyboard, showing the Sephardi Square script type.
⩩&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;⟩
</div></p>
<p>This resource not only boosts confidence for transcribers, it also allows them to engage with paleographic concepts in a way that meets them at their level, whatever that may be. Users can look at the full list of scripts available and learn how to distinguish between square, cursive, and minuscule scripts. They can learn the names of Hebrew characters. Regional variations on scripts may inspire transcribers to think more closely about how or why writing might differ across physical space. This resource allows people to engage deeply with primary source materials without judging their level of expertise. It tells them it’s okay to be wrong. It invites participants in and encourages budding curiosity to bloom.</p>
<div class="interlude force-page-break">
<div class="center">
<h2 id="visual-script-references">Visual Script References</h2>
<h3 id="08-keys-with-visual-script-references">08. Keys with Visual Script References</h3>
<p>Now that we’ve proven that it’s possible to map different key input to characters from different languages, we need to solve another problem. Our users will be looking at <strong>handwritten manuscripts</strong> from different regions and different eras, so it’ll be very useful if they can have a <strong>visual reference</strong> for the different kind of <strong>scripts (handwritten text)</strong> available.</p>
<p>Fortunately, this is a fairly straightforward matter of adding images—for each character, from various scripts—to our visual keyboard.</p>
<p>In our example below, we’ve added the “Yemenite Square” visual script reference for the Hebrew keyboard.</p>
<iframe title="Keyboard with Script Images" id="kb-s08" src="/issues/2/strangers-in-the-landscape/zooniverse-interludes/section-08.html"></iframe>
<div class="txt-only">
⩩&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;⟩
| INTERACTIVE COMPONENT.
| SOURCE CODE: <a href="https://github.com/shaunanoordin/zooniverse-startwords/blob/master/section-08.html">https://github.com/shaunanoordin/zooniverse-startwords/blob/master/section-08.html</a>
⩩&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;⟩
</div>
<p>The actual hard work comes in two parts. First, it requires a human hand to create the reference image JPEG for each style of script, and to ensure it has a consistent layout. Second, there&rsquo;s a one-off upfront development cost to map the visuals to the data. We found that this early investment is well worth it when we get into the next section.</p>
<p><em>For our project, we decided to put every character of the “Yemenite Square” Hebrew script into a single image file (i.e. as opposed to having dozens of image files, one for each character) and used a CSS technique called “image sprites” to separate each character when needed. For example, when we want to show the ‘Alef’ א character (top row, right-most column) we tell the code to “crop” the image at x=440px y=0px width=50px height=50px.</em></p>
<figure ><img loading="lazy" alt="A chart showing individual cropped Hebrew characters in Yemenite Square script." src="/issues/2/strangers-in-the-landscape/images/yemenite-square.jpg"
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset="/issues/2/strangers-in-the-landscape/images/yemenite-square_hu003a4498ca4049b3f0267a10ce0b2dbe_105492_500x0_resize_q75_box.jpg 500w,
    /issues/2/strangers-in-the-landscape/images/yemenite-square_hu003a4498ca4049b3f0267a10ce0b2dbe_105492_800x0_resize_q75_box.jpg 800w,/issues/2/strangers-in-the-landscape/images/yemenite-square.jpg 490w" 
     class="landscape"
     ><figcaption>
        <p>Visual Hebrew script reference for Yemenite Square.
        </p>
    </figcaption>
</figure>
<div class="txt-only">
⩩&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;⟩
| FIGURE. A chart showing individual cropped Hebrew characters in Yemenite Square script.
|
| CAPTION: Visual Hebrew script reference for Yemenite Square.
⩩&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;⟩
</div>
</div>

</div>
<h2 id="research-development-and-volunteer-advocacy">Research Development and Volunteer Advocacy</h2>
<p>The process of designing and building <em>Scribes of the Cairo Geniza</em> required a deeply human-centered approach to ensure we could meet the original project goals of transcribing the Geniza corpus and providing a space for anyone to engage with Geniza materials, no matter their level of expertise. To achieve this, we considered the range of experience our users might have, and included scaffolding in the project to ensure that there were multiple pathways to participation (e.g. the Sorting workflow, transcription with aid from on-screen keyboards).</p>
<p>In this essay, we’ve discussed the interpersonal challenges of collaborating across disciplines, and the technical challenges of designing and building resources for a range of users. The final piece to discuss is the challenge of balancing engagement and outcome—in particular, identifying where the opportunities exist in this process to advocate for a positive user experience from our positions of power as builders and project leads, and considering what sort of impact that advocacy can have on the project’s outcomes.</p>

<blockquote class="pull left">
    Crowdsourcing is never a case of building a project and letting volunteers come to you. Scribes has succeeded in attracting a broad volunteer base because we built the project intentionally, with them in mind.
</blockquote>
<p>Whether we’re discussing workflows, networks of communication, data pipelines, or design processes, the individual components of public crowdsourcing projects cannot exist independently from the project as a whole. We don’t think about design as separate from data, because these pieces are inextricably linked; project data influences design, which then impacts data output. Every decision we make during the design phase will impact various other pieces of a project beyond those directly affected in that moment. Choosing to build for a broad audience instead of restricting the project to those with previous experience will have an impact on the results. It will also increase the amount of labor involved in creating the project.</p>
<div class="interlude">
<div class="center">
<h3 id="09-multiple-visual-script-references">09. Multiple Visual Script References</h3>
<p>There are several advantages to organising our &ldquo;Yemenite Square&rdquo; Hebrew script into a single image file. Smaller downloads for our users is one, but more importantly, its consistent visual layout allows us to use it as a template to quickly deploy <strong>multiple visual scripts.</strong></p>
<p>In the example below, you’ll see that we’ve added <strong>six new Hebrew scripts,</strong> and if you check the code, doing so only required six additional lines of code.</p>
<iframe title="Keyboard with Multiple Script Images" id="kb-s09" src="/issues/2/strangers-in-the-landscape/zooniverse-interludes/section-09.html"></iframe>
<div class="txt-only">
⩩&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;⟩
| INTERACTIVE COMPONENT.
| SOURCE CODE: <a href="https://github.com/shaunanoordin/zooniverse-startwords/blob/master/section-09.html">https://github.com/shaunanoordin/zooniverse-startwords/blob/master/section-09.html</a>
⩩&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;⟩
</div>
<p>While it’s now trivial to add new scripts from a code perspective, please remember that it still takes a considerable amount of effort to create each individual script’s JPEG. (So developers, please remember to thank the people who’ve been scanning the manuscripts, manually identifying the handwritten characters, and putting them into a nice image file for us.)</p>
<p><em>Below, you can see three different Hebrew scripts that we used. You’ll note that while we made an effort to keep the visual layout, character position, and character size consistent across every style of script, some scripts are missing certain characters. For example, both Maghrebi Cursive and Byzantine Miniscule don’t have a visual reference for the “elongated Kaf” ך character. In these cases, we simply didn’t have a visual reference from the source.</em></p>
<figure ><img loading="lazy" alt="A chart showing individual cropped Hebrew characters in Yemenite Square script." src="/issues/2/strangers-in-the-landscape/images/yemenite-square.jpg"
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset="/issues/2/strangers-in-the-landscape/images/yemenite-square_hu003a4498ca4049b3f0267a10ce0b2dbe_105492_500x0_resize_q75_box.jpg 500w,
    /issues/2/strangers-in-the-landscape/images/yemenite-square_hu003a4498ca4049b3f0267a10ce0b2dbe_105492_800x0_resize_q75_box.jpg 800w,/issues/2/strangers-in-the-landscape/images/yemenite-square.jpg 490w" 
     class="landscape"
     ><figcaption>
        <p>Visual Hebrew script reference for Yemenite Square.
        </p>
    </figcaption>
</figure>
<div class="txt-only">
⩩&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;⟩
| FIGURE. A chart showing individual cropped Hebrew characters in Yemenite Square script.
|
| CAPTION: Visual Hebrew script reference for Yemenite Square.
⩩&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;⟩
</div>
<figure ><img loading="lazy" alt="A chart showing individual cropped Hebrew characters in Byzantine Minuscule script." src="/issues/2/strangers-in-the-landscape/images/byzantine-minuscule.jpg"
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset="/issues/2/strangers-in-the-landscape/images/byzantine-minuscule_huf5affd40beb4bacf65ccfdae4f80429e_149192_500x0_resize_q75_box.jpg 500w,
    /issues/2/strangers-in-the-landscape/images/byzantine-minuscule_huf5affd40beb4bacf65ccfdae4f80429e_149192_800x0_resize_q75_box.jpg 800w,/issues/2/strangers-in-the-landscape/images/byzantine-minuscule.jpg 490w" 
     class="landscape"
     ><figcaption>
        <p>Visual Hebrew script reference for Byzantine Minuscule.
        </p>
    </figcaption>
</figure>
<div class="txt-only">
⩩&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;⟩
| FIGURE. A chart showing individual cropped Hebrew characters in Byzantine Minuscule script.
|
| CAPTION: Visual Hebrew script reference for Byzantine Minuscule
⩩&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;⟩
</div>
<figure ><img loading="lazy" alt="A chart showing individual cropped Hebrew characters in Maghrebi Cursive script." src="/issues/2/strangers-in-the-landscape/images/maghrebi-cursive.jpg"
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset="/issues/2/strangers-in-the-landscape/images/maghrebi-cursive_hu4757435849cfdceaa42c44e572993365_106152_500x0_resize_q75_box.jpg 500w,
    /issues/2/strangers-in-the-landscape/images/maghrebi-cursive_hu4757435849cfdceaa42c44e572993365_106152_800x0_resize_q75_box.jpg 800w,/issues/2/strangers-in-the-landscape/images/maghrebi-cursive.jpg 490w" 
     class="landscape"
     ><figcaption>
        <p>Visual Hebrew script reference for Maghrebi Cursive.
        </p>
    </figcaption>
</figure>
<div class="txt-only">
⩩&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;⟩
| FIGURE. A chart showing individual cropped Hebrew characters in Maghrebi Cursive script.
|
| CAPTION: Visual Hebrew script reference for Maghrebi Cursive.
⩩&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;⟩
</div>
</div>

</div>
<p>In the case of <em>Scribes</em>, creating the Sorting workflow was not part of the original project goals. Including the workflow meant that there would be another large set of project results, in addition to the transcription data being generated, that the Penn team would need to manage. It also meant that our team would have to consider how best to move data from the Sorting workflow into the appropriate Transcription workflows based on how the data was classified. Yes, this choice has resulted in more work for all of us, but it is also by far the most popular workflow on the project, with more than 325,000 classifications generated since <em>Scribes</em> launched in August 2017.</p>

<blockquote class="pull right">
    An early review of the Sorting workflow data showed that for a majority of the fragments, volunteers were in one hundred percent agreement about which category best represented the scripts being used in the fragment (Hebrew, Arabic, both, no text).
</blockquote>
<p>The Sorting workflow and the clickable keyboards are both examples of how creating projects that are truly catered to nonspecialists requires teams to actually include public engagement as a goal and priority, instead of allowing it to be a secondary outcome to data generation. This prioritization requires serious time and effort. In particular, it requires a rejection of the common narrative around crowdsourcing as being a way to save time and energy, or a good option for under-resourced institutions who don’t have staff time to process data. Crowdsourcing is never a case of building a project and letting volunteers come to you. <em>Scribes</em> has succeeded in attracting a broad volunteer base because we built the project intentionally, with them in mind.</p>
<p>Paleography and manuscript transcription have traditionally been the purview of specialists, only accessible to those with institutional access and the skills to be trusted with fragile physical resources. By opening up a complex task to a broad, nonspecialist audience through collaborative, human-centered design, <em>Scribes</em> says to the public, “We trust you, we appreciate your help, and we worked hard to create a space that will support you.” We ended up with a space that “strangers” to the field could explore without feeling lost.</p>
<p>And it worked. An early review of the Sorting workflow data showed that for a majority of the fragments, volunteers were in one hundred percent agreement about which category best represented the scripts being used in the fragment (Hebrew, Arabic, both, no text). As Penn team member Emily Esten notes in a blog post about these results, “That’s impressive, considering the range of expertise from our volunteer base. For volunteers who had no experience at all, this means your best guess contributed to the community of knowledge and was, more likely than not, in agreement with others.”<sup id="fnref:18"><a href="#fn:18" class="footnote-ref" role="doc-noteref">18</a></sup> For public crowdsourcing projects, this is the best possible outcome: useful results created by a community of volunteers who don’t feel like they need special credentials to take part, and who can then see their collective effort taking shape as a meaningful contribution to research. From “strangers in a landscape” to makers themselves.</p>
<section class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1" role="doc-endnote">
<p>Catherine D’Ignazio and Lauren F. Klein, <em>Data Feminism (Cambridge: MIT Press, 2020)</em>, 133.&#160;<a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:2" role="doc-endnote">
<p>We use “platform maintainers” in a capacious sense, encompassing all of the various skill sets and backgrounds that team members can bring to a successful digital humanities collaboration. The authors of this piece (core Zooniverse team members who worked on the Scribes of the Cairo Geniza front-end interface) have professional backgrounds in manuscript studies/digital humanities research, front-end development (x 2), and UX design, respectively.&#160;<a href="#fnref:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:3" role="doc-endnote">
<p><a href="https://www.zooniverse.org">Zooniverse</a> is the world’s largest platform for online crowdsourced research, often referred to as “citizen science” or “citizen research.” More than 2.3 million volunteers have registered on the platform since its founding in 2009. Zooniverse volunteers have collectively contributed more than 625 million classifications to over 350 projects, the results of which have been used in more than two hundred peer-reviewed publications.&#160;<a href="#fnref:3" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:4" role="doc-endnote">
<p>The Cairo Geniza is a corpus of hundreds of thousands of manuscript fragments, found in the Ben Ezra Synagogue of Fustat (Old Cairo). To learn about the fragments featured in <em>Scribes of the Cairo Geniza</em>, please see <a href="https://www.scribesofthecairogeniza.org/about#provenance">https://www.scribesofthecairogeniza.org/about#provenance</a>.&#160;<a href="#fnref:4" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:5" role="doc-endnote">
<p>The project is led by the University of Pennsylvania Libraries and the Zooniverse team, in collaboration with an international cohort of Geniza researchers and image-sharing partner institutions. For a full list of partners, see <a href="https://www.scribesofthecairogeniza.org/about#partners">https://www.scribesofthecairogeniza.org/about#partners</a>&#160;<a href="#fnref:5" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:6" role="doc-endnote">
<p>For more about the project goals, see Laura Newman Eckstein, “Of Scribes and Scripts: Citizen Science and the Cairo Genizah,” <em>Manuscript Studies</em> 3, no.1 (2018), 208–14; and Emily Esten and Samantha Blickhan, “Scribes of the Cairo Geniza,” in <em>Visualizing Objects, Places, and Spaces: A Digital Project Handbook</em> (2021), <a href="https://doi.org/10.21428/51bee781.0afc1687">https://doi.org/10.21428/51bee781.0afc1687</a>.&#160;<a href="#fnref:6" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:7" role="doc-endnote">
<p>IMLS award number LG-71-16-0028-16. For an overview of the project goals, see Victoria Van Hyning, Samantha Blickhan, Laura Trouille, and Chris Lintott,  “Transforming Libraries and Archives Through Crowdsourcing,” <em>D-Lib Magazine</em> 23, nos. 5/6 (2017), <a href="https://doi.org/10.1045/may2017-vanhyning">https://doi.org/10.1045/may2017-vanhyning</a>.&#160;<a href="#fnref:7" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:8" role="doc-endnote">
<p><em>Scribes</em> also features a clickable modern Arabic keyboard, but this piece will focus on creating the Hebrew keyboards since the majority of the fragments in the project thus far are written in Hebrew.&#160;<a href="#fnref:8" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:9" role="doc-endnote">
<p>Bill Endres, &ldquo;A Literacy of Building: Making in the Digital Humanities,&rdquo; in <em>Making Things and Drawing Boundaries: Experiments in the Digital Humanities</em>, ed. Jentery Sayers (Minneapolis: University of Minnesota Press, 2017), 44.&#160;<a href="#fnref:9" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:10" role="doc-endnote">
<p>For further detail on the <em>Ancient Lives</em> project, see <a href="https://zooniverseancientlives.wordpress.com/">https://zooniverseancientlives.wordpress.com/</a>.&#160;<a href="#fnref:10" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:11" role="doc-endnote">
<p>A 2019 blog post by Emily Esten examines the languages found in the project so far, through an analysis of hashtags used in the project’s ‘Talk’ message boards. “#DataDeep Dive: Scripts &amp; Languages of the Geniza,” <em>Judaica DH at the Penn Libraries</em>, April 23, 2019,  <a href="https://medium.com/@judaicadh/datadeepdive-scripts-languages-of-the-geniza-22c64504d009">https://medium.com/@judaicadh/datadeepdive-scripts-languages-of-the-geniza-22c64504d009</a>.&#160;<a href="#fnref:11" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:12" role="doc-endnote">
<p>Many definitions of crowdsourcing in digital humanities include language that includes “meaningful” participation as a prerequisite. See, for example, Mia Ridge et al., <em>The Collective Wisdom Handbook: Perspectives on Crowdsourcing in Cultural Heritage</em> (2021), <a href="https://britishlibrary.pubpub.org/;">https://britishlibrary.pubpub.org/;</a> Mia Ridge, ed., <em>Crowdsourcing Our Cultural Heritage</em> (Farnham: Ashgate Publishing, 2014).&#160;<a href="#fnref:12" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:13" role="doc-endnote">
<p>A full list of the initial questions (as well as a few that didn’t make the cut) is available, along with additional discussion around the creation of the Sorting phase, in Eckstein, “Of Scribes and Scripts.”&#160;<a href="#fnref:13" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:14" role="doc-endnote">
<p>This breakdown would later become the basis for user-facing resources in the project, including the Tutorial, Help Text, and Field Guide.&#160;<a href="#fnref:14" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:15" role="doc-endnote">
<p>“Scope creep” refers to the way that projects will often gradually expand while under construction, as ongoing design and development work leads to new ideas that were not included in the original scope (or, crucially, the budget).&#160;<a href="#fnref:15" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:16" role="doc-endnote">
<p>The Flesch-Kinkaid scale is a metric used to determine the difficulty of English-language writing. The Flesch-Kinkaid resource our team used for this project was <a href="https://goodcalculators.com/flesch-kincaid-calculator/">https://goodcalculators.com/flesch-kincaid-calculator/</a>.&#160;<a href="#fnref:16" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:17" role="doc-endnote">
<p>A full explanation of Zooniverse text transcription data aggregation practices is available in Samantha Blickhan et al., “Individual vs. Collaborative Methods of Crowdsourced Transcription,” in “Collecting, Preserving, and Disseminating Endangered Cultural Heritage for New Understandings through Multilingual Approaches,” eds. Amel Fraisse, Ronald Jenn, and Shelley Fisher Fishkin, special issue, <em>Journal of Data Mining and Digital Humanities</em> (2019), <a href="https://doi.org/10.46298/jdmdh.5759">https://doi.org/10.46298/jdmdh.5759</a>. “Zooniverse projects all follow the same general format: each item in a project, be it an image, audio or video file, is independently assessed by multiple individuals. The responses are then aggregated together for ‘consensus’ (typically majority rule).” Blickhan et. al, “Individual vs. Collaborative Methods,” 2.&#160;<a href="#fnref:17" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:18" role="doc-endnote">
<p>Emily Esten, “Reviewing Sorting Phase Data: Hebrew or Arabic Script?” <em>Judaica DH at the Penn Libraries</em> (blog), March 22, 2019, <a href="https://medium.com/@judaicadh/reviewing-phase-1-data-hebrew-or-arabic-script-a8ad3316fcbe">https://medium.com/@judaicadh/reviewing-phase-1-data-hebrew-or-arabic-script-a8ad3316fcbe</a>.&#160;<a href="#fnref:18" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</section>
]]></content></entry><entry><title type="html">Data Beyond Vision</title><link href="https://startwords.cdh.princeton.edu/issues/1/data-beyond-vision/?utm_source=atom_feed" rel="alternate" type="text/html"/><link href="https://startwords.cdh.princeton.edu/issues/1/modeling-howto/?utm_source=atom_feed" rel="related" type="text/html" title="Print a Model of the Shakespeare and Company Lending Library Membership"/><link href="https://startwords.cdh.princeton.edu/issues/1/stacking-howto/?utm_source=atom_feed" rel="related" type="text/html" title="Stack Shakespeare and Company Membership Activities"/><link href="https://startwords.cdh.princeton.edu/issues/1/weaving-howto/?utm_source=atom_feed" rel="related" type="text/html" title="Weave Derrida's References"/><link href="https://startwords.cdh.princeton.edu/issues/1/weaving-as-interface/?utm_source=atom_feed" rel="related" type="text/html" title="Weaving as Interface"/><id>https://startwords.cdh.princeton.edu/issues/1/data-beyond-vision/</id><author><name>Rebecca Sutton Koeser</name></author><author><name>Gissoo Doroudian</name></author><author><name>Nick Budak</name></author><author><name>Xinyi Li</name></author><published>2020-10-01T00:00:00+00:00</published><updated>2022-02-07T13:54:19-05:00</updated><content type="html"><![CDATA[<p>How do we represent tangible objects in a visual medium? We use words, pictures, and diagrams. We describe, share, show, and fail.</p>
<p>Humanists continue to expand the range of objects they study, but the range of scholarly outputs has not seen a similar expansion. While there are movements within Digital Humanities to consider nontraditional formats, the presentation and publishing of these experimental works (such as installations and project demos) are still secondary or sidelined, where they exist at all. What would it look like to consider non-textual research outputs as first-order scholarly work? The historian David Staley suggests the terms “interpretive objects” or “humanistic objects” for creative scholarly acts that are not limited to text;<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup> Catherine D’Ignazio and Lauren Klein offer the broader term “rhetorical objects.”<sup id="fnref:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup> This kind of innovative work is carefully researched and theorized. It deserves scholarly engagement and intellectual rigor even if it does not fit into established modes of scholarly communication.</p>
<p>Academic research has a long history of textual practice and citation that we haven’t yet figured out how to adapt to non-textual scholarship. Both the <a href="https://openhumanitiesdata.metajnl.com/">Journal of Open Humanities Data</a> and the <a href="https://joss.theoj.org/">Journal of Open Source Software</a> can be seen as steps in this direction: they provide venues for the review and publication of data and software, respectively, accompanied by brief “metapapers.” But even these journals rely on transforming the content they review—data and software—into text in order to function! What are the implications if we truly expand the range of accepted scholarly outputs to include such interpretive objects as data structures, databases, software, datasets, physical objects, and augmented reality experiences? Will scholars need to become experts in all these modes, or can we find a way to become conversant in multiple forms of argumentation, as with other important scholarly theories?</p>
<p>The pieces that follow describe four different data physicalizations, which we consider to be one class of interpretive object. This is an exploration of our work as we wrestle with how to present physical objects in a non-physical medium, objects meant to be held, touched, or viewed from different angles. Not quite metapaper, manual, or manifesto — these are guides toward reading and thinking in creative new scholarly modes.<sup id="fnref:3"><a href="#fn:3" class="footnote-ref" role="doc-noteref">3</a></sup></p>
<div id="interlude">
<div class="left">
<p><strong>SEE</strong></p>
<p>from a distance.<br>
Cold, commanding.<br>
Sense of mastery,<br>
but optical illusions deceive.</p>
<p>Look in a mirror.<br>
and see yourself<br>
seeing.</p>
</div>
<div class="right">
<p><strong>TOUCH</strong></p>
<p>up close.<br>
Intimate, incomplete.<br>
Explore partial knowledge,<br>
enlighten slowly.</p>
<p>Run fingers across skin<br>
and touch yourself<br>
touching.</p>
</div>

</div>
<p>Data physicalization represents data in physical form.<sup id="fnref:4"><a href="#fn:4" class="footnote-ref" role="doc-noteref">4</a></sup> Like other approaches to understanding and representing data, it highlights particular senses to communicate information, specifically touch and sight.<sup id="fnref:5"><a href="#fn:5" class="footnote-ref" role="doc-noteref">5</a></sup> But data physicalization is distinct from other sensory approaches in that it bridges the gap between creative, physical, and conceptual exploration, a nexus often associated with critical making.<sup id="fnref:6"><a href="#fn:6" class="footnote-ref" role="doc-noteref">6</a></sup> Data physicalizations surface the amount of labor involved with data production and representation; they lend data different perspectives and dimensions.<sup id="fnref:7"><a href="#fn:7" class="footnote-ref" role="doc-noteref">7</a></sup> These physicalizations also create an opportunity for viewers to become active participants in the making of a piece using data.</p>
<p>Data physicalization attempts to defamiliarize us from the many two-dimensional data representations we have seen by literally placing data in the <em>mise en scène</em> of a conceptual exploration. There is something unique about turning data points into physical forms and placing them in space, something that triggers the mind to understand data in a distinctive way.</p>
















<figure aria-describedby="conceptmap-desc" ><img loading="lazy" alt="Diagram defining the relationships between various data representations and the senses they incorporate; content available in description" src="/issues/1/data-beyond-vision/images/conceptmap.svg" role="img"><figcaption>
        <p>Concept map situating data physicalization in relation to other types of data representations and interpretations. Revised from the concept map included in the poster presented by the authors at DH2019 in Utrecht. Rebecca Sutton Koeser, Nick Budak, Gissoo Doroudian, and Xinyi Li, “Data Beyond Vision” (poster, DH2019, Utrecht, Netherlands, July 11, 2019).
        </p>
    </figcaption>
</figure>
<div class="txt-only">
⩩&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;⟩
| FIGURE.
|
| CAPTION: Concept map situating data physicalization in relation to other types of data representations and interpretations. Revised from the concept map included in the poster presented by the authors at DH2019 in Utrecht.
| ATTRIBUTION: Koeser, Rebecca Sutton, Nick Budak, Gissoo Doroudian, and Xinyi Li. “Data Beyond Vision,” July 11, 2019.
| LINK: <a href="https://doi.org/10.5281/zenodo.3261531">https://doi.org/10.5281/zenodo.3261531</a>
⩩&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;⟩
</div>
<div class="sr-only" id="conceptmap-desc">
<p>Other approaches for data representation and interpretation include:</p>
<ul>
<li>Data Visualization, which focuses on storytelling by using graphical elements</li>
<li>Data Edibilization, which focuses on experiencing data through food using edible materials</li>
<li>Data Sonification, which focuses on auditory patterns by using sound</li>
<li>Data Visceralization, which focuses on physical and emotional experience by using multiple senses and affect, making it the only approach that emphasizes emotion.</li>
<li>Data Art, which focuses on representing links between data and artistic creations by using expressive frameworks and raw data.</li>
<li>Interpretive object, which focuses on revealing meanings and relationships via non-textual forms by using metaphors.</li>
</ul>

</div>
<p>There is an ethics of drawing on other senses. Feminist philosopher Donna Haraway describes “visualizing technologies” as the “god trick of seeing everything from nowhere.”<sup id="fnref:8"><a href="#fn:8" class="footnote-ref" role="doc-noteref">8</a></sup> Klein and D’Ignazio expand on this, demonstrating that the assumed neutrality and objectivity of even the simplest visualizations always come from a particular perspective, usually a dominant cultural view that fundamentally excludes and marginalizes.<sup id="fnref:9"><a href="#fn:9" class="footnote-ref" role="doc-noteref">9</a></sup></p>
<p>This is especially the case when making data visualizations accessible to vision-impaired readers. The typical solution is to provide a table with the data underlying the chart or graph. This isn’t practical for large datasets, and it’s clearly not the same experience; otherwise, we would provide the tabular data to all users. Another approach is to provide an extended description sharing the insights gained from the chart.<sup id="fnref:10"><a href="#fn:10" class="footnote-ref" role="doc-noteref">10</a></sup> This is helpful, but pre-digesting the chart in this way doesn’t allow readers to perceive and interpret the patterns and draw their own conclusions. Tactile data physicalizations provide sensory forms that offer individuals the opportunity to explore and discover patterns in the data for themselves.</p>
<p>Approaching an object like a data physicalization on display encourages bodily engagement in physical space. It encourages the person encountering it to consider multiple angles and perspectives, and it should raise questions about how the objects are meant to be read. This touching requires proximity and a certain intimacy.<sup id="fnref:11"><a href="#fn:11" class="footnote-ref" role="doc-noteref">11</a></sup> For Emmanuel Levinas, the “ocularcentrism” of western civilization has produced a false sense that vision is synonymous with objectivity; he proposes instead the metaphor of touch as the basis for ethical engagement with the Other. Ocularcentrism requires distance or separation and encourages objectification and mastery of that which is viewed.<sup id="fnref:12"><a href="#fn:12" class="footnote-ref" role="doc-noteref">12</a></sup> French feminist philosopher Luce Irigaray extends this metaphor in her notion of the “caress,” which “weds without consum(mat)ing.”<sup id="fnref:13"><a href="#fn:13" class="footnote-ref" role="doc-noteref">13</a></sup> Because touch requires intimacy, boundaries, and consent, it offers connection without the taint of mastery.<sup id="fnref:14"><a href="#fn:14" class="footnote-ref" role="doc-noteref">14</a></sup></p>
<hr>
<p>These are not artist statements because this is not art; these objects might look like Data Art, but the goals and methods are different. This is representation, correspondence, laborious translation. These are our attempts to communicate our goals, to help you to <em>read</em> and interpret these unfamiliar objects, and to be challenged by the potential of physicalization.</p>
<p>We invite you to participate in the embodiment and visible labor of data work. Download the following models and instructions, use your hands to recreate the data physicalizations we developed, or use them as inspiration to make your own interpretive objects. If you make any of these physicalizations, please share them on social media with the hashtag <a href="https://twitter.com/search?q=(%23DataBeyondVision)">#DataBeyondVision</a>.</p>
<div class="icon-nav">
<span class="help">Choose an object</span>
<a href="#folding"><img src="images/icon-folding.svg" alt="read folding section"></a>
<a href="#modeling"><img src="images/icon-printing.svg" alt="read modeling section"></a>
<a href="#weaving"><img src="images/icon-weaving.svg" alt="read weaving section"></a>
<a href="#stacking"><img src="images/icon-stacking.svg" alt="read stacking section"></a>
</div>
<h2 id="folding">Folding in the Lesser Known Members of the Shakespeare and Company Lending Library</h2>
<p><em>Nick Budak, Xinyi Li</em></p>
<h3 id="goal">Goal</h3>
<p>The Shakespeare and Company lending library is best known for its famous members — writers such as Gertrude Stein, James Joyce, Ernest Hemingway, Aimé Césaire, and Simone de Beauvoir. We wanted to highlight the activity of the relatively unknown members — many of them women — who in fact represent a much larger portion of the library&rsquo;s day-to-day activity and thus arguably better represent it than do the prominent names. This piece makes use of unit origami to create a larger, cohesive form from small folded units, mirroring the relationship between the overall membership of the library and a single member.<sup id="fnref:15"><a href="#fn:15" class="footnote-ref" role="doc-noteref">15</a></sup></p>






















<figure ><img loading="lazy" alt="Folded origami model of a green cube intersecting a white octahedron covered with printed text." src="/issues/1/data-beyond-vision/images/folding-installation-photo.jpg"
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset="/issues/1/data-beyond-vision/images/folding-installation-photo_hue8cc9d37f77dd4cd10109019f3675f97_9534334_500x0_resize_q75_box.jpg 500w,
    /issues/1/data-beyond-vision/images/folding-installation-photo_hue8cc9d37f77dd4cd10109019f3675f97_9534334_800x0_resize_q75_box.jpg 800w,/issues/1/data-beyond-vision/images/folding-installation-photo_hue8cc9d37f77dd4cd10109019f3675f97_9534334_1200x0_resize_q75_box.jpg 1200w,/issues/1/data-beyond-vision/images/folding-installation-photo_hue8cc9d37f77dd4cd10109019f3675f97_9534334_1500x0_resize_q75_box.jpg 1500w,/issues/1/data-beyond-vision/images/folding-installation-photo_hue8cc9d37f77dd4cd10109019f3675f97_9534334_1800x0_resize_q75_box.jpg 1800w,/issues/1/data-beyond-vision/images/folding-installation-photo.jpg 5472w" 
     class="landscape"
     ><figcaption>
        <p>Completed piece on display at the Center for Digital Humanities, with early drafts visible in background.
        </p>
    </figcaption>
</figure>
<div class="txt-only">
⩩&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;⟩
| FIGURE. Folded origami model of a green cube intersecting a white octahedron covered with printed text.
|
| CAPTION: Completed piece on display at the Center for Digital Humanities, with early drafts visible in background.
| ATTRIBUTION: Photo by Shelley Szwast.
⩩&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;⟩
</div>
<h3 id="description">Description</h3>
<p>The physicalization contrasts the activity of the better known members of the lending library — those linked by researchers to an entry in the <a href="https://viaf.org/">Virtual International Authority File</a> (VIAF)<sup id="fnref:16"><a href="#fn:16" class="footnote-ref" role="doc-noteref">16</a></sup> — with the activity of relatively unknown members with no known authority record.<sup id="fnref:17"><a href="#fn:17" class="footnote-ref" role="doc-noteref">17</a></sup> Activity is represented by the total number of borrowing events that would plausibly have brought members into the library, namely checking out and returning books. Names of the lesser known members are printed on the paper used to create the octahedron as a way of corporealizing and “re-humanizing” humanities data.<sup id="fnref:18"><a href="#fn:18" class="footnote-ref" role="doc-noteref">18</a></sup> By holding the physicalization in two different ways, the user can “grasp” two separate sets of data: the octahedron (non-famous members) and the cube (famous members). The ratio of the volumes of these two solids reflects the use of the library by these two different groups.<sup id="fnref:19"><a href="#fn:19" class="footnote-ref" role="doc-noteref">19</a></sup></p>
<p>
<div class="sketchfab-embed-wrapper">
    <iframe
        id="sketchfab-9c96fadd27c34a11902f0a1281ea0ab4"
        aria-label="Two different still images of the model rotated in the 3D viewer, emphasizing the two shapes combined in the object: the cube and the octahedron."
        frameborder="0"
        allow="autoplay; fullscreen; vr"
        mozallowfullscreen="true"
        webkitallowfullscreen="true"
        loading="lazy"
        src="https://sketchfab.com/models/9c96fadd27c34a11902f0a1281ea0ab4/embed?autospin=0.2&amp;autostart=0&amp;camera=0&amp;preload=1&amp;ui_controls=1&amp;ui_infos=1&amp;ui_inspector=1&amp;ui_stop=1&amp;ui_watermark=1&amp;ui_watermark_link=1">
    </iframe>
    
    
</div>

<div class="txt-only">
⩩&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;⟩
| FIGURE. 3-D model of a green cube intersecting a white octahedron covered with printed text.
⩩&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;⟩
</div></p>
<h3 id="insights">Insights</h3>
















<figure aria-describedby="pie-desc" ><img loading="lazy" alt="A pie chart with a 70% majority section labeled “no VIAF” in green, with the remainder labeled “VIAF”." style="max-height: 300px" src="/issues/1/data-beyond-vision/images/folding_viaf_pie.svg" role="img"><figcaption>
        <p>A pie chart representing the proportions of members with and without VIAF identification.
        </p>
    </figcaption>
</figure>
<div class="txt-only">
⩩&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;⟩
| FIGURE. A pie chart with a 70% majority section labeled “no VIAF” in green, with the remainder labeled “VIAF”.
|
| CAPTION: A pie chart representing the proportions of members with and without VIAF identification.
⩩&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;⟩
</div>
<div class="sr-only" id="pie-desc">
The majority section of the pie chart represents the 14,583 library members who we identified as “lesser known” because they are not listed in VIAF. The minority section represents the 6,248 members who are listed in VIAF, often because they were involved with a well-known creative work.
</div>
<p>A pie chart can be used to present the same ratio of data conveyed in the physicalization; this representation is useful when we want to illustrate a situation where we know the totality of the data. Pie charts also depict a world where data fit neatly into mutually exclusive categories. The act of grasping the two intersecting solids in our physicalization is a response to this approach: the membership data of the lending library is a work in progress, updated as researchers comb through archives that are fragmentary and incomplete. One cannot see all sides of a three-dimensional solid simultaneously. By representing our data as intersecting solids, we instead mirror the fuzzy distinction between “famous” and “non-famous” members, acknowledging the intersection of the varied identities of the library’s members.<sup id="fnref:20"><a href="#fn:20" class="footnote-ref" role="doc-noteref">20</a></sup></p>
<h3 id="next-steps">Next Steps</h3>
<p>Using cut, punched, or embossed paper would make the piece more tactile; instead of simply printing names, we could add unique patterns to represent membership and borrowing activities for individual members. In the future, we could use generative methods to create unique folding patterns for individual library member activity and make them available via print-on-demand. This would enable viewers to become participants and turn folding into an act of recovery of the stories of the lesser known library members.<sup id="fnref:21"><a href="#fn:21" class="footnote-ref" role="doc-noteref">21</a></sup></p>
<div class="icon-nav">
<span class="help">Choose a different object</span>
<a href="#modeling"><img src="images/icon-printing.svg" alt="read modeling section"></a>
<a href="#weaving"><img src="images/icon-weaving.svg" alt="read weaving section"></a>
<a href="#stacking"><img src="images/icon-stacking.svg" alt="read stacking section"></a>
</div>
<h2 id="modeling">Modeling Shakespeare and Company Library Membership</h2>
<p><em>Rebecca Sutton Koeser</em></p>
<h3 id="goal-1">Goal</h3>






















<figure ><img loading="lazy" alt="3D printed object and accompanying 3D printed labels laid out on a table; this side view shows labels for the years 1919–1942." src="/issues/1/data-beyond-vision/images/modeling-side-view.jpg"
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset="/issues/1/data-beyond-vision/images/modeling-side-view_hu5bc641453e1033078d4f48224daca5b0_4425375_500x0_resize_q75_box.jpg 500w,
    /issues/1/data-beyond-vision/images/modeling-side-view_hu5bc641453e1033078d4f48224daca5b0_4425375_800x0_resize_q75_box.jpg 800w,/issues/1/data-beyond-vision/images/modeling-side-view_hu5bc641453e1033078d4f48224daca5b0_4425375_1200x0_resize_q75_box.jpg 1200w,/issues/1/data-beyond-vision/images/modeling-side-view_hu5bc641453e1033078d4f48224daca5b0_4425375_1500x0_resize_q75_box.jpg 1500w,/issues/1/data-beyond-vision/images/modeling-side-view_hu5bc641453e1033078d4f48224daca5b0_4425375_1800x0_resize_q75_box.jpg 1800w,/issues/1/data-beyond-vision/images/modeling-side-view.jpg 3400w" 
     class="landscape"
     ><figcaption>
        <p>Side view of 3D printed lollipop chart with labels and statement.
        </p>
    </figcaption>
</figure>
<div class="txt-only">
⩩&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;⟩
| FIGURE. 3D printed object and accompanying 3D printed labels laid out on a table; this side view shows labels for the years 1919–1942.
|
| CAPTION: Side view of 3D printed lollipop chart with labels and statement.
| ATTRIBUTION: Photo by Shelley Szwast.
⩩&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;⟩
</div>
<p>This data physicalization demonstrates the affordances of three dimensions for representing data: time series data are displayed with sequential months and years adjacent to each other, which makes it easier to discern seasonal and annual trends. I hope to inspire others to try experimental approaches to representing data; writing software to generate printable 3D models directly from the data makes the process reproducible, and may eventually enable others to create and print their own physicalizations. The tactile nature of the object suggests the possibilities of 3D printing to create more accessible representations of data.</p>






















<figure ><img loading="lazy" alt="Alternating rows of white and green “lollipops” fade into the distance and out of focus, with the white data points noticeably larger in the foreground." src="/issues/1/data-beyond-vision/images/modeling-close-up.jpg"
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset="/issues/1/data-beyond-vision/images/modeling-close-up_hub2dfc5608e8305f7eaaaae3e90a5c8a5_5473478_500x0_resize_q75_box.jpg 500w,
    /issues/1/data-beyond-vision/images/modeling-close-up_hub2dfc5608e8305f7eaaaae3e90a5c8a5_5473478_800x0_resize_q75_box.jpg 800w,/issues/1/data-beyond-vision/images/modeling-close-up_hub2dfc5608e8305f7eaaaae3e90a5c8a5_5473478_1200x0_resize_q75_box.jpg 1200w,/issues/1/data-beyond-vision/images/modeling-close-up_hub2dfc5608e8305f7eaaaae3e90a5c8a5_5473478_1500x0_resize_q75_box.jpg 1500w,/issues/1/data-beyond-vision/images/modeling-close-up_hub2dfc5608e8305f7eaaaae3e90a5c8a5_5473478_1800x0_resize_q75_box.jpg 1800w,/issues/1/data-beyond-vision/images/modeling-close-up.jpg 3400w" 
     class="landscape"
     ><figcaption>
        <p>Close up of 3D printed lollipop chart with labels.
        </p>
    </figcaption>
</figure>
<div class="txt-only">
⩩&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;⟩
| FIGURE. Alternating rows of white and green “lollipops” fade into the distance and out of focus, with the white data points noticeably larger in the foreground.
|
| CAPTION: Close-up of 3D printed lollipop chart with labels.
| ATTRIBUTION: Photo by Shelley Szwast.
⩩&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;⟩
</div>
<h3 id="description-1">Description</h3>
<p>This is a two-variable, three-dimensional lollipop chart showing the membership of the Shakespeare and Company lending library and bookshop, by month and year, from November 1919 when Sylvia Beach opened her bookshop to its official closing in 1941.<sup id="fnref:22"><a href="#fn:22" class="footnote-ref" role="doc-noteref">22</a></sup> Membership data are drawn from two different sources, both of which are incomplete: broad membership information comes from <a href="https://shakespeareandco.princeton.edu/sources/logbooks/">logbooks</a> (although logbooks for 1930, parts of 1931–32, and 1937 are missing); detailed borrowing histories come from <a href="https://shakespeareandco.princeton.edu/sources/cards/">lending library cards</a> for a subset of members.<sup id="fnref:23"><a href="#fn:23" class="footnote-ref" role="doc-noteref">23</a></sup> The white octahedrons represent the number of members with an active membership in each month; the green icospheres correspond to the number of members with borrowing activity in each month.<sup id="fnref:24"><a href="#fn:24" class="footnote-ref" role="doc-noteref">24</a></sup> For any month where the value is zero, there is no lollipop. Representing the two different datasets as adjacent, half lollipops exposes the discrepancies between the stories these sources tell us about the membership of the library without privileging either of them.<sup id="fnref:25"><a href="#fn:25" class="footnote-ref" role="doc-noteref">25</a></sup> Using two different shapes makes the two parts of the physicalization distinguishable to touch. The two lollipop charts are designed to be printed independently and then assembled, so that any 3D printer can be used. In this version, the two pieces slide together; this is both a simplification and an improvement over the previous version, where one piece was placed on top of the other.<sup id="fnref:26"><a href="#fn:26" class="footnote-ref" role="doc-noteref">26</a></sup></p>
<p>
<div class="sketchfab-embed-wrapper">
    <iframe
        id="sketchfab-89985d66f7244d87b7edbe5fd6266f0d"
        aria-label="3-D model of Shakespeare and Company membership lollipop chart."
        frameborder="0"
        allow="autoplay; fullscreen; vr"
        mozallowfullscreen="true"
        webkitallowfullscreen="true"
        loading="lazy"
        src="https://sketchfab.com/models/89985d66f7244d87b7edbe5fd6266f0d/embed?autospin=0.2&amp;autostart=0&amp;camera=0&amp;preload=1&amp;ui_controls=1&amp;ui_infos=1&amp;ui_inspector=1&amp;ui_stop=1&amp;ui_watermark=1&amp;ui_watermark_link=1">
    </iframe>
    
    
    <figure class="preview">
        <img src="images/modeling-3d-alt.jpg" alt="3D printed object and accompanying 3D printed labels displayed on a table; this side view shows labels for the years 1919–1942."/>
        <figcaption><p>The online version of this essay includes an interactive 3D viewer displaying a model of this object.</p></figcaption>
    </figure>
    
</div>

<div class="txt-only">
⩩&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;⟩
| FIGURE. 3-D model of Shakespeare and Company membership lollipop chart.
⩩&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;⟩
</div></p>
<h3 id="insights-1">Insights</h3>
















<figure aria-describedby="bars-desc" ><img loading="lazy" alt="Bar chart showing members with borrowing activity and total members each month" src="/issues/1/data-beyond-vision/images/membership-book-activity-combined_1919-19411.svg" role="img"><figcaption>
        <p>Shakespeare and Company lending library members with borrowing activity and members, 1919–1941. From Kotin and Koeser, “Shakespeare and Company Lending Library Cards.”
        </p>
    </figcaption>
</figure>
<div class="txt-only">
⩩&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;⟩
| FIGURE. Bar chart showing members with borrowing activity and total members each month.
|
| CAPTION: Shakespeare and Company lending library members with borrowing activity and members, 1919–1941.
| ATTRIBUTION: Kotin and Koeser, “The Shakespeare and Company Lending Library Cards in Context.”
| LINK: <a href="http://shakespeareandco.princeton.edu/analysis/2020/03/shakespeare-and-company-lending-library-cards-context/">http://shakespeareandco.princeton.edu/analysis/2020/03/shakespeare-and-company-lending-library-cards-context/</a>
⩩&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;⟩
</div>
<div class="sr-only" id="bars-desc">
Plotting documented membership accounts against borrowing activity shows the differences in members tracked across the two sources. The Shakespeare and Company Project has information about the borrowing activity of 11% of lending library members. For the 1920s, the percentage is lower: only 6%. But in the 1930s, the percentage is higher: 23%. Some months show more members with borrowing activity than total members because information on the cards overlaps gaps in logbook coverage.
</div>
<p>The same membership data can be presented in a two-variable bar chart. Overall trends are easy to see, and both representations of the data make it possible to compare the two data series against each other. Seasonal trends are visible in the bar chart, but it’s difficult to identify distinct months; in contrast, changing perspective on the 3D lollipop chart allows us to focus on yearly or monthly trends. Missing data in one variable are visible in both, but seem more striking in the 3D version where the base of the piece is bare without any lollipop tops. At the current scale, touching the piece requires focusing attention on just a portion of the object but invites exploration, which can proceed in any direction.<sup id="fnref:27"><a href="#fn:27" class="footnote-ref" role="doc-noteref">27</a></sup> While the bar chart demands sequential reading from left to right, the 3D printed object doesn’t provide or demand a particular starting point or sequence.</p>
<p>The bar chart conveys a sense of certitude and exactness that does not reflect the missing and partial data that underlie it; the 3D printed object, with its irregularities and fragility, is more representative of the contingent, historical data.<sup id="fnref:28"><a href="#fn:28" class="footnote-ref" role="doc-noteref">28</a></sup></p>
<h3 id="next-steps-1">Next Steps</h3>
<p>The current version uses different shapes for the two variables, but adding textures would make the model even more tactile. Simple 3D printed labels with text and braille have been added for display alongside the piece, but they could be incorporated directly on the model, and refined to provide a scale for the axes.<sup id="fnref:29"><a href="#fn:29" class="footnote-ref" role="doc-noteref">29</a></sup> The 3D printed objects could also be augmented with other media: lights or sound could convey the intensity of borrowing activity, or threads connecting months could represent the number of subscription renewals and convey a sense of continuity. The Python code used to create these models could be generalized for reuse, and eventually made available as a Blender plugin.<sup id="fnref:30"><a href="#fn:30" class="footnote-ref" role="doc-noteref">30</a></sup> New shapes or approaches could be used to leverage innovations in 3D modeling, such as generative design, to create objects that are more inviting to touch and even more distinct from 2D data visualizations. 3D models could be revised for fabrication with CNC machines to create objects out of wood instead of plastic, which could make them more inviting to touch.</p>
<p><a href="/issues/1/modeling-howto/">Make one &gt;</a></p>
<div class="icon-nav">
<span class="help">Choose a different object</span>
<a href="#folding"><img src="images/icon-folding.svg" alt="read folding section"></a>
<a href="#weaving"><img src="images/icon-weaving.svg" alt="read weaving section"></a>
<a href="#stacking"><img src="images/icon-stacking.svg" alt="read stacking section"></a>
</div>
<h2 id="weaving">Weaving Derrida’s References</h2>
<blockquote>
<p>… we all of us, grave or light, get our thoughts entangled in metaphors…
<cite> George Eliot, Middlemarch</cite></p>
</blockquote>
<p><em>Rebecca Sutton Koeser, Gissoo Doroudian</em></p>
<h3 id="goal-2">Goal</h3>
<p>With this piece, we aim to literalize the metaphor of weaving as writing, embedded in the very words “textile” and “text,” by representing Derrida’s intertextuality as a woven tapestry.<sup id="fnref:31"><a href="#fn:31" class="footnote-ref" role="doc-noteref">31</a></sup> The textures of the yarn and woven fabric invite touch, but by showing an in-progress weaving with the pattern and instructions provided, we move viewers beyond seeing and touching to enable them to become participants in reconstructing the data. Showing the weaving in progress also foregrounds the labor of data work, since curation, collection, and visualization all take an enormous amount of work and skill, often from a range of different individuals.</p>
<p><div class="deepzoom" id="openseadragon-23" style="height: 10em" aria-label="Interactive zoomable viewer displaying a blue scarf with alternating bands of varied threads."></div>
<script>
    window.addEventListener("DOMContentLoaded", function() {
        OpenSeadragon({
            id: "openseadragon-23",
            prefixUrl: "https://cdn.jsdelivr.net/npm/openseadragon@2.4/build/openseadragon/images/",
            preserveViewport: true,
            visibilityRatio:    1,
            minZoomLevel:       1,
            defaultZoomLevel:   1,
            gestureSettingsMouse: { scrollToZoom: false },
            tileSources: "https:\/\/iiif.princeton.edu\/loris\/iiif\/2\/figgy_prod%2F58%2F51%2Fd4%2F5851d48b225b42699a13181c778a6095%2Fintermediate_file.jp2\/info.json",
        });
    });
</script>


<figure class="deepzoom-preview">
    <img src="images/weaving-deepzoom-alt.jpg" alt="Composite of two images from the high resolution image shown in the deep zoom viewer: one showing the full length of the woven piece, and another with a close-up showing the threads and different weaving patterns."/>
    <figcaption><p>The online version of this essay includes an interactive deep zoom viewer displaying a high resolution capture of this object.</p></figcaption>
</figure>

<div class="txt-only">
⩩&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;⟩
| FIGURE. Interactive zoomable viewer displaying a blue scarf with alternating bands of varied threads.
⩩&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;⟩
</div></p>
<h3 id="description-2">Description</h3>
<p>This weaving represents the references in Chapter 1 of Jacques Derrida’s <em>de la Grammatologie</em> (1967). The references have been cataloged and categorized by the research team of Derrida’s Margins.<sup id="fnref:32"><a href="#fn:32" class="footnote-ref" role="doc-noteref">32</a></sup> Each type of reference (epigraph, citation, quotation, footnote) is represented by a distinct yarn and weaving pattern. Derrida’s highly intertextual writing suggested the idea of weaving.<sup id="fnref:33"><a href="#fn:33" class="footnote-ref" role="doc-noteref">33</a></sup> Using yarn to symbolize the foundational work of deconstructionism, which operates by finding the place where a text unravels, gives additional depth to this physicalization.</p>
<p>Working with textiles is often stereotyped as female activity; therefore this piece also raises questions of gender and other false binaries such as art versus craft, high- versus low-tech. Based on anthropological research, women produced most of the textiles in the ancient world, but that work can be read as female authorship involved in the earliest textual practices.<sup id="fnref:34"><a href="#fn:34" class="footnote-ref" role="doc-noteref">34</a></sup> The loom itself runs the gamut from high to low technology: a backstrap loom can be assembled at home from dowels, rods, and cords; and yet, Joseph-Marie Jacquard’s 1801 power loom, which used punch cards to automatically create elaborate woven patterns, was an important precursor to early computers.</p>






















<figure ><img loading="lazy" alt="The weaver sits in front of a table top loom; one hand lifts two strand of the warp yarn, the other stretches out the yarn being looped around it." src="/issues/1/data-beyond-vision/images/weaving-soumak.jpg"
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset="/issues/1/data-beyond-vision/images/weaving-soumak_hu4c20ea29d73279e64865a8a2b7a14231_9638085_500x0_resize_q75_box.jpg 500w,
    /issues/1/data-beyond-vision/images/weaving-soumak_hu4c20ea29d73279e64865a8a2b7a14231_9638085_800x0_resize_q75_box.jpg 800w,/issues/1/data-beyond-vision/images/weaving-soumak_hu4c20ea29d73279e64865a8a2b7a14231_9638085_1200x0_resize_q75_box.jpg 1200w,/issues/1/data-beyond-vision/images/weaving-soumak_hu4c20ea29d73279e64865a8a2b7a14231_9638085_1500x0_resize_q75_box.jpg 1500w,/issues/1/data-beyond-vision/images/weaving-soumak_hu4c20ea29d73279e64865a8a2b7a14231_9638085_1800x0_resize_q75_box.jpg 1800w,/issues/1/data-beyond-vision/images/weaving-soumak.jpg 3400w" 
     class="landscape"
     ><figcaption>
        <p>Gissoo Doroudian, creating a Soumak weave.
        </p>
    </figcaption>
</figure>
<div class="txt-only">
⩩&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;⟩
| FIGURE. The weaver sits in front of a table-top loom; one hand lifts two strand of the warp yarn, the other stretches out the yarn being looped around it.
|
| CAPTION: Gissoo, creating a Soumak weave.
⩩&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;⟩
</div>
<h3 id="insights-2">Insights</h3>
<p>The data encoded in the weaving could be represented as a stacked bar chart, a familiar and easily available choice for communicating types and quantities. However, the bar chart may be the least effective for communicating the depth and conceptual nuance of data on multiple levels.</p>
















<figure aria-describedby="refs-desc" ><img loading="lazy" alt="Stacked bar chart showing number and kind of references by page." style="max-height: 500px" src="/issues/1/data-beyond-vision/images/derrida-refsbytype-chap1.svg" role="img"><figcaption>
        <p>References in Chapter 1 of <em>de la Grammatologie</em> by page and type. (Chapter 1 begins on page 15).
        </p>
    </figcaption>
</figure>
<div class="txt-only">
⩩&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;⟩
| FIGURE. Stacked bar chart showing number and kind of references by page.
|
| CAPTION: References in chapter 1 of De la grammatologie by page and type. (Chapter 1 begins on page 15).
⩩&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;⟩
</div>
<div class="sr-only" id="refs-desc">
The chart shows that quotations are the most common type of reference in Chapter 1, and a few pages include six or more quotations. Footnotes are the next most common reference; there is only one epigraph, on the first page in the chapter, and one citation, on page 35. Only six pages have no references at all, and many pages have more than one.
</div>
<p>The ability to feel the density and frequency of each type of reference, color coded above, creates a unique experience for each participant, specific to their own perspective. These organic experiences bring to light the depth and complexities of the original work as well as the labor involved with gathering this data. This woven piece, which represents the first half (thirteen pages) of the first chapter of <em>De la grammatologie</em> is thirty-seven inches long, a little more than three feet. The physical nature of this data representation required that materials and dimensions be carefully calculated and measured.<sup id="fnref:35"><a href="#fn:35" class="footnote-ref" role="doc-noteref">35</a></sup> The process of creating this piece is embodied and experiential, which naturally leads to conversations that effortlessly surface the labor of data work and the depth of the original text. Unfortunately, this is less likely to happen naturally when creating data visualizations.</p>
<h3 id="next-steps-2">Next Steps</h3>
<p>Adding conductive thread and sensors could turn the weaving into an interface, so that touching the fabric would bring up the relevant reference on an associated screen. Data weavings could also be augmented with other media, such as light and sound, to convey other aspects of the same or related data. Incorporating other work on automated weaving and knitting machines would add to the variety of options for data textiles.</p>
<p><a href="/issues/1/weaving-howto/">Make one &gt;</a></p>
<div class="icon-nav">
<span class="help">Choose a different object</span>
<a href="#folding"><img src="images/icon-folding.svg" alt="read folding section"></a>
<a href="#modeling"><img src="images/icon-printing.svg" alt="read modeling section"></a>
<a href="#stacking"><img src="images/icon-stacking.svg" alt="read stacking section"></a>
</div>
<h2 id="stacking">Stacking New and Continuing Membership Activities of the Shakespeare and Company Lending Library</h2>
<p><em>Xinyi Li</em></p>
















<figure ><img loading="lazy" alt="Animated GIF with the camera panning revealing different portions of the paper model." src="/issues/1/data-beyond-vision/images/stacking-horizontal-pan.gif"><figcaption>
        <p>Overview of a folded model representing the lending library membership activities from 1919 to 1941.
        </p>
    </figcaption>
</figure>
<div class="txt-only">
⩩&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;⟩
| FIGURE. Animated GIF with the camera panning revealing different portions of the paper model.
|
| CAPTION: Overview of a folded model representing the lending library membership activities from 1919 to 1941.
⩩&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;⟩
</div>
<h3 id="goal-3">Goal</h3>
<p>This piece aims to reveal the continuity and growth of Sylvia Beach’s lending library and bookshop by showing the extent of activity and recorded membership based on logbooks and lending library cards. Multiple variables are encoded in the dimensions of stacking boxes based on the technique of pop-up box folds. By exhibiting the evolution of the library over time while contrasting activities of new and old members, this piece enables multiple ways to compare and interpret the data. By transforming a flat surface to a three-dimensional form with play of light and shadows, this production technique serves as a metaphor for the larger purpose of the <a href="https://shakespeareandco.princeton.edu/">Shakespeare and Company Project</a> — bringing archival data to life and facilitating rich interpretations.</p>






















<figure ><img loading="lazy" alt="Textual labels overlaying a 3d rendering of a unit of the folded model along its three directions." src="/issues/1/data-beyond-vision/images/stacking-photo-legend.png"
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset="/issues/1/data-beyond-vision/images/stacking-photo-legend_hu82654c780d94fbe639e7d55a501ef41b_40394428_500x0_resize_box_3.png 500w,
    /issues/1/data-beyond-vision/images/stacking-photo-legend_hu82654c780d94fbe639e7d55a501ef41b_40394428_800x0_resize_box_3.png 800w,/issues/1/data-beyond-vision/images/stacking-photo-legend_hu82654c780d94fbe639e7d55a501ef41b_40394428_1200x0_resize_box_3.png 1200w,/issues/1/data-beyond-vision/images/stacking-photo-legend_hu82654c780d94fbe639e7d55a501ef41b_40394428_1500x0_resize_box_3.png 1500w,/issues/1/data-beyond-vision/images/stacking-photo-legend_hu82654c780d94fbe639e7d55a501ef41b_40394428_1800x0_resize_box_3.png 1800w,/issues/1/data-beyond-vision/images/stacking-photo-legend.png 6980w" 
     class="landscape"
     ><figcaption>
        <p>Legend showing how to read the information represented in three dimensions.
        </p>
    </figcaption>
</figure>
<div class="txt-only">
⩩&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;⟩
| FIGURE. Textual labels overlaying a 3D rendering of a unit of the folded model along its three directions.
|
| CAPTION: Legend showing how to read the information represented in three dimensions.
⩩&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;⟩
</div>
<h3 id="description-3">Description</h3>
<p>Shakespeare and Company Project lending library membership data from 1919 to 1941 are represented as a hybrid of time-series and stacked bar charts showing part-to-whole relationships made from paper and folding. Each unit, a cuboid in space and sometimes its stacking child, represents one year and displays nine variables for that year. The height corresponds to the number of active members recorded in the <a href="https://shakespeareandco.princeton.edu/sources/logbooks/">logbooks</a>; the depth depicts the number of members with borrowing activity, according to each member’s <a href="https://shakespeareandco.princeton.edu/sources/cards/">lending library card</a>; the length along the timeline is based on the total number of borrowing events.<sup id="fnref:36"><a href="#fn:36" class="footnote-ref" role="doc-noteref">36</a></sup> Each of the variables is split into two parts: previous members who have renewed a membership contrasted with new members. The upper portion shows the growth and the activities of new readers. Viewers can see the rise and fall of members, inspect the difference between members with borrowing activity and the members as represented in the logbooks, compare the growth over time by viewing the stacking part from the front, and survey the involvement of continuing members versus new members, to name a few possibilities. In some cases, a small number of new members were very active readers based on their borrowing activity.</p>
<p>
<div class="sketchfab-embed-wrapper">
    <iframe
        id="sketchfab-96403a4659414537b470f03da96d7a88"
        aria-label="3D model showing a folded long paper as base, with opened cuts folded into additional panels."
        frameborder="0"
        allow="autoplay; fullscreen; vr"
        mozallowfullscreen="true"
        webkitallowfullscreen="true"
        loading="lazy"
        src="https://sketchfab.com/models/96403a4659414537b470f03da96d7a88/embed?autospin=0.2&amp;autostart=0&amp;camera=0&amp;preload=1&amp;ui_controls=1&amp;ui_infos=1&amp;ui_inspector=1&amp;ui_stop=1&amp;ui_watermark=1&amp;ui_watermark_link=1">
    </iframe>
    
    
    <figure class="preview">
        <img src="images/stacking-3d-alt.jpg" alt="Three photos from multiple angles showing a folded long paper as base, with opened cuts folded into additional panels."/>
        <figcaption><p>The online version of this essay includes an interactive 3D viewer displaying a model of this object.</p></figcaption>
    </figure>
    
</div>

<div class="txt-only">
⩩&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;⟩
| FIGURE. 3D model showing a folded long paper as base, with opened cuts folded into additional panels.
⩩&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;⟩
</div></p>
<p>This physicalization made use of kirigami technique, which transforms single sheets of paper into three-dimensional forms. Data was mapped to the shapes with <a href="http://data-illustrator.com/">Data Illustrator</a>, semi-manual calculation, and vector drawing. The materiality and the process have a poetic connection to the subject matter, metaphorically: stories and knowledge can be embedded on flat papers, but the act of reading unfolds the surface into interpretive space even beyond three dimensions.</p>
<h3 id="insights-3">Insights</h3>
















<figure aria-describedby="stackedbar-desc" ><img loading="lazy" alt="A series of stacked bar charts comparing the number of members, numbers of borrowers, and borrowing events, and the portion of new and renewed members among each of these categories." src="/issues/1/data-beyond-vision/images/2d-stacked-bar.svg" role="img"><figcaption>
        <p>Membership activities of the Shakespeare and Company lending library from 1919 to 1941 represented as stacked bar charts.
        </p>
    </figcaption>
</figure>
<div class="txt-only">
⩩&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;⟩
| FIGURE. A series of stacked bar charts comparing the number of members, numbers of borrowers, and borrowing events, and the portion of new and renewed members among each of these categories.
|
| CAPTION: Membership activities of the Shakespeare and Company Lending Library from 1919 to 194 represented as stacked bar charts.
⩩&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;⟩
</div>
<div class="sr-only" id="stackedbar-desc">
Members with borrowing events constitute a fraction of all the members in the earlier years. The overall number of borrowing events increases gradually from 1919 to 1926, drops off slightly, then evidently increases from 1934 to 1939, even though the number of members drops drastically after 1929. It’s not easy to compare book borrowing by new members across the years.
</div>
<p>With current off-the-shelf visualization tools like the ones that come with Google Sheets, these three data series can generate three separate stacked bar charts. Since the numbers have different ranges, the vertical axes are drawn in different scales, which makes comparison across series impossible. The aggregate version presented here required manual adjustment to combine the separated charts and to make the Y axes comparable. In this 2D version, various activities of the growing membership body are not linked, and it’s difficult to draw connections between active members and the intensity of their activities because spatially these bars are not adjacent to each other. In the conventional pie charts, although the part-whole relationship between new membership activity and all activity is apparent, comparing across the three types of activities is not possible.</p>
















<figure aria-describedby="pieseries-desc" ><img loading="lazy" alt="A series of pie charts comparing the number of members, numbers of borrowers, borrowing events, and the portion of new and renewed members among each of these categories." src="/issues/1/data-beyond-vision/images/2d-pie.svg" role="img"><figcaption>
        <p>Membership activities of the Shakespeare and Company lending library between 1919 and 1941 represented as pie charts.
        </p>
    </figcaption>
</figure>
<div class="txt-only">
⩩&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;⟩
| FIGURE. A series of pie charts comparing the number of members, numbers of borrowers, borrowing events, and the portion of new and renewed members among each of these categories.
|
| CAPTION: Membership activities of the Shakespeare and Company lending library between 1919 and 1941 represented as pie charts.
⩩&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;⟩
</div>
<div class="sr-only" id="pieseries-desc">
Overall, renewed members outsize new members before 1929, followed by five years with nearly two times more new members than renewed members. Members with borrowing events represent a fraction of all the members in the early years between 1919 and 1929. Then members with borrowing events grow and become more comparable to the size of all members, which sizes down drastically after 1929. Borrows from new members outsize renewed members since 1934. It is not easy to compare the proportion of growth across the years.
</div>
<p>Extending into physical space allows data to be encoded in three axes and provides multiple possible angles to view the piece, depending on the relationships one is interested in. Different angles can reveal new interactions between logbook members, members with lending library card activities, and borrowing events. The separation of renewing and new members makes it possible to juxtapose and compare activities between the two groups of members. Spatial factors communicate different facets of the data, and color coding is no longer required.</p>
<p>Throughout the process of developing this project as practice-based research, making and reflecting are in constant oscillation, and knowing happens in actions. As I worked through this piece and observed the artifact, new questions emerged: how do we measure the level of liveliness of the lending library? Is it by the number of members or by the number of borrowing events? Instead of drawing comparisons by the lengths along each axis, perhaps perhaps we might look at the vibrancy of the lending library in a different way: through the volumes and relative sizes of the cuboids and rectangles, which factor in both the number of members and the borrowing activity.</p>
<h3 id="next-steps-3">Next Steps</h3>
<p>The pattern generation process is very programming-friendly and the materials required are also easily accessible. The data encoding process could be automated by custom code, which could then be made available as a tool for presenting part-to-whole relationships in other datasets. With the addition of dynamic media such as projection mapping, this piece could convey more context and narratives around the lending library.</p>
<p><a href="/issues/1/stacking-howto/">Make one &gt;</a></p>
<div class="icon-nav">
<span class="help">Choose a different object</span>
<a href="#folding"><img src="images/icon-folding.svg" alt="read folding section"></a>
<a href="#modeling"><img src="images/icon-printing.svg" alt="read modeling section"></a>
<a href="#weaving"><img src="images/icon-weaving.svg" alt="read weaving section"></a>
</div>
<h2 id="acknowledgments">Acknowledgments</h2>
<p>Photos of the data physicalizations on display and Gissoo Doroudian weaving are by Shelley Szwast. The high resolution capture of the data weaving used for the deep zoom and margin image was created by the Digital Imaging Studio, Princeton University Library. The photo of the CDH main space with empty tables is by Mana Winters. The custom visuals for this essay were created by Doroudian; the icons for each section were created by Doroudian and revised by Doroudian and Xinyi Li. All other photos, charts, and models were created by the authors.</p>
<p>Thanks to our collaborators on the <a href="https://shakespeareandco.princeton.edu/about/credits/">Shakespeare and Company Project team</a> and <a href="https://derridas-margins.princeton.edu/credits/">Derrida’s Margins project team</a> for their work to create the data we have experimented with and physicalized here; to the <a href="http://ach2019.ach.org/cfp-call-for-participation-en/">ACH2019 conference organizers for the generous CFP</a> with the option of installations, which led in part to this work; and to the <a href="https://cdh.princeton.edu/">Center for Digital Humanities at Princeton</a> and our colleagues there for the tremendous support and encouragement for this project. Special thanks to our colleagues at Princeton University Library, Meghan Testerman and Annette Jushchuk, for participating in a weaving exhibition test run and giving us feedback to improve the instructions.</p>
<section class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1" role="doc-endnote">
<p>David Staley, “On the ‘Maker Turn’ in the Humanities,” in <em>Making Things and Drawing Boundaries: Experiments in the Digital Humanities</em>, ed. Jentery Sayers (Minneapolis: University of Minnesota Press, 2017), 32–41, <a href="https://doi.org/10.5749/j.ctt1pwt6wq.5">https://doi.org/10.5749/j.ctt1pwt6wq.5</a>.&#160;<a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:2" role="doc-endnote">
<p>“Any communicating object that reflects choices about the selection and representation of reality is a rhetorical object.” Catherine D’Ignazio and Lauren F. Klein, <em>Data Feminism</em> (Cambridge: MIT Press, 2020), 78.&#160;<a href="#fnref:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:3" role="doc-endnote">
<p>These pieces are based on statements—partly inspired by artist statements—that were included as part of the “Data Beyond Vision” installation presented at the ACH2019 conference. However, we have considerably expanded and adapted them, moving beyond that format. Rebecca Sutton Koeser, Nick Budak, Gissoo Doroudian, and Xinyi Li, “Data Beyond Vision” (installation, ACH2019, Pittsburgh, PA, July 25, 2019).&#160;<a href="#fnref:3" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:4" role="doc-endnote">
<p>The term “data physicalization” can be understood in three ways: as a “physical artifact whose geometry or material properties encode data”; as the process of giving physical form to data; or, as the research area combining data visualization and tangible user interfaces.  See Yvonne Jansen, Pierre Dragicevic, Petra Isenberg, Jason Alexander, Abhijit Karnik, Johan Kildal, Sriram Subramanian, and Kasper Hornbæk, “Opportunities and Challenges for Data Physicalization,” in <em>CHI ’15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems</em> (April 2015), 3227–36, <a href="https://doi.org/10.1145/2702123.2702180">https://doi.org/10.1145/2702123.2702180</a>.&#160;<a href="#fnref:4" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:5" role="doc-endnote">
<p>To get a better sense of the variety and historic range of data physicalizations, browse a gallery of physical visualizations and related artifacts at <a href="http://dataphys.org/list/gallery/">http://dataphys.org/list/gallery/</a>.&#160;<a href="#fnref:5" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:6" role="doc-endnote">
<p>Read more about “Critical Making”, which was coined by Matt Ratto, at <a href="https://criticalmaking.com/matt-ratto/">https://criticalmaking.com/matt-ratto/</a>.&#160;<a href="#fnref:6" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:7" role="doc-endnote">
<p>This work is strongly aligned with the principles of data feminism—in particular, elevating emotion and embodiment; considering context; and making labor visible. D’Ignazio and Klein, <em>Data Feminism</em>, 17–18.&#160;<a href="#fnref:7" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:8" role="doc-endnote">
<p>Donna Haraway, &ldquo;Situated Knowledges: The Science Question in Feminism and the Privilege of Partial Perspective,&rdquo; <em>Feminist Studies</em> 14, no. 3 (Autumn 1988): 581. <a href="https://doi.org/10.2307/3178066">https://doi.org/10.2307/3178066</a>.&#160;<a href="#fnref:8" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:9" role="doc-endnote">
<p>D’Ignazio and Klein, <em>Data Feminism</em>, 76.&#160;<a href="#fnref:9" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:10" role="doc-endnote">
<p>We’re trying out this approach on research partnership projects we’ve worked on at the Center for Digital Humanities at Princeton. Read the <a href="https://github.com/princeton-cdh/mep-django/issues/404">GitHub issue where we discussed the implementation</a>, the <a href="https://www.sarasoueidan.com/blog/accessible-data-charts-for-khan-academy-2018-annual-report/">article that inspired our approach</a>, and an example of it in use in a <a href="https://prosody.princeton.edu/editorial/2020/01/visualizing-collections/">Princeton Prosody Archive Editorial essay</a>. The journal you are now reading also experiments with this approach. See the <a href="https://github.com/Princeton-CDH/startwords/pull/95">GitHub pull request</a> where we discussed a plain text caption and alt-text schema.&#160;<a href="#fnref:10" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:11" role="doc-endnote">
<p>The difficulty and unfamiliarity of this intimacy may be demonstrated in part by our experience with displaying these objects. We often have to encourage and reassure people that they are allowed to touch these items, even though there are signs clearly posted inviting just that.&#160;<a href="#fnref:11" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:12" role="doc-endnote">
<p>&ldquo;Mastery&rdquo; is a problematic term, as African Americans and members of other marginalized groups know well, and as the racial unrest in the United States this summer has made White Americans more aware. Klein and D’Ignazio also point out that the term has a gendered component as well, with the master stereotype associated with men across many Western cultures. <em>Data Feminism,</em> 77. For a discussion of “master” and its unfortunate use in technology, see “Toward anti-racist technical terminology,” Association for Computers and the Humanities (ACH), accessed October 22, 2020, <a href="https://ach.org/toward-anti-racist-technical-terminology/">https://ach.org/toward-anti-racist-technical-terminology/</a>&#160;<a href="#fnref:12" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:13" role="doc-endnote">
<p>“Levinas is one of few philosophers to displace the metaphor of vision dominating ontological accounts of intersubjectivity into a metaphor of touch … which resonates with Irigaray’s own reformulation of subject-object relations in the figure of the two lips.” Ince, Kate Ince, “Questions to Luce Irigaray,” <em>Hypatia</em> 11, no. 2 (1996): 122–40, <a href="http://www.jstor.org/stable/3810267">http://www.jstor.org/stable/3810267</a>&#160;<a href="#fnref:13" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:14" role="doc-endnote">
<p>“This gesture . . . which weds without consum(mat)ing .. may be called: the touch of the caress. . . . This touch binds and unbinds two others in a flesh that is still and always untouched by mastery.” Luce Irigaray, <em>An Ethics of Sexual Difference</em>, trans. Carolyn Burke and Gillian C. Gill (Ithaca: Cornell Press, 1993), 186.&#160;<a href="#fnref:14" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:15" role="doc-endnote">
<p>This technique, also called “modular origami,” uses separate sheets folded into repeated interlocking small forms. The practice is attested as early as the eighteenth century, but gained popularity in the 1960s with the work of Robert Neale in the United States and Mitsunobu Sonobe in Japan. Our model uses forms from Tomoko Fuse’s book, <em>Unit Origami: Multidimensional Transformations</em> (Tokyo: Japan Publications, 1990).&#160;<a href="#fnref:15" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:16" role="doc-endnote">
<p>VIAF aggregates records from multiple national libraries with authoritative names for people, organizations, and titles. Typically only people associated with published works, such as authors and translators, have records in VIAF; we used this as a proxy for some degree of fame, even though there are plenty of names in VIAF that are not strictly famous.&#160;<a href="#fnref:16" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:17" role="doc-endnote">
<p>This work is based on pre-release versions of the datasets now published as: Joshua Kotin, Rebecca Sutton Koeser, Carl Adair, Serena Alagappan, Jean Bauer, Oliver J. Browne, Nick Budak, Harriet Calver, Jin Chow, Ian Davis, Gissoo Doroudian, Currie Engel, Elspeth Green, Benjamin Hicks, Madeleine E. Joelson, Carolyn Kelly, Sara Krolewski, Xinyi Li, Ellie Maag, Cate Mahoney, Jesse D. McCarthy, Mary Naydan, Isabel Ruehl, Sylvie Thode, Camey VanSant, and Clifford E. Wulfman, <em>Shakespeare and Company Project Dataset: Lending Library Members, Books, Events</em>, version 1.0, July 2020, distributed by DataSpace, Princeton University, <a href="https://doi.org/10.34770/pe9w-x904">https://doi.org/10.34770/pe9w-x904</a>. For more information, see <a href="https://shakespeareandco.princeton.edu/about/data/">https://shakespeareandco.princeton.edu/about/data/</a>&#160;<a href="#fnref:17" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:18" role="doc-endnote">
<p>This is inspired in part by ethical principles from the Colored Conventions Project, which asks researchers using their data to “contextualize and narrate the conditions of the people who appear as ‘data’ and to name them when possible.” “Introduction to CCP Corpus,” Colored Conventions Project, accessed October 22, 2020, <a href="https://coloredconventions.org/about-records/ccp-corpus/">https://coloredconventions.org/about-records/ccp-corpus/</a>.&#160;<a href="#fnref:18" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:19" role="doc-endnote">
<p>We wanted to include a 3D model of this physicalization in order to provide some semblance of virtually grasping and rotating the object. Because we didn’t have a way to capture the actual object in 3D, we created a model of it in <a href="https://www.blender.org/">Blender</a>; this was fairly straightforward, since it consists of two simple shapes.&#160;<a href="#fnref:19" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:20" role="doc-endnote">
<p>For more on the strengths and weaknesses of the pie chart, see Steve Johnson, “The Case Against Pie Charts,” University of Utah Health, March 3, 2017, <a href="https://accelerate.uofuhealth.utah.edu/connect/steves-dojo-7-the-case-against-pie-charts">https://accelerate.uofuhealth.utah.edu/connect/steves-dojo-7-the-case-against-pie-charts</a>.&#160;<a href="#fnref:20" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:21" role="doc-endnote">
<p>We do not provide a how-to for this object out of respect for the copyright of origami authors, who often spend years developing and refining single designs. The three-dimensional forms used to make this piece are a combination of two modular origami units which are the original creations of the brilliant Tomoko Fuse, and can be found in her book <em>Unit Origami</em>. The octahedron is formed from eight units with triangular windows, and these windows are filled with eight so-called E-b units that create the illusion of an intersecting cube. Fuse, <em>Multidimensional Origami,</em> 109, 233. When assembling from your own paper, you can print <a href="https://startwords.cdh.princeton.edu/issues/1/data-beyond-vision/non_viaf_names.pdf">a document containing the names of the non-VIAF members of the library</a> onto the paper before folding the octahedron. Sheets of 8.5 inch x 11 inch copy paper can become difficult to manipulate when folded many times; thinner paper is easier to work with.&#160;<a href="#fnref:21" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:22" role="doc-endnote">
<p>A <a href="https://datavizproject.com/data-type/lollipop-chart/">lollipop chart</a> is a bar chart variant that uses dots to mark the values. Earlier prototypes of this model were based on bar charts, but I discovered that the space between bars in a lollipop chart made it easier to “read” the 3D version, since the thinner vertical supports obscure less of the model visually.&#160;<a href="#fnref:22" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:23" role="doc-endnote">
<p>This work is based on pre-release versions of the <a href="https://shakespeareandco.princeton.edu/about/data/">datasets now available</a>. Kotin et al., <em>Shakespeare and Company Project Dataset: Lending Library Members, Books, Events.</em>&#160;<a href="#fnref:23" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:24" role="doc-endnote">
<p>We use white and green in our physicalizations of data from the Shakespeare and Company Project because green is the most iconic color used in the site design. <img src="images/scp_colors_dark.png" alt="Color palette from Shakespeare and company project.">&#160;<a href="#fnref:24" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:25" role="doc-endnote">
<p>To better understand the Shakespeare and Company Project sources, see Shakespeare and Company Project, “Lending Library Cards,” Center for Digital Humanities, Princeton University, November 20, 2019, <a href="https://shakespeareandco.princeton.edu/sources/cards/">https://shakespeareandco.princeton.edu/sources/cards/</a>; and Shakespeare and Company Project, “Logbooks,” Center for Digital Humanities, Princeton University, November 20, 2019, <a href="https://shakespeareandco.princeton.edu/sources/logbooks/">https://shakespeareandco.princeton.edu/sources/logbooks/</a>. To understand how the Project data from those sources fit together, read Joshua Kotin and Rebecca Sutton Koeser, “The Shakespeare and Company Lending Library Cards in Context,” Shakespeare and Company Project, Center for Digital Humanities, Princeton University. March 9, 2020, <a href="http://shakespeareandco.princeton.edu/analysis/2020/03/shakespeare-and-company-lending-library-cards-context/">http://shakespeareandco.princeton.edu/analysis/2020/03/shakespeare-and-company-lending-library-cards-context/</a>.&#160;<a href="#fnref:25" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:26" role="doc-endnote">
<p>The previous version was more complicated to print; the overlapping framework interfered with small data points, and the tightly interlocking parts did not scale well. <img src="images/modeling-ach2019-side-view.jpg" alt="Side view of early model version draft for ACH 2019 conference."> <img src="images/modeling-ach2019-top-view.jpg" alt="Top view of early model version draft for ACH 2019 conference.">&#160;<a href="#fnref:26" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:27" role="doc-endnote">
<p>Due to COVID-19, I’m writing and revising this from my home office without physical access to the object in question. I find myself closing my eyes and extending my fingers to focus on my memories of touching the object.&#160;<a href="#fnref:27" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:28" role="doc-endnote">
<p>For an exploration of the subjectivity, uncertainty, and interpretation implicit in data, read <a href="https://startwords.cdh.princeton.edu/issues/1/their-data-ourselves/">Rebecca Munson’s essay</a> in this issue of <em>Startwords</em>. For an overview of common techniques for representing uncertainty visually, see Nathan Yau, “Visualizing the Uncertainty in Data,” <em>FlowingData</em> (blog), January 8, 2018, <a href="https://flowingdata.com/2018/01/08/visualizing-the-uncertainty-in-data/">https://flowingdata.com/2018/01/08/visualizing-the-uncertainty-in-data/</a>. For more on the difficulty people have in recognizing uncertainty in data visualization, see D’Ignazio and Klein on “Visceralizing Uncertainty” in <em>Data Feminism</em>, 88.&#160;<a href="#fnref:28" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:29" role="doc-endnote">
<p>These have not yet been tested by anyone who reads braille.&#160;<a href="#fnref:29" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:30" role="doc-endnote">
<p><a href="https://www.blender.org/">Blender</a> is an open-source 3D modeling creation suite which includes a Python API. I experimented with multiple other solutions for generating 3D models programmatically, including <a href="https://www.openscad.org/">OpenSCAD</a> and <a href="https://github.com/dbrgn/tangible">Tangible</a>, but found they were too limited and couldn’t handle a model of the size and complexity I needed to generate for this dataset, so I eventually settled on Blender and Python. The Blender interface makes it possible to view and modify models generated from code, there is <a href="https://docs.blender.org/api/current/">documentation for the Python API</a>, and I found many helpful answers on <a href="https://blender.stackexchange.com/">Blender Stack Exchange</a>.&#160;<a href="#fnref:30" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:31" role="doc-endnote">
<p>The word “text” comes from Latin <em>textus,</em> literally “thing woven” and from the verb <em>texere,</em> “to weave.” According to Kathryn Sullivan Kruger, “the connection between weaving (textiles) and language (texts) becomes so entangled as to be almost impossible to separate. In many languages, including English, the verb to weave defines not just the making of textiles, but any creative act.” Kathryn Sullivan Kruger, <em>Weaving the Word: The Metaphorics of Weaving and Female Textual Production</em> (Cranbury, NJ: Rosemont Publishing &amp; Printing, 2001), 29. To play on one of Derrida’s most famous statements, “<em>il n&rsquo;y a pas de hors-textile.</em>”&#160;<a href="#fnref:31" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:32" role="doc-endnote">
<p>See the <em>Derrida&rsquo;s Margins</em> project at <a href="https://derridas-margins.princeton.edu/">https://derridas-margins.princeton.edu/</a>. Kate Chenoweth et al., “References in Jacques Derrida&rsquo;s <em>de la Grammatologie</em>,” September 10, 2018, Figshare, <a href="https://doi.org/10.6084/m9.figshare.7180448.v1">https://doi.org/10.6084/m9.figshare.7180448.v1</a>.&#160;<a href="#fnref:32" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:33" role="doc-endnote">
<p>For a deeper exploration of textile metaphors in Derrida’s work, see Caroline Rooney’s “Deconstruction and Weaving” in <em>Deconstructions: A User&rsquo;s Guide,</em> ed. Nicholas Royle (London: Palgrave, 2000), <a href="https://doi.org/10.1007/978-1-137-06095-2_14">https://doi.org/10.1007/978-1-137-06095-2_14</a>.&#160;<a href="#fnref:33" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:34" role="doc-endnote">
<p>See Kruger, <em>Weaving the Word,</em> 21, 34, 136.&#160;<a href="#fnref:34" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:35" role="doc-endnote">
<p>When we first did the math on the weaving and measured, we discovered that doing all of Chapter 1 would require a warp longer than three tables end-to-end in the CDH main space, which is why we scaled back to just half of the chapter. <img src="images/cdh-empty-tables.jpg" alt="read of empty tables in main space at CDH.">&#160;<a href="#fnref:35" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:36" role="doc-endnote">
<p>This work is based on pre-release versions of the <a href="https://shakespeareandco.princeton.edu/about/data/">datasets now available</a>. Kotin et al., <em>Shakespeare and Company Project Dataset: Lending Library Members, Books, Events.</em>&#160;<a href="#fnref:36" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</section>]]></content></entry><entry><title type="html">Print a Model of the Shakespeare and Company Lending Library Membership</title><link href="https://startwords.cdh.princeton.edu/issues/1/modeling-howto/?utm_source=atom_feed" rel="alternate" type="text/html"/><link href="https://startwords.cdh.princeton.edu/issues/1/stacking-howto/?utm_source=atom_feed" rel="related" type="text/html" title="Stack Shakespeare and Company Membership Activities"/><link href="https://startwords.cdh.princeton.edu/issues/1/weaving-howto/?utm_source=atom_feed" rel="related" type="text/html" title="Weave Derrida's References"/><link href="https://startwords.cdh.princeton.edu/issues/1/data-beyond-vision/?utm_source=atom_feed" rel="related" type="text/html" title="Data Beyond Vision"/><link href="https://startwords.cdh.princeton.edu/issues/1/weaving-as-interface/?utm_source=atom_feed" rel="related" type="text/html" title="Weaving as Interface"/><id>https://startwords.cdh.princeton.edu/issues/1/modeling-howto/</id><author><name>Rebecca Sutton Koeser</name></author><published>2020-10-01T00:00:00+00:00</published><updated>2022-02-07T13:54:19-05:00</updated><content type="html"><![CDATA[<p>





















<figure ><img loading="lazy" alt="Alternating rows of white and green “lollipops” fade into the distance and out of focus, with the white data points noticeably larger in the foreground." src="/issues/1/modeling-howto/images/modeling-close-up.jpg"
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset="/issues/1/modeling-howto/images/modeling-close-up_hub2dfc5608e8305f7eaaaae3e90a5c8a5_5473478_500x0_resize_q75_box.jpg 500w,
    /issues/1/modeling-howto/images/modeling-close-up_hub2dfc5608e8305f7eaaaae3e90a5c8a5_5473478_800x0_resize_q75_box.jpg 800w,/issues/1/modeling-howto/images/modeling-close-up_hub2dfc5608e8305f7eaaaae3e90a5c8a5_5473478_1200x0_resize_q75_box.jpg 1200w,/issues/1/modeling-howto/images/modeling-close-up_hub2dfc5608e8305f7eaaaae3e90a5c8a5_5473478_1500x0_resize_q75_box.jpg 1500w,/issues/1/modeling-howto/images/modeling-close-up_hub2dfc5608e8305f7eaaaae3e90a5c8a5_5473478_1800x0_resize_q75_box.jpg 1800w,/issues/1/modeling-howto/images/modeling-close-up.jpg 3400w" 
     class="landscape"
     ><figcaption>
        <p>Close-up of 3D printed lollipop chart with labels.<span class="attribution">Photo by Shelley Szwast</span>
        </p>
    </figcaption>
</figure>
<div class="txt-only">
⩩&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;⟩
| FIGURE. Alternating rows of white and green “lollipops” fade into the distance and out of focus, with the white data points noticeably larger in the foreground.
|
| CAPTION: Close up of 3D printed lollipop chart with labels.
| ATTRIBUTION: Photo by Shelley Szwast
⩩&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;⟩
</div></p>
<p>Print a model of Shakespeare and Company lending library membership by date, as described in <a href="https://startwords.cdh.princeton.edu/issues/1/data-beyond-vision">Data Beyond Vision</a>.</p>
<p>We invite you to participate in the embodiment and visible labor of data work. Download the following models and instructions, use your hands to recreate the data physicalizations we developed, or use them as inspiration to make your own interpretive objects. If you make any of these physicalizations, please share them on social media with the hashtag <a href="https://twitter.com/search?q=(%23DataBeyondVision)">#DataBeyondVision</a>.</p>
<h2 id="tools">Tools</h2>
<ul>
<li>3D printer (single or dual filament)</li>
<li>Slicing software (e.g. <a href="https://ultimaker.com/software/ultimaker-cura">Cura</a> or <a href="https://www.simplify3d.com/">Simplify3D</a>)</li>
<li>Blade or file (for removing filament artifacts)</li>
</ul>
<h2 id="supplies">Supplies</h2>
<ul>
<li>3D printing filament in two different colors</li>
</ul>
<h2 id="steps">Steps</h2>
<ol>
<li>Download the <a href="DataBeyondVision-lollipop-members-3Dprint.zip">zip file with 3D models</a> and extract the files.</li>
<li>Load <code>comb-lolly-cards-a.stl</code> into your slicing software and rotate and scale it so that it fits along the long dimension of your print bed. Make a note of the scale factor you use.</li>
<li>Load and slice the other three parts of the lollipop chart (<code>comb-lolly-cards-b.stl</code>, <code>comb-lolly-members-a.stl</code>, and <code>comb-lolly-members-b.stl</code>), scaling them with the same scale factor you used for the first model.</li>
<li>Print the two card models in the same color.</li>
<li>Print the two member models in the second color.</li>
<li>Clean up any printing artifacts or threads on the lollipops.</li>
<li>If you want to print labels, slice and print the appropriate set for your printer (dual filament or single). Dual print models are provided as base and text, to be combined in your slicing software.</li>
<li>Arrange the comb models and labels on a table or other display.</li>
</ol>
<h2 id="yield">Yield</h2>
<p>3D printed model of Shakespeare and Company library membership</p>
<p>
<div class="sketchfab-embed-wrapper">
    <iframe
        id="sketchfab-89985d66f7244d87b7edbe5fd6266f0d"
        aria-label="3-D model of Shakespeare and Company membership lollipop chart."
        frameborder="0"
        allow="autoplay; fullscreen; vr"
        mozallowfullscreen="true"
        webkitallowfullscreen="true"
        loading="lazy"
        src="https://sketchfab.com/models/89985d66f7244d87b7edbe5fd6266f0d/embed?autospin=0.2&amp;autostart=0&amp;camera=0&amp;preload=1&amp;ui_controls=1&amp;ui_infos=1&amp;ui_inspector=1&amp;ui_stop=1&amp;ui_watermark=1&amp;ui_watermark_link=1">
    </iframe>
    
    
    <figure class="preview">
        <img src="images/modeling-3d-alt.jpg" alt="3D printed object and accompanying 3D printed labels laid out on a table; this side view shows labels for the years, 1919–1942."/>
        <figcaption><p>The online version of this essay includes an interactive 3D viewer displaying a model of this object.</p></figcaption>
    </figure>
    
</div>

<div class="txt-only">
⩩&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;⟩
| FIGURE. 3-D model of Shakespeare and Company membership lollipop chart.
⩩&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;⟩
</div></p>
]]></content></entry><entry><title type="html">Stack Shakespeare and Company Membership Activities</title><link href="https://startwords.cdh.princeton.edu/issues/1/stacking-howto/?utm_source=atom_feed" rel="alternate" type="text/html"/><link href="https://startwords.cdh.princeton.edu/issues/1/modeling-howto/?utm_source=atom_feed" rel="related" type="text/html" title="Print a Model of the Shakespeare and Company Lending Library Membership"/><link href="https://startwords.cdh.princeton.edu/issues/1/weaving-howto/?utm_source=atom_feed" rel="related" type="text/html" title="Weave Derrida's References"/><link href="https://startwords.cdh.princeton.edu/issues/1/data-beyond-vision/?utm_source=atom_feed" rel="related" type="text/html" title="Data Beyond Vision"/><link href="https://startwords.cdh.princeton.edu/issues/1/weaving-as-interface/?utm_source=atom_feed" rel="related" type="text/html" title="Weaving as Interface"/><id>https://startwords.cdh.princeton.edu/issues/1/stacking-howto/</id><author><name>Xinyi Li</name></author><author><name>Rebecca Sutton Koeser</name></author><published>2020-10-01T00:00:00+00:00</published><updated>2022-02-07T13:54:19-05:00</updated><content type="html"><![CDATA[<p>





















<figure ><img loading="lazy" alt="A portion of a paper model against dark background with years printed on the base." src="/issues/1/stacking-howto/images/stacking-part_v2.jpg"
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset="/issues/1/stacking-howto/images/stacking-part_v2_hu1697ab991fe780752a9ac253a846b640_6198895_500x0_resize_q75_box.jpg 500w,
    /issues/1/stacking-howto/images/stacking-part_v2_hu1697ab991fe780752a9ac253a846b640_6198895_800x0_resize_q75_box.jpg 800w,/issues/1/stacking-howto/images/stacking-part_v2_hu1697ab991fe780752a9ac253a846b640_6198895_1200x0_resize_q75_box.jpg 1200w,/issues/1/stacking-howto/images/stacking-part_v2_hu1697ab991fe780752a9ac253a846b640_6198895_1500x0_resize_q75_box.jpg 1500w,/issues/1/stacking-howto/images/stacking-part_v2_hu1697ab991fe780752a9ac253a846b640_6198895_1800x0_resize_q75_box.jpg 1800w,/issues/1/stacking-howto/images/stacking-part_v2.jpg 6016w" 
     class="landscape"
     ><figcaption>
        <p>Close-up of the finished model of membership activities of the Shakespeare and Company lending library
        </p>
    </figcaption>
</figure>
<div class="txt-only">
⩩&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;⟩
| FIGURE. A partition of a paper model against dark background with years printed on the base.
|
| CAPTION: Close-up of the finished model of membership activities of Shakespeare and Company Library
⩩&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;⟩
</div></p>
<p>Create your own kirigami model of the Shakespeare and Company lending library membership activities, as described in <a href="https://startwords.cdh.princeton.edu/issues/1/data-beyond-vision">Data Beyond Vision</a>.</p>
<p>We invite you to participate in the embodiment and visible labor of data work. Download the following models and instructions, use your hands to recreate the data physicalizations we developed, or use them as inspiration to make your own interpretive objects. If you make any of these physicalizations, please share them on social media with the hashtag <a href="https://twitter.com/search?q=(%23DataBeyondVision)">#DataBeyondVision</a>.</p>
<h2 id="tools">Tools</h2>
<ul>
<li>Printer</li>
<li>X-acto knife or other blade</li>
<li>Bone folder or credit card</li>
<li>Cutting mat or a stack of scrap paper</li>
</ul>
<h2 id="supplies">Supplies</h2>
<ul>
<li>5 Sheets of cover stock paper (around 75 lb or 200 gsm; letter size is recommended, larger also works)</li>
<li>Double-sided tape (optional)</li>
</ul>
<h2 id="steps">Steps</h2>
<ol>
<li>Download <a href="stacking-chart_instructions.pdf">the PDF for the model</a></li>
<li>Print on cardstock paper at actual size</li>
<li>Cut along the vertical solid lines</li>
<li>Fold along the horizontal dotted lines. Follow the legend for mountain and valley folds.</li>
<li>Set up on a table or shelf</li>
<li>For best results, set on a table against a wall and use double-stick tape to fix to table and wall surface (optional)</li>
</ol>
<h2 id="yield">Yield</h2>
<p>kirigami model of new and continuing Shakespeare and Company library membership activities

<div class="sketchfab-embed-wrapper">
    <iframe
        id="sketchfab-96403a4659414537b470f03da96d7a88"
        aria-label="3D model showing a folded long paper as base, with opened cuts folded into additional panels."
        frameborder="0"
        allow="autoplay; fullscreen; vr"
        mozallowfullscreen="true"
        webkitallowfullscreen="true"
        loading="lazy"
        src="https://sketchfab.com/models/96403a4659414537b470f03da96d7a88/embed?autospin=0.2&amp;autostart=0&amp;camera=0&amp;preload=1&amp;ui_controls=1&amp;ui_infos=1&amp;ui_inspector=1&amp;ui_stop=1&amp;ui_watermark=1&amp;ui_watermark_link=1">
    </iframe>
    
    
    <figure class="preview">
        <img src="images/modeling-3d-alt.jpg" alt="Three photos from multiple angles showing a folded long paper as base, with opened cuts folded into additional panels."/>
        <figcaption><p>The online version of this essay includes an interactive 3D viewer displaying a model of this object.</p></figcaption>
    </figure>
    
</div>

<div class="txt-only">
⩩&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;⟩
| FIGURE. 3D model showing a folded long paper as base, with opened cuts folded into additional panels.
⩩&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;⟩
</div></p>
]]></content></entry><entry><title type="html">Their Data, Ourselves: Illness as Information</title><link href="https://startwords.cdh.princeton.edu/issues/1/their-data-ourselves/?utm_source=atom_feed" rel="alternate" type="text/html"/><id>https://startwords.cdh.princeton.edu/issues/1/their-data-ourselves/</id><author><name>Rebecca Munson</name></author><published>2020-10-01T00:00:00+00:00</published><updated>2022-02-07T13:54:19-05:00</updated><content type="html"><![CDATA[<p>When I was growing up I liked to read about dying children. I’m not talking about the Victorian orphan kind of dying, not the dying of storybooks, but children who were terminally ill.</p>
<p>I was twelve and fixated on books written by an author with the improbable name of Lurlene McDaniel. The first book I encountered was <em>Six Months to Live</em>, which chronicled the life of a popular teenager in the wake of her diagnosis with leukemia. Not all of McDaniel&rsquo;s characters had cancer; they wrestled with all kinds of chronic illnesses (cystic fibrosis, hemophilia, diabetes) as well as the untimely death of loved ones from causes including suicide. McDaniel&rsquo;s books were about grief and communities formed through crisis.</p>
<p>These books would have been perfect for a budding hypochondriac, or for a reader inclined toward purple prose and melodrama, but I read them instead for medical details, taking mental notes on how to recognize signs and symptoms and stockpiling already-outdated knowledge about treatment options. Rather than imagining myself as the sick main character, I occupied the position of the doctor, a role I planned (at the time) to take on later in real life. It turned out, though, that I would have to be the protagonist anyway.</p>
<p>I was diagnosed with Stage 4 breast cancer in January 2019. I was thirty-four at the time, with zero family history and no warning signs aside from the lump I hoped fervently would be a cyst. Immediately, I was launched into a world at once familiar and alien. I had grown up among doctors and research scientists in the orbit of Washington University School of Medicine, largely because my father is a medical ethicist with an abiding interest in the practical applications of his work. I had even worked in a research laboratory there from ages sixteen to twenty, studying&mdash;of all things&mdash;the genetics of breast cancer.</p>

<blockquote class="pull left">
    …my best chance at coping with cancer was to make sure I was a research subject, to transform my body as rapidly as possible into the right kind of data.
</blockquote>
<p>Is it any wonder, then, that I investigated my treatment options as though I were the PI on an exploratory grant rather than a cancer patient? The type of breast cancer I have (triple negative) is particularly rare and intractable. At the time of my diagnosis it had already progressed to its most advanced stage with metastases to lungs, liver, and bones. It was immediately clear that finding promising clinical trials would be my best option. My parents and I (all academics) and circle of friends (ditto) kicked into research mode, scouring databases and firing off emails to friends from conferences, people from our past, even casual acquaintances who might have a line on newer, more successful treatments. The numbers were not good. We wanted some better numbers.</p>
<p>As I made phone calls to oncologists and combed through the clinical trials database, I performed a distancing maneuver that I first began practicing when reading Lurlene McDaniel; I became a clinical observer of a diseased body, only this time it was my own. I mentally dissected it, narrowing it down to the cancerous focal points that became all that mattered. I lay repeatedly in CT and MRI machines and held my breath through biopsies with only local anesthetics, willing myself out of the body I was at the same time trying so hard to save.</p>
<p>I became at once both object and analyst, alienating my self (with her feelings about her body and her illness) from my body as a source of information about potential causes and, hopefully, potential cures. In some ways it was the extreme of Cartesian dualism—I would think as the large magnets in the MRI machine echoed all around me—that my consciousness should roam so freely while I tried my hardest not to move a muscle in order to produce as clear an image of my body as possible. I was the mind-body problem made flesh, and then abstracted from flesh into numbers that could be either parsed by a machine or interpreted by a human.</p>
<p>Where did this data sit on the spectrum of mental and physical properties? My cancer was physical but, like an electron or snippet of DNA, it was not directly observable without the aid of technologies nor communicable without the intervention of an interpreter. In each of the two trials in which I&rsquo;ve been a subject I have contributed both pieces of my body&mdash;samples of tissue to be used at the discretion of researchers&mdash;and data generated from it. Because I am a participant in clinical trials, the status of my embodied data possesses an enduring significance, since it has the potential to influence the funding and availability of future cancer therapies, even the lifespan of future patients.</p>
<p>We all agreed that my best chance at coping with cancer was to make sure I was a research subject, to transform my body as rapidly as possible into the right kind of data: not a mortality statistic but an experimental resource.</p>
<hr>
<p>Cancer is invisible and so are data.</p>
<p>Neither exists in the sense of being detectable, nameable, or identifiable until plucked from their surroundings and marked out with a significance determined by the observer. The observer marks a data point as distinctive, distinguishing the &ldquo;that&rdquo; from the &ldquo;not-that&rdquo; of everything around it. Even if a data point is meant to be representative, to stand in for a larger phenomenon, the act of selecting it renders the data point distinctive. The data you select&mdash;and the data you don&rsquo;t&mdash;say something about you as well as about them. Data are not objective phenomena. It is for this reason that digital humanities scholar Johanna Drucker has suggested that it is perhaps more accurate to think of data as <em>capta</em> to indicate their situatedness&mdash;that they are seized and, from the moment of demarcation, imbued with an interpretive viewpoint.<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup></p>
<p>The introduction of the interpretive viewpoint in medicine is called diagnosis. During the initial diagnostic phase, as I received phone call after phone call with more bad news, I spent some time thinking about how &ldquo;diagnosis&rdquo; sounded like a term familiar to me from my PhD in Renaissance literature, one that showed up mostly in discussions of tragedies: anagnorisis, meaning &ldquo;recognition,&rdquo; referring to the moment of a critical discovery about a character&rsquo;s own circumstances.</p>

<blockquote class="pull right">
    Any promise of transparency or intelligibility must be counterbalanced by the knowledge that all data have a viewpoint because they have an observer.
</blockquote>
<p>You will not recognize that you have cancer until someone tells you. You may have a suspicion that something is not quite right, but you require professional assessment. Assessment comes in the form of quantification, which requires abstraction. Your physical body is transformed into radiological images by technologies that allow trained specialists to measure and quantify, to compare averages and standard variations, and to relay that information back to you in language that leads, invariably, to another set of numbers concerned with averages and likelihoods. Where is the line between &ldquo;normal&rdquo; and &ldquo;pathological&rdquo;? In whose view is a treatment &ldquo;better&rdquo; or &ldquo;worse&rdquo;? When the questions are of life and death, it is more than a little disconcerting to realize that the answer depends very much on who you&rsquo;re asking.</p>
<p>Cancer exists before it is named, just like data. And even at its moment of detection (capture) its fixity is illusory: it is in cancer&rsquo;s nature to grow and change, just like data. The moment of visibility for both is firmly situated in time, place, and the subject position of the interpreter. Take, for example, the open question of how extensively cancer may have spread to my liver. Unusually for my age, I was actually tested for cancer in 2016, in search of answers to a years-long chronic fatigue for which I still have no good explanation. The bone marrow biopsy showed no cause for concern and even though there was a lesion on my liver, measuring 29 mm x 28 mm, the conclusion was that it was a benign growth called a hemangioma. (I stand by this view, if only because a cancerous growth on my liver, a canary in a coal mine, would have become significantly worse over the course of three years given how aggressive cancer has been elsewhere in my body in the time since my diagnosis.)</p>
<p>My first CT after diagnosis in January 2019 showed the liver lesion to be 29 mm x 35 mm, a finding that the radiologist remarked might represent growth (and therefore metastasis) or might not, since a difference of 6 mm could be caused by different positioning during the scan or different measurements by different doctors. The lesion continued to remain stable on my next CTs, but in March 2019 an additional spot was detected on the right inferior lobe, measuring 12 mm. By June 2019 that spot was reported to be 28 mm, confirming that my liver had been affected. In December the second lesion was measured under 5 mm, part of a larger pattern of regression that meant the treatment was working (which it had been doing but would not continue to do past that month). A third spot on the left lobe was recorded in three scans, showing up as 5 mm August 2019, 4 mm in September, and 3 mm in November. By December that third spot went unremarked. The large lesion from 2016, however, merely waxed and waned, never clocking in at more than 35 mm or fewer than 27 mm, numbers easily attributable to variation in imaging or interpretation.</p>
<p>So was the original liver lesion a benign hemangioma, a coincidence unrelated to the cancer that would metastasize years later, or the first sign that a breast cancer concealed in single, unmassed (and therefore undetectable) cells had already done so? Did the 2016 scan produce bad data, or rather bad capta? Was the interpretation of the image biased by the fact that I was young (thirty-one) and, aside from mysterious, debilitating fatigue, healthy? Should I have acted differently? Should my doctors? The ramifications of these questions for my diagnosis and emotional response to it are profound: a cancer that had been present since 2016 would look relatively less aggressive compared to one that was new as of 2019; being misdiagnosed and living with cancer for three years would compound my fear (and guilt) that my situation was preventable.</p>
<p>There is no way to know, though the probability is strong that the first lesion was and remains benign. But that uncertainty is the constant condition of the body as data. Any promise of transparency or intelligibility must be counterbalanced by the knowledge that all data have a viewpoint because they have an observer.</p>
<hr>
<p>In <em>The Undying</em>, her account of treatment for triple-negative breast cancer, the poet Anne Boyer writes that &ldquo;a patient is a system-containing object within a series of interlocking systems full of other system-containing objects&rdquo; and that &ldquo;to take a thing or set of things from one system and reclassify these as elements in another also resembles diagnosis, which takes information from our bodies and rearranges what came from inside of us into a system imposed from far away.”<sup id="fnref:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup> Cancer is caused by the body&rsquo;s own cells growing out of control, a hostile takeover from within that violates the rules of the system already in place. Reclassified, your own cells are a disease and your own body a weapon. Reclassified, you are not an individual but a patient and your body not a collection of sensations but a rich mine of information.</p>

<blockquote class="pull left">
    Living your life as medical data is an alienating experience particularly if, like me, you look bad on paper.
</blockquote>
<p>Once you enter the systems of modern medicine you become data to be ingested, part of the larger dataset of those who have previously been ill, been treated, and lived or died. This is not the &ldquo;violence of abstraction&rdquo; of which Marxist theorists wrote, yet the phrase seems equally applicable to the anonymity&mdash;the interchangeability&mdash;of those subsumed by the medical-industrial complex. Part of the reason that I sought clinical trials was that I felt that it was the best way to enable physicians to see me as an individual whose life, and whose treatment, mattered. I was eager to make myself an object of study and contribute to thwarting the disease that is threatening my life. But I was equally eager not to be simply tagged, processed, and swept through the prescribed (and not very promising) series of treatments that constituted the &ldquo;standard of care&rdquo; for my type of cancer.</p>
<p>Living your life as medical data is an alienating experience particularly if, like me, you look bad on paper. Boyer describes herself as &ldquo;a patient made of information, produced by the work of women,&rdquo; remarking on the &ldquo;paradoxical simultaneity&rdquo; of the care work and data work performed by the overwhelmingly female nursing staff in their interactions with patients.<sup id="fnref:3"><a href="#fn:3" class="footnote-ref" role="doc-noteref">3</a></sup> It is crucial to focus on the significance of the word &ldquo;made&rdquo; here. None of us exist as free-floating data points; medical data are <em>made</em>, are in fact <em>capta</em> that depend on nurses and technicians, radiologists and pathologists, and, perhaps most of all, on patients.</p>
<hr>
<p>Cancer is invisible, and so are viruses.</p>
<p>I have worked on this essay over the course of the COVID-19 pandemic. I began it in March 2020, days after my workplace went remote and fourteen months after my initial cancer diagnosis. It is now October 2020, my third line of treatment has failed, and I am moving on to another. The pandemic still ravages much of the country. Conceiving of bodies as &ldquo;made of information&rdquo; (and participating in the quantification of illness and the violence of abstraction that accompanies this process) has become a national way of life.</p>
<p>I have lived nearly two years tolerating the same kind of existential uncertainty and fear of an alien invader in the body that the world as a whole is now experiencing. I have played my own doctor, watching my body for signs that a treatment is working, or that it is not, in much the same way we monitor ourselves for symptoms. I have tried to anticipate what will happen if I become severely immunocompromised and have given up many of the pleasures that made my life better before (traveling, going out with friends) in the name of my health. I have offered my body up as data to research scientists with the goal of furthering not just my own treatment but survival prospects for the future.</p>
<p>I did not know that I was in training for a time when we would all of necessity be regarded as bodies with the potential to produce valuable data about the spread and effects of COVID-19. We are constantly starved for numbers, for data on infections and recoveries and for statistical models that may relieve us of the uncertainty we feel about the future. I cannot provide that. But I can tell you to be cautious readers of data and statistics that speak with any pretense to authority right now, even though I crave them too.</p>
<p>We are in the middle of the data. Some of us clamor loudly to be heard, to be seen and counted by institutions that deliberately overlook and under-report. For some of us, visibility entails vulnerability and the threat of unemployment or detainment weighs so heavily that illness must remain invisible, ignored or hidden. We are the data, but we do not always speak for ourselves.</p>
<p>Susan Sontag wrote in <em>Illness as Metaphor</em> that &ldquo;everyone who is born holds dual citizenship, in the kingdom of the well and in the kingdom of the sick. Although we all prefer to use only the good passport, sooner or later each of us is obliged, at least for a spell, to identify ourselves as citizens of that other place.”<sup id="fnref:4"><a href="#fn:4" class="footnote-ref" role="doc-noteref">4</a></sup> A pandemic transcends borders but does not do away with the kingdom of the sick. As someone already resident, I can say to you: welcome. The hardest thing about being here is the grief for what we have lost, including a sense of normalcy. The best thing, though, is what we may find: community in a time of crisis.</p>
<section class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1" role="doc-endnote">
<p>Johanna Drucker, &ldquo;Humanities Approaches to Graphical Display,&rdquo; <em>Digital Humanities Quarterly</em> 5, no. 1 (March 10, 2011), <a href="http://www.digitalhumanities.org/dhq/vol/5/1/000091/000091.html">http://www.digitalhumanities.org/dhq/vol/5/1/000091/000091.html</a>.&#160;<a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:2" role="doc-endnote">
<p>Anne Boyer, <em>The Undying: Pain, Vulnerability, Mortality, Medicine, Art, Time, Dreams, Data, Exhaustion, Cancer, and Care,</em> (New York: Farrar, Straus and Giroux, 2019), 65, 14.&#160;<a href="#fnref:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:3" role="doc-endnote">
<p>Boyer, <em>Undying,</em> 55.&#160;<a href="#fnref:3" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:4" role="doc-endnote">
<p>Susan Sontag, <em>Illness as Metaphor</em> (New York: Farrar, Straus and Giroux, 1978), 3.&#160;<a href="#fnref:4" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</section>]]></content></entry><entry><title type="html">Weave Derrida's References</title><link href="https://startwords.cdh.princeton.edu/issues/1/weaving-howto/?utm_source=atom_feed" rel="alternate" type="text/html"/><link href="https://startwords.cdh.princeton.edu/issues/1/modeling-howto/?utm_source=atom_feed" rel="related" type="text/html" title="Print a Model of the Shakespeare and Company Lending Library Membership"/><link href="https://startwords.cdh.princeton.edu/issues/1/stacking-howto/?utm_source=atom_feed" rel="related" type="text/html" title="Stack Shakespeare and Company Membership Activities"/><link href="https://startwords.cdh.princeton.edu/issues/1/data-beyond-vision/?utm_source=atom_feed" rel="related" type="text/html" title="Data Beyond Vision"/><link href="https://startwords.cdh.princeton.edu/issues/1/weaving-as-interface/?utm_source=atom_feed" rel="related" type="text/html" title="Weaving as Interface"/><id>https://startwords.cdh.princeton.edu/issues/1/weaving-howto/</id><author><name>Gissoo Doroudian</name></author><published>2020-10-01T00:00:00+00:00</published><updated>2022-02-07T13:54:19-05:00</updated><content type="html"><![CDATA[





















<figure ><img loading="lazy" alt="A scarf with alternating bands of blue fabrics resting on a table." src="/issues/1/weaving-howto/images/weaving-display.jpg"
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset="/issues/1/weaving-howto/images/weaving-display_hu6e182ffdd39bfbfe34e02dfa38c31055_5080252_500x0_resize_q75_box.jpg 500w,
    /issues/1/weaving-howto/images/weaving-display_hu6e182ffdd39bfbfe34e02dfa38c31055_5080252_800x0_resize_q75_box.jpg 800w,/issues/1/weaving-howto/images/weaving-display_hu6e182ffdd39bfbfe34e02dfa38c31055_5080252_1200x0_resize_q75_box.jpg 1200w,/issues/1/weaving-howto/images/weaving-display_hu6e182ffdd39bfbfe34e02dfa38c31055_5080252_1500x0_resize_q75_box.jpg 1500w,/issues/1/weaving-howto/images/weaving-display_hu6e182ffdd39bfbfe34e02dfa38c31055_5080252_1800x0_resize_q75_box.jpg 1800w,/issues/1/weaving-howto/images/weaving-display.jpg 3400w" 
     class="landscape"
     ><figcaption>
        <p>Completed weaving of the first thirteen pages of Derrida’s references in chapter 1 of de la Grammatologie.<span class="attribution">Photo by Shelley Szwast</span>
        </p>
    </figcaption>
</figure>
<div class="txt-only">
⩩&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;⟩
| FIGURE. A scarf with alternating bands of blue fabrics resting on a table.
|
| CAPTION: Completed weaving of the first 13 pages of Derrida’s references in chapter 1 of de la Grammatologie
| ATTRIBUTION: Photo by Shelley Szwast
⩩&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;⟩
</div>
<p>Create your own data weaving of Derrida’s references in chapter 1 of <em>de la Grammatologie</em>, as described in <a href="https://startwords.cdh.princeton.edu/issues/1/data-beyond-vision">Data Beyond Vision</a>.</p>
<p>We invite you to participate in the embodiment and visible labor of data work. Download the following models and instructions, use your hands to recreate the data physicalizations we developed, or use them as inspiration to make your own interpretive objects. If you make any of these physicalizations, please share them on social media with the hashtag <a href="https://twitter.com/search?q=(%23DataBeyondVision)">#DataBeyondVision</a>.</p>
<h2 id="tools">Tools</h2>
<ul>
<li>Loom – rigid heddle loom is recommended for beginners. DIY backstrap loom with a string heddle is also possible.</li>
<li>Stick Shuttle (at least 1)<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup></li>
<li>Scissors</li>
<li>Long straw or thin dowel</li>
<li>Yarn needle (optional)</li>
</ul>
<h2 id="supplies">Supplies</h2>
<ul>
<li>9 bundles of yarn of 6 different colors:
<ul>
<li>4 light (size 3), 2 different colors for plain text, page separator, and warp. Be sure to choose a sturdy, smooth yarn for your warp. Yarn with 2 strands is recommended for warp.<sup id="fnref:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup></li>
<li>1 bulky (size 5) – for epigraphs</li>
<li>2 super bulky (size 6), 2 different colors – for footnotes and citations</li>
<li>2 jumbo (size 7) – for quotations</li>
</ul>
</li>
</ul>
<h2 id="steps">Steps</h2>
<ol>
<li>Let’s learn about some <a href="#key-points-about-the-rigid-heddle-loom">key points and terms on the loom</a>, and <a href="#how-to-set-up-the-warp-on-the-loom">how to set up the warp on the loom</a>.</li>
<li>Let’s learn about the weaving types used in this piece and what each represents in the <a href="#weaving-types">“Weaving Types” section</a>.</li>
<li>Let’s weave the Derrida references page by page, covered in the <a href="Pattern-Guide-for-Weaving-Derridas-Margins.pdf">“Pattern Guide for Weaving Derrida’s Margins.”</a></li>
</ol>
<h2 id="yield">Yield</h2>
<p>Weaving of the references in chapter one of Jacques Derrida’s <em>de la Grammatologie</em> (1967).</p>
<div class="deepzoom" id="openseadragon-2" style="height: 10em" aria-label="Interactive zoomable viewer displaying a blue scarf with alternating bands of varied threads."></div>
<script>
    window.addEventListener("DOMContentLoaded", function() {
        OpenSeadragon({
            id: "openseadragon-2",
            prefixUrl: "https://cdn.jsdelivr.net/npm/openseadragon@2.4/build/openseadragon/images/",
            preserveViewport: true,
            visibilityRatio:    1,
            minZoomLevel:       1,
            defaultZoomLevel:   1,
            gestureSettingsMouse: { scrollToZoom: false },
            tileSources: "https:\/\/iiif.princeton.edu\/loris\/iiif\/2\/figgy_prod%2F58%2F51%2Fd4%2F5851d48b225b42699a13181c778a6095%2Fintermediate_file.jp2\/info.json",
        });
    });
</script>


<figure class="deepzoom-preview">
    <img src="images/weaving-deepzoom-alt.jpg" alt="Composite of two images from the high resolution image shown in the deep zoom viewer: one showing the full length of the woven piece, and another with a close up showing the threads and different weaving patterns."/>
    <figcaption><p>The online version of this essay includes an interactive deep zoom viewer displaying a high resolution capture of this object.</p></figcaption>
</figure>

<div class="txt-only">
⩩&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;⟩
| FIGURE. Interactive zoomable viewer displaying a blue scarf with alternating bands of varied threads.
⩩&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;⟩
</div>
<h2 id="key-points-about-the-rigid-heddle-loom">Key points about the Rigid Heddle Loom</h2>






















<figure ><img loading="lazy" alt="Wooden loom sitting on table with blue thread strung taught." src="/issues/1/weaving-howto/images/loom-neutral-position.jpg"
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset="/issues/1/weaving-howto/images/loom-neutral-position_hu8cc7c7aed7826c8aacb143f017aeac83_3956849_500x0_resize_q75_box.jpg 500w,
    /issues/1/weaving-howto/images/loom-neutral-position_hu8cc7c7aed7826c8aacb143f017aeac83_3956849_800x0_resize_q75_box.jpg 800w,/issues/1/weaving-howto/images/loom-neutral-position_hu8cc7c7aed7826c8aacb143f017aeac83_3956849_1200x0_resize_q75_box.jpg 1200w,/issues/1/weaving-howto/images/loom-neutral-position_hu8cc7c7aed7826c8aacb143f017aeac83_3956849_1500x0_resize_q75_box.jpg 1500w,/issues/1/weaving-howto/images/loom-neutral-position_hu8cc7c7aed7826c8aacb143f017aeac83_3956849_1800x0_resize_q75_box.jpg 1800w,/issues/1/weaving-howto/images/loom-neutral-position.jpg 3400w" 
     class="landscape"
     ><figcaption>
        <p>Heddle in neutral position.<span class="attribution">Photo by Gissoo Doroudian, edited by Xinyi Li.</span>
        </p>
    </figcaption>
</figure>
<div class="txt-only">
⩩&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;⟩
| FIGURE. Wooden loom sitting on table with blue thread strung taught.
|
| CAPTION: Heddle in neutral position.
| ATTRIBUTION: Photo by Gissoo Doroudian, edited by Xinyi Li.
⩩&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;⟩
</div>






















<figure ><img loading="lazy" alt="Wooden loom sitting on table with blue thread strung taught, pulled upwards." src="/issues/1/weaving-howto/images/loom-upper-position.jpg"
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset="/issues/1/weaving-howto/images/loom-upper-position_hu27f9665dfeb0407193f95315e61863a7_4205073_500x0_resize_q75_box.jpg 500w,
    /issues/1/weaving-howto/images/loom-upper-position_hu27f9665dfeb0407193f95315e61863a7_4205073_800x0_resize_q75_box.jpg 800w,/issues/1/weaving-howto/images/loom-upper-position_hu27f9665dfeb0407193f95315e61863a7_4205073_1200x0_resize_q75_box.jpg 1200w,/issues/1/weaving-howto/images/loom-upper-position_hu27f9665dfeb0407193f95315e61863a7_4205073_1500x0_resize_q75_box.jpg 1500w,/issues/1/weaving-howto/images/loom-upper-position_hu27f9665dfeb0407193f95315e61863a7_4205073_1800x0_resize_q75_box.jpg 1800w,/issues/1/weaving-howto/images/loom-upper-position.jpg 3400w" 
     class="landscape"
     ><figcaption>
        <p>Heddle in upper position.<span class="attribution">Photo by Gissoo Doroudian, edited by Xinyi Li.</span>
        </p>
    </figcaption>
</figure>
<div class="txt-only">
⩩&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;⟩
| FIGURE. Wooden loom sitting on table with blue thread strung taught, pulled upwards.
|
| CAPTION: Heddle in upper position.
| ATTRIBUTION: Photo by Gissoo Doroudian, edited by Xinyi Li.
⩩&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;⟩
</div>






















<figure ><img loading="lazy" alt="Wooden loom sitting on table with blue thread strung taught, pulled downwards." src="/issues/1/weaving-howto/images/loom-lower-position.jpg"
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset="/issues/1/weaving-howto/images/loom-lower-position_huaab913883759ea62d53fc817d5b16562_3740196_500x0_resize_q75_box.jpg 500w,
    /issues/1/weaving-howto/images/loom-lower-position_huaab913883759ea62d53fc817d5b16562_3740196_800x0_resize_q75_box.jpg 800w,/issues/1/weaving-howto/images/loom-lower-position_huaab913883759ea62d53fc817d5b16562_3740196_1200x0_resize_q75_box.jpg 1200w,/issues/1/weaving-howto/images/loom-lower-position_huaab913883759ea62d53fc817d5b16562_3740196_1500x0_resize_q75_box.jpg 1500w,/issues/1/weaving-howto/images/loom-lower-position_huaab913883759ea62d53fc817d5b16562_3740196_1800x0_resize_q75_box.jpg 1800w,/issues/1/weaving-howto/images/loom-lower-position.jpg 3400w" 
     class="landscape"
     ><figcaption>
        <p>Heddle in lower position.<span class="attribution">Photo by Gissoo Doroudian, edited by Xinyi Li.</span>
        </p>
    </figcaption>
</figure>
<div class="txt-only">
⩩&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;⟩
| FIGURE. Wooden loom sitting on table with blue thread strung taught, pulled downwards.
|
| CAPTION: Heddle in lower position.
| ATTRIBUTION: Photo by Gissoo Doroudian, edited by Xinyi Li.
⩩&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;⟩
</div>






















<figure ><img loading="lazy" alt="Close-up of wooden loom showing long wooden rod with blue yarn wrapped around it." src="/issues/1/weaving-howto/images/shuttle.jpg"
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset="/issues/1/weaving-howto/images/shuttle_hu517e8a7be430e6ac680aac87e5b4d973_4964328_500x0_resize_q75_box.jpg 500w,
    /issues/1/weaving-howto/images/shuttle_hu517e8a7be430e6ac680aac87e5b4d973_4964328_800x0_resize_q75_box.jpg 800w,/issues/1/weaving-howto/images/shuttle_hu517e8a7be430e6ac680aac87e5b4d973_4964328_1200x0_resize_q75_box.jpg 1200w,/issues/1/weaving-howto/images/shuttle_hu517e8a7be430e6ac680aac87e5b4d973_4964328_1500x0_resize_q75_box.jpg 1500w,/issues/1/weaving-howto/images/shuttle_hu517e8a7be430e6ac680aac87e5b4d973_4964328_1800x0_resize_q75_box.jpg 1800w,/issues/1/weaving-howto/images/shuttle.jpg 3400w" 
     class="landscape"
     ><figcaption>
        <p>Shuttle, a tool used to pass the yarn through the warp.<span class="attribution">Photo by Gissoo Doroudian, edited by Xinyi Li.</span>
        </p>
    </figcaption>
</figure>
<div class="txt-only">
⩩&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;⟩
| FIGURE. Close-up of wooden loom showing long wooden rod with blue yarn wrapped around it.
|
| CAPTION: Shuttle, a tool used to pass the yarn through the warp.
| ATTRIBUTION: Photo by Gissoo Doroudian, edited by Xinyi Li.
⩩&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;⟩
</div>






















<figure ><img loading="lazy" alt="Close-up of crossed yarn with vertical threads labeled “warp” and horizontal yarns threads labeled “weft”." src="/issues/1/weaving-howto/images/warp-weft-annotated.jpg"
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset="/issues/1/weaving-howto/images/warp-weft-annotated_hu7bc76d175bd5292bb8defbabd9d6bf04_5104258_500x0_resize_q75_box.jpg 500w,
    /issues/1/weaving-howto/images/warp-weft-annotated_hu7bc76d175bd5292bb8defbabd9d6bf04_5104258_800x0_resize_q75_box.jpg 800w,/issues/1/weaving-howto/images/warp-weft-annotated_hu7bc76d175bd5292bb8defbabd9d6bf04_5104258_1200x0_resize_q75_box.jpg 1200w,/issues/1/weaving-howto/images/warp-weft-annotated_hu7bc76d175bd5292bb8defbabd9d6bf04_5104258_1500x0_resize_q75_box.jpg 1500w,/issues/1/weaving-howto/images/warp-weft-annotated_hu7bc76d175bd5292bb8defbabd9d6bf04_5104258_1800x0_resize_q75_box.jpg 1800w,/issues/1/weaving-howto/images/warp-weft-annotated.jpg 3000w" 
     class="portrait"
     ><figcaption>
        <p>“Warp” and “weft” yarns.<span class="attribution">Photo by Gissoo Doroudian.</span>
        </p>
    </figcaption>
</figure>
<div class="txt-only">
⩩&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;⟩
| FIGURE. Close-up of crossed yarn with vertical threads labeled “Warp” and horizontal threads labeled “weft”.
|
| CAPTION: “Warp” and “weft” yarns.
| ATTRIBUTION: Photo by Gissoo Doroudian.
⩩&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;⟩
</div>
<p>The yarn <em>on which</em> you weave a piece, which acts as the base of the weaving and sits longitudinally is called “warp”; yarns you use to weave a piece are called “weft”.<sup id="fnref:3"><a href="#fn:3" class="footnote-ref" role="doc-noteref">3</a></sup></p>
<h2 id="how-to-set-up-the-warp-on-the-loom">How to set up the warp on the loom</h2>
<p>If you purchase a loom, it will most likely include setup instructions. However, below are a few great resources on how to set up the warp on a rigid heddle loom.</p>
<ul>
<li><a href="https://www.youtube.com/watch?v=fa1WrHOTjxY">A video that carefully demonstrates the steps visually and verbally</a></li>
<li><a href="https://www.wearingwoad.com/saori-weaving-tutorial-warping-a-rigid-heddle-loom/">An article that includes a written description of the steps </a></li>
<li><a href="https://www.ashford.co.nz/images/download_pdfs/learn_to/learn_to_weave_on_the_rigid_heddle.pdf">A downloadable PDF that includes visual and written instructions </a></li>
</ul>
<p>Note: Approximately 37 inches of warp yarn were cut and set up on the loom to weave pages 15–27, which makes up half of chapter 1 of <em>de la Grammatologie</em>.</p>
<h2 id="weaving-types">Weaving Types</h2>
<p>Weaving types used in this piece:</p>
<ol>
<li><a href="#plain-weave">Plain weave</a></li>
<li><a href="#soumak-weave">Soumak weave</a></li>
<li><a href="#pile-loop-weave">Pile loop weave</a></li>
<li><a href="#rya-knot">Rya knot</a></li>
</ol>
<h3 id="plain-weave">Plain Weave</h3>
<p>Note: If the yarn is thin you can use the shuttle and the upper and lower position of the heddle to weave the plain weave. However, if the yarn is too thick you need to leave the heddle in neutral position and use your hands to weave.</p>
<h4 id="method-1">Method #1</h4>
<p>This method was used to represent plain text (in royal blue) and page separation in (white).</p>






















<figure ><img loading="lazy" alt="Composite of eight images showing various stages of weaving." src="/issues/1/weaving-howto/images/plain-weave-thin.jpg"
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset="/issues/1/weaving-howto/images/plain-weave-thin_huf032ac8439ba3742b430b43046a2812d_6876127_500x0_resize_q75_box.jpg 500w,
    /issues/1/weaving-howto/images/plain-weave-thin_huf032ac8439ba3742b430b43046a2812d_6876127_800x0_resize_q75_box.jpg 800w,/issues/1/weaving-howto/images/plain-weave-thin_huf032ac8439ba3742b430b43046a2812d_6876127_1200x0_resize_q75_box.jpg 1200w,/issues/1/weaving-howto/images/plain-weave-thin_huf032ac8439ba3742b430b43046a2812d_6876127_1500x0_resize_q75_box.jpg 1500w,/issues/1/weaving-howto/images/plain-weave-thin_huf032ac8439ba3742b430b43046a2812d_6876127_1800x0_resize_q75_box.jpg 1800w,/issues/1/weaving-howto/images/plain-weave-thin.jpg 3000w" 
     class="portrait"
     ><figcaption>
        <p>How to make a plain weave in eight steps utilizing the shuttle along with changing the heddle positions, appropriate for thinner yarns.<span class="attribution">Photos by Shelley Szwast and Gissoo Doroudian.</span>
        </p>
    </figcaption>
</figure>
<div class="txt-only">
⩩&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;⟩
| FIGURE. Composite of eight images showing various stages of weaving.
|
| CAPTION: How to make a plain weave in eight steps utilizing the shuttle along with changing the heddle positions, appropriate for thinner yarns.
| ATTRIBUTION: Photos by Shelley Szwast and Gissoo Doroudian.
⩩&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;⟩
</div>
<p>Heddle position: upper and lower</p>
<p>Yarn size: 3/light</p>
<p>#1–5 below correspond to the numbers on the images.</p>
<p>To create a plain weave:</p>
<ol>
<li>Place the heddle in the upper position.</li>
<li>Insert the shuttle into the opening (called the shed) between the raised and lowered yarns.</li>
<li>Take the shuttle out the other side.</li>
<li>Press the weft into place using the heddle.</li>
<li>Place the heddle in the lower position. On the second pass back (to start the second row), going left to right, repeat the process above (reflected in #6–8 in the photos).</li>
</ol>
<p>The basic weave continues on in this way over as many warp yarns as you wish.</p>
<p>Note: Starting the weave from left to right going <em>over</em> the first warp yarn is better because it enables weaving in the loose end of the weft yarn easily. Starting by going under the first warp yarn would cause the weave to look not as seamless.</p>
<p>Learned and adapted from: <a href="https://www.theweavingloom.com/weaving-techniques-the-plain-weave/">https://www.theweavingloom.com/weaving-techniques-the-plain-weave/</a></p>
<h4 id="method-2">Method #2</h4>
<p>This method was used to represent quotations.</p>
<p>





















<figure ><img loading="lazy" alt="Composite of four images showing various stages of weaving." src="/issues/1/weaving-howto/images/plain-weave-thick.jpg"
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset="/issues/1/weaving-howto/images/plain-weave-thick_hu8f3e4ad5c3fc6076013f221854fec1fd_4254456_500x0_resize_q75_box.jpg 500w,
    /issues/1/weaving-howto/images/plain-weave-thick_hu8f3e4ad5c3fc6076013f221854fec1fd_4254456_800x0_resize_q75_box.jpg 800w,/issues/1/weaving-howto/images/plain-weave-thick_hu8f3e4ad5c3fc6076013f221854fec1fd_4254456_1200x0_resize_q75_box.jpg 1200w,/issues/1/weaving-howto/images/plain-weave-thick_hu8f3e4ad5c3fc6076013f221854fec1fd_4254456_1500x0_resize_q75_box.jpg 1500w,/issues/1/weaving-howto/images/plain-weave-thick_hu8f3e4ad5c3fc6076013f221854fec1fd_4254456_1800x0_resize_q75_box.jpg 1800w,/issues/1/weaving-howto/images/plain-weave-thick.jpg 3400w" 
     class="landscape"
     ><figcaption>
        <p>How to make a plain weave in four steps utilizing the hands to pass the yarn through the warp.<span class="attribution">Photos by Gissoo Doroudian.</span>
        </p>
    </figcaption>
</figure>
<div class="txt-only">
⩩&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;⟩
| FIGURE. Composite of eight images showing various stages of weaving.
|
| CAPTION: How to make a plain weave in four steps utilizing the hands to pass the yarn through the warp.
| ATTRIBUTION: Photos by Gissoo Doroudian.
⩩&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;⟩
</div></p>
<p>Heddle position: neutral</p>
<p>Yarn size: 7/jumbo</p>
<p>(Reflected in #1 in the photos)</p>
<ol>
<li>Pull the weft yarn over the first warp yarn,</li>
<li>under the second warp yarn,</li>
<li>over the third warp yarn.</li>
</ol>
<p>Continue until you get to the end of the warp yarn. On the second pass back (to start the second row), going right to left: (Reflected in #2-4 in the photos)</p>
<ol start="4">
<li>Pass the weft yarn under the first warp yarn,</li>
<li>over the second warp yarn,</li>
<li>under the third warp yarn.</li>
</ol>
<p>Continue until the first warp yarn is met again. The basic weave continues on in this way over as many warp yarn as you wish.</p>
<p>Learned and adapted from:</p>
<p><a href="https://www.theweavingloom.com/weaving-techniques-the-plain-weave/">https://www.theweavingloom.com/weaving-techniques-the-plain-weave/</a></p>
<h3 id="soumak-weave">Soumak Weave</h3>
<p>This technique was used to represent footnotes.</p>
<p>





















<figure ><img loading="lazy" alt="Composite of eight images showing various stages of weaving." src="/issues/1/weaving-howto/images/soumak-weave.jpg"
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset="/issues/1/weaving-howto/images/soumak-weave_hu7ed6df7bb8b0216e72d821b99a1bdddd_3525885_500x0_resize_q75_box.jpg 500w,
    /issues/1/weaving-howto/images/soumak-weave_hu7ed6df7bb8b0216e72d821b99a1bdddd_3525885_800x0_resize_q75_box.jpg 800w,/issues/1/weaving-howto/images/soumak-weave_hu7ed6df7bb8b0216e72d821b99a1bdddd_3525885_1200x0_resize_q75_box.jpg 1200w,/issues/1/weaving-howto/images/soumak-weave_hu7ed6df7bb8b0216e72d821b99a1bdddd_3525885_1500x0_resize_q75_box.jpg 1500w,/issues/1/weaving-howto/images/soumak-weave_hu7ed6df7bb8b0216e72d821b99a1bdddd_3525885_1800x0_resize_q75_box.jpg 1800w,/issues/1/weaving-howto/images/soumak-weave.jpg 3000w" 
     class="portrait"
     ><figcaption>
        <p>How to make a soumak weave in eight steps. Photos by Gissoo Doroudian.
        </p>
    </figcaption>
</figure>
<div class="txt-only">
⩩&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;⟩
| FIGURE. Composite of eight images showing various stages of weaving.
|
| CAPTION: How to make a soumak weave in eight steps. Photos by Gissoo Doroudian.
⩩&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;⟩
</div></p>
<p>Heddle position: neutral</p>
<p>Yarn size: 6/super bulky</p>
<p>Note: images above were taken on a paper prototype loom; therefore the warp yarns are pulling more than they would on a heddle loom.</p>
<p>#1–3 below correspond to the numbers on the images.</p>
<p>The soumak weave is the process of wrapping the weft yarn around the warp yarn.</p>
<p>To create the soumak pattern:</p>
<ol>
<li>Place the end of the weft yarn behind the two warp yarns, with the end coming out to the front on the right-hand side of the two warp yarns.</li>
<li>Pull out the next two warp yarns. While holding the weft yarn bundling in your right hand, pass the weft yarn behind these two warp yarns from right to left.</li>
<li>After pulling the weft yarn right through to form your first slanted stitch, make sure not to pull too tightly as this will distort the warp.</li>
</ol>
<p>Continue until you get to the end of the warp yarns. On the second pass back (to start the second row), going right to left,</p>
<ol start="4">
<li>At the end of the row wrap around the last two warp yarns twice. (Reflected in #6 in the photos)</li>
<li>Pull out the next two warp yarns to the left of the end and holding the yarn bundle in your left hand, pass it behind the two warps from left to right. This will create a stitch that slants in the opposite direction. (Reflected in #7 in the photos)</li>
</ol>
<p>Continue until the first warp yarn is met again.</p>
<p>Learned and adapted from: <a href="https://www.youtube.com/watch?v=OaP4eQLRefk">https://www.youtube.com/watch?v=OaP4eQLRefk</a></p>
<h3 id="pile-loop-weave">Pile Loop Weave</h3>
<p>This technique was used to represent epigraphs.</p>
<p>





















<figure ><img loading="lazy" alt="Composite of seven images showing various stages of weaving." src="/issues/1/weaving-howto/images/pile-loop-weave.jpg"
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset="/issues/1/weaving-howto/images/pile-loop-weave_hu3a2e44b4770da06b2e9369a7c95e8010_3768410_500x0_resize_q75_box.jpg 500w,
    /issues/1/weaving-howto/images/pile-loop-weave_hu3a2e44b4770da06b2e9369a7c95e8010_3768410_800x0_resize_q75_box.jpg 800w,/issues/1/weaving-howto/images/pile-loop-weave_hu3a2e44b4770da06b2e9369a7c95e8010_3768410_1200x0_resize_q75_box.jpg 1200w,/issues/1/weaving-howto/images/pile-loop-weave_hu3a2e44b4770da06b2e9369a7c95e8010_3768410_1500x0_resize_q75_box.jpg 1500w,/issues/1/weaving-howto/images/pile-loop-weave_hu3a2e44b4770da06b2e9369a7c95e8010_3768410_1800x0_resize_q75_box.jpg 1800w,/issues/1/weaving-howto/images/pile-loop-weave.jpg 3000w" 
     class="portrait"
     ><figcaption>
        <p>How to make a pile loop weave in seven steps.<span class="attribution">Photos by Gissoo Doroudian.</span>
        </p>
    </figcaption>
</figure>
<div class="txt-only">
⩩&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;⟩
| FIGURE. Composite of seven images showing various stages of weaving.
|
| CAPTION: How to make a pile loop weave in seven steps.
| ATTRIBUTION: Photos by Gissoo Doroudian.
⩩&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;⟩
</div></p>
<p>Heddle position: neutral</p>
<p>Yarn size: 5/bulky</p>
<p>Numbered list below corresponds to the numbers on the images. To create the pile loop:</p>
<ol>
<li>Weave a row of plain weave in the area that you want your loops, using one or two strands of yarn. Please refer to the <a href="#plain-weave">“Plain Weave”</a> section for instructions. Since this yarn is thinner you can use a yarn needle to pass it through the warp as well.</li>
<li>Take the wooden dowel and pick up your “stitches” by wrapping them around it as shown.</li>
<li>Once the entire plain weave row is on the dowel, pull the dowel down on the warp so that it brings the loops down to the support rows.</li>
<li>Gently remove the dowel so that you leave behind a row of loops.</li>
<li>Weave another plain weave row above your loops, and repeat the steps above, while making sure not to pull the weft too much; otherwise you’ll start to lose the loops you just made. (Reflected in #5-7 in the photos)</li>
</ol>
<p>Continue in this pattern until you have made all the loops you want. Once done, weave a support row of plain weave and smash that support row down into your loops. You want to really smash the loop rows down so that your weave doesn’t loosen once you cut it off the loom.</p>
<p>Learned and adapted from: <a href="https://www.theweavingloom.com/best-of-weaving-technique-pile-loop-weave/">https://www.theweavingloom.com/best-of-weaving-technique-pile-loop-weave/</a></p>
<h3 id="rya-knot">Rya knot</h3>
<p>This technique was used to represent citations.</p>
<p>





















<figure ><img loading="lazy" alt="Composite of four images showing various stages of weaving." src="/issues/1/weaving-howto/images/rya-knot-weave.jpg"
     sizes="(max-width: 768px) 100vw, 80vw"
     srcset="/issues/1/weaving-howto/images/rya-knot-weave_hud3071ba86ff95d7aec199970c73cee20_4420018_500x0_resize_q75_box.jpg 500w,
    /issues/1/weaving-howto/images/rya-knot-weave_hud3071ba86ff95d7aec199970c73cee20_4420018_800x0_resize_q75_box.jpg 800w,/issues/1/weaving-howto/images/rya-knot-weave_hud3071ba86ff95d7aec199970c73cee20_4420018_1200x0_resize_q75_box.jpg 1200w,/issues/1/weaving-howto/images/rya-knot-weave_hud3071ba86ff95d7aec199970c73cee20_4420018_1500x0_resize_q75_box.jpg 1500w,/issues/1/weaving-howto/images/rya-knot-weave_hud3071ba86ff95d7aec199970c73cee20_4420018_1800x0_resize_q75_box.jpg 1800w,/issues/1/weaving-howto/images/rya-knot-weave.jpg 3400w" 
     class="landscape"
     ><figcaption>
        <p>How to make a rya knot in four steps.
        </p>
    </figcaption>
</figure>
<div class="txt-only">
⩩&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;⟩
| FIGURE. Composite of four images showing various stages of weaving.
|
| CAPTION: How to make a rya knot in four steps.
⩩&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;⟩
</div></p>
<p>Heddle position: neutral</p>
<p>Yarn size: 6/super bulky</p>
<p>Numbered list below corresponds to the numbers on the images. To create a rya knot:</p>
<ol>
<li>Place strands of yarn over the warp yarns.</li>
<li>Bring the left side of your yarn behind and around two warp yarns.</li>
<li>Bring the right side of your yarn behind and around your other two warp yarns so that the ends meet up in the middle.</li>
<li>Pull the end pieces below the top knot area.</li>
</ol>
<p>Note: Before pulling ends down and tightening the top knot, make sure to match up both sides of the end pieces and then pull evenly, so that the knot ties with all ends at about the same length. Trimming is usually required for a more uniform fringe, but this helps reduce yarn waste. If starting with the rya knot (bottom up weaving), pull the end pieces below the top knot area. If you are ending with the rya knot (top down weaving) you would pull the end pieces above the top knot area.</p>
<p>Learned and adapted from: <a href="https://www.theweavingloom.com/weaving-techniques-rya-knots/">https://www.theweavingloom.com/weaving-techniques-rya-knots/</a></p>
<p>If you would like to try weaving the first chapter of <em>de la Grammatologie</em> download the <a href="Pattern-Guide-for-Weaving-Derridas-Margins.pdf">“Pattern Guide for Weaving Derrida’s Margins”</a> and follow the instructions.</p>
<section class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1" role="doc-endnote">
<p>A shuttle is a tool that is used to hold and pass the yarn through the warp.&#160;<a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:2" role="doc-endnote">
<p>A yarn is made up of several twisted strands of fiber, referred to as “plies”&#160;<a href="#fnref:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:3" role="doc-endnote">
<p>The word “weft” literally means “that which is woven,” and comes from an obsolete form of the word “weave”; the forms are similar to “leave” and “left.” Wikipedia, s.v. “Weaving,” last modified October 13, 2020, 22:52, <a href="https://en.wikipedia.org/wiki/Weaving;">https://en.wikipedia.org/wiki/Weaving;</a> OED Online, s.v. “weft, n. 1,” accessed October 26, 2020, <a href="http://www.oed.com/view/Entry/226851">www.oed.com/view/Entry/226851</a>.&#160;<a href="#fnref:3" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</section>
]]></content></entry><entry><title type="html">About</title><link href="https://startwords.cdh.princeton.edu/about/?utm_source=atom_feed" rel="alternate" type="text/html"/><id>https://startwords.cdh.princeton.edu/about/</id><published>0001-01-01T00:00:00+00:00</published><updated>2022-02-07T13:54:19-05:00</updated><content type="html"><![CDATA[<p><em>Startwords</em> is a research periodical irregularly published by the Center for Digital Humanities at Princeton. More formal than a blog yet more speculative and iterative than a peer-reviewed journal, <em>Startwords</em> is a forum for experimental humanities scholarship. Embedded code, data physicalizations, design, and emerging forms of process documentation are detailed through writing that is essayistic, creative, and research-driven.</p>
<p>Each issue features two articles that speak to a common theme, feature, or concern. “Snippets” invite readers to engage with the digital evidence underlying those articles. Issues will be released one to three times a year, when we have something to share or say.</p>
<p><em>Startwords</em> (ISSN 2694-2658) is built with the Hugo static site generator using a custom-made theme. In support of open access principles, we publish all articles under a Creative Commons license (CC BY 4.0) and the <a href="https://github.com/Princeton-CDH/startwords">website code</a> under an Apache 2.0 license.</p>
<div class="masthead">
<h2 id="masthead">Masthead</h2>
<p><strong>Editor</strong> Grant Wythoff</p>
<p><strong>UX Designer</strong> Gissoo Doroudian</p>
<p><strong>Technical Lead</strong> Rebecca Sutton Koeser</p>
<p><strong>Manuscript Editing</strong> Camey VanSant</p>
<p><strong>Technical</strong></p>
<ul>
<li>Nick Budak (Technical Lead, 2020)</li>
<li>Kevin McElwee</li>
<li>Grant Wythoff</li>
</ul>
<p><strong>Board of Advisors</strong></p>
<ul>
<li>Natalia Ermolaev</li>
<li>Zoe LeBlanc</li>
<li>Meredith Martin</li>
<li>Rebecca Munson (2020)</li>
</ul>

</div>
]]></content></entry><entry><title type="html">Weaving as Interface</title><link href="https://startwords.cdh.princeton.edu/issues/1/weaving-as-interface/?utm_source=atom_feed" rel="alternate" type="text/html"/><link href="https://startwords.cdh.princeton.edu/issues/1/data-beyond-vision/?utm_source=atom_feed" rel="related" type="text/html" title="Data Beyond Vision"/><link href="https://startwords.cdh.princeton.edu/issues/1/modeling-howto/?utm_source=atom_feed" rel="related" type="text/html" title="Print a Model of the Shakespeare and Company Lending Library Membership"/><link href="https://startwords.cdh.princeton.edu/issues/1/stacking-howto/?utm_source=atom_feed" rel="related" type="text/html" title="Stack Shakespeare and Company Membership Activities"/><link href="https://startwords.cdh.princeton.edu/issues/1/weaving-howto/?utm_source=atom_feed" rel="related" type="text/html" title="Weave Derrida's References"/><id>https://startwords.cdh.princeton.edu/issues/1/weaving-as-interface/</id><author><name>Rebecca Sutton Koeser</name></author><author><name>Gissoo Doroudian</name></author><published>0001-01-01T00:00:00+00:00</published><updated>2022-02-07T13:54:19-05:00</updated><content type="html"><![CDATA[<p>This weaving represents the references in chapter one of Jacques Derrida’s <em>de la Grammatologie</em> (1967). The references have been cataloged and categorized by the research team of <a href="https://derridas-margins.princeton.edu/">Derrida’s Margins</a>. Each type of reference (epigraph, citation, quotation, footnote) is represented by a distinct yarn and weaving pattern. For more details on the goals and insights of this data physicalization, read <a href="/issues/1/data-beyond-vision/#weaving">Weaving Derrida’s References</a>.</p>
<p>As a way of turning the weaving into an interface, we offer this experiment with an annotated deep-zoom image of the weaving linked to information about the references it represents, allowing you to explore the underlying data through the context of the weaving.</p>
<p><sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup> <sup id="fnref:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup> <sup id="fnref:3"><a href="#fn:3" class="footnote-ref" role="doc-noteref">3</a></sup> <sup id="fnref:4"><a href="#fn:4" class="footnote-ref" role="doc-noteref">4</a></sup> <sup id="fnref:5"><a href="#fn:5" class="footnote-ref" role="doc-noteref">5</a></sup> <sup id="fnref:6"><a href="#fn:6" class="footnote-ref" role="doc-noteref">6</a></sup> <sup id="fnref:7"><a href="#fn:7" class="footnote-ref" role="doc-noteref">7</a></sup> <sup id="fnref:8"><a href="#fn:8" class="footnote-ref" role="doc-noteref">8</a></sup> <sup id="fnref:9"><a href="#fn:9" class="footnote-ref" role="doc-noteref">9</a></sup> <sup id="fnref:10"><a href="#fn:10" class="footnote-ref" role="doc-noteref">10</a></sup> <sup id="fnref:11"><a href="#fn:11" class="footnote-ref" role="doc-noteref">11</a></sup> <sup id="fnref:12"><a href="#fn:12" class="footnote-ref" role="doc-noteref">12</a></sup> <sup id="fnref:13"><a href="#fn:13" class="footnote-ref" role="doc-noteref">13</a></sup> <sup id="fnref:14"><a href="#fn:14" class="footnote-ref" role="doc-noteref">14</a></sup> <sup id="fnref:15"><a href="#fn:15" class="footnote-ref" role="doc-noteref">15</a></sup> <sup id="fnref:16"><a href="#fn:16" class="footnote-ref" role="doc-noteref">16</a></sup> <sup id="fnref:17"><a href="#fn:17" class="footnote-ref" role="doc-noteref">17</a></sup> <sup id="fnref:18"><a href="#fn:18" class="footnote-ref" role="doc-noteref">18</a></sup> <sup id="fnref:19"><a href="#fn:19" class="footnote-ref" role="doc-noteref">19</a></sup> <sup id="fnref:20"><a href="#fn:20" class="footnote-ref" role="doc-noteref">20</a></sup> <sup id="fnref:21"><a href="#fn:21" class="footnote-ref" role="doc-noteref">21</a></sup> <sup id="fnref:22"><a href="#fn:22" class="footnote-ref" role="doc-noteref">22</a></sup> <sup id="fnref:23"><a href="#fn:23" class="footnote-ref" role="doc-noteref">23</a></sup> <sup id="fnref:24"><a href="#fn:24" class="footnote-ref" role="doc-noteref">24</a></sup> <sup id="fnref:25"><a href="#fn:25" class="footnote-ref" role="doc-noteref">25</a></sup> <sup id="fnref:26"><a href="#fn:26" class="footnote-ref" role="doc-noteref">26</a></sup> <sup id="fnref:27"><a href="#fn:27" class="footnote-ref" role="doc-noteref">27</a></sup> <sup id="fnref:28"><a href="#fn:28" class="footnote-ref" role="doc-noteref">28</a></sup> <sup id="fnref:29"><a href="#fn:29" class="footnote-ref" role="doc-noteref">29</a></sup> <sup id="fnref:30"><a href="#fn:30" class="footnote-ref" role="doc-noteref">30</a></sup> <sup id="fnref:31"><a href="#fn:31" class="footnote-ref" role="doc-noteref">31</a></sup></p>
</div> <!-- close text container -->
<div class="deepzoom full-width" id="dataweaving-zoom"></div>
<div class="text-container"> <!-- re-open text container -->
<!-- container for overlays added in code based on json -->
<div id="overlays"> </div>
<h2 id="acknowledgments">Acknowledgments</h2>
<p>The reference information shown here is drawn from datasets related to <a href="https://derridas-margins.princeton.edu/">Derrida&rsquo;s Margins</a>:</p>
<blockquote>
<p>Chenoweth, Katie, Alexander Baron-Raiffe, Renée Altergott, Chloé Vettier, Chad Córdova, Rebecca Sutton Koeser, Jean Bauer, and Benjamin Hicks. 2018. “References in Jacques Derrida&rsquo;s De La Grammatologie”. figshare. <a href="https://doi.org/10.6084/m9.figshare.7180448.v1">doi:10.6084/m9.figshare.7180448.v1</a>.</p>
</blockquote>
<blockquote>
<p>Chenoweth, Katie, Alexander Baron-Raiffe, Renée Altergott, Chad Córdova, Austin Hancock, Chloé Vettier, Rebecca Sutton Koeser, Jean Bauer, Benjamin Hicks, and Nick Budak. 2018. “Works Cited by Jacques Derrida in De La Grammatologie”. figshare. <a href="https://doi.org/10.6084/m9.figshare.7180460.v1">doi:10.6084/m9.figshare.7180460.v1</a>.</p>
</blockquote>
<p>The high resolution capture of the data weaving used here was created by Princeton University Library, Digital Imaging Studio.  Annotations on the image were drawn with <a href="https://recogito.pelagios.org/">Recogito</a>.</p>
<section class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1" role="doc-endnote">
<p><span class="reftype">Epigraph<span class="page">, p. 15</span></span>
<em><a href="https://derridas-margins.princeton.edu/library/nietzsche-die-geburt-der-tragodie-aus-dem-geiste-der-musik-1949/">La Naissance de la tragédie</a></em> (1949)<br/>
Friedrich Nietzsche<br/>
<cite lang="fr">Socrate, celui qui n&rsquo;écrit pas.</cite> (p. 172)
<img src="https://derridas-margins.princeton.edu/library/nietzsche-die-geburt-der-tragodie-aus-dem-geiste-der-musik-1949/gallery/images/front-cover/thumbnail/" alt="Cover of La Naissance de la tragédie">&#160;<a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:2" role="doc-endnote">
<p><span class="reftype">Footnote<span class="page">, p. 16</span></span>
<em><a href="https://derridas-margins.princeton.edu/titles/227/">Langue et écriture</a></em> <br/>
V. M. Istrin<br/>
<cite lang="fr">Parler ici d&rsquo;une écriture première ne revient pas à affirmer une priorité chronologique de fait. On connaît ce débat  : l&rsquo;écriture est-elle, comme l&rsquo;affirmaient par exemple Metchnaninov et Marr, puis Loukotka, « antérieure au langage phonétique » ? (Conclusion assumée par la première édition de la Grande Encyclopédie Soviétique, puis contredite par Staline. Sur ce débat, cf. V. Istrine, <em>Langue et écriture</em>, in <em>Linguistique, op. cit.</em>, pp. 35, 60. Ce débat s&rsquo;est aussi fixé autour des thèses du P. van Ginneken. Sur la discussion de ces thèses, cf. J. Février, <em>Histoire de l&rsquo;écriture</em>, Payot, 1948-1959, p. 5 sq.) Nous essaierons de montrer plus loin pourquoi les termes et les prémisses d&rsquo;un tel débat appellent la suspicion.</cite> (p. 35)&#160;<a href="#fnref:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:3" role="doc-endnote">
<p><span class="reftype">Footnote<span class="page">, p. 16</span></span>
<em><a href="https://derridas-margins.princeton.edu/titles/227/">Langue et écriture</a></em> <br/>
V. M. Istrin<br/>
<cite lang="fr">Parler ici d&rsquo;une écriture première ne revient pas à affirmer une priorité chronologique de fait. On connaît ce débat  : l&rsquo;écriture est-elle, comme l&rsquo;affirmaient par exemple Metchnaninov et Marr, puis Loukotka, « antérieure au langage phonétique » ? (Conclusion assumée par la première édition de la Grande Encyclopédie Soviétique, puis contredite par Staline. Sur ce débat, cf. V. Istrine, <em>Langue et écriture</em>, in <em>Linguistique, op. cit.</em>, pp. 35, 60. Ce débat s&rsquo;est aussi fixé autour des thèses du P. van Ginneken. Sur la discussion de ces thèses, cf. J. Février, <em>Histoire de l&rsquo;écriture</em>, Payot, 1948-1959, p. 5 sq.) Nous essaierons de montrer plus loin pourquoi les termes et les prémisses d&rsquo;un tel débat appellent la suspicion.</cite> (p. 60)&#160;<a href="#fnref:3" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:4" role="doc-endnote">
<p><span class="reftype">Footnote<span class="page">, p. 16</span></span>
<em><a href="https://derridas-margins.princeton.edu/library/?query=fevrier-histoire-de-lecriture-1948&amp;is_extant=false">Histoire de l&rsquo;écriture</a></em> (1948)<br/>
James Février<br/>
<cite lang="fr">Parler ici d&rsquo;une écriture première ne revient pas à affirmer une priorité chronologique de fait. On connaît ce débat  : l&rsquo;écriture est-elle, comme l&rsquo;affirmaient par exemple Metchnaninov et Marr, puis Loukotka, « antérieure au langage phonétique » ? (Conclusion assumée par la première édition de la Grande Encyclopédie Soviétique, puis contredite par Staline. Sur ce débat, cf. V. Istrine, <em>Langue et écriture</em>, in <em>Linguistique, op. cit.</em>, pp. 35, 60. Ce débat s&rsquo;est aussi fixé autour des thèses du P. van Ginneken. Sur la discussion de ces thèses, cf. J. Février, <em>Histoire de l&rsquo;écriture</em>, Payot, 1948-1959, p. 5 sq.) Nous essaierons de montrer plus loin pourquoi les termes et les prémisses d&rsquo;un tel débat appellent la suspicion.</cite> (p. 5)&#160;<a href="#fnref:4" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:5" role="doc-endnote">
<p><span class="reftype">Quotation<span class="page">, p. 17</span></span>
<em><a href="https://derridas-margins.princeton.edu/library/?query=rousseau-emile-ou-de-leducation-1762&amp;is_extant=false">Émile ou de l&rsquo;éducation</a></em> (1762)<br/>
Jean-Jacques Rousseau<br/>
<cite lang="fr">plus fondamentale que celle qui, avant cette conversion, passait pour le simple « supplément à la parole » (Rousseau).</cite>&#160;<a href="#fnref:5" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:6" role="doc-endnote">
<p><span class="reftype">Footnote<span class="page">, p. 17</span></span>
<em><a href="https://derridas-margins.princeton.edu/library/?query=derrida-la-voix-et-le-phenomene-1967&amp;is_extant=false">La voix et le phénomène</a></em> (1967)<br/>
Jacques Derrida<br/>
<cite lang="fr">C&rsquo;est un problème que nous abordons plus directement dans <em>La voix et le phénomène</em> (P.U.F. 1967).</cite>&#160;<a href="#fnref:6" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:7" role="doc-endnote">
<p><span class="reftype">Footnote<span class="page">, p. 20</span></span>
<em><a href="https://derridas-margins.princeton.edu/library/bloch-lecriture-et-la-psychologie-des-peuples-actes-de-colloque-1963/">L&rsquo;Ecriture et la psychologie des peuples: actes de colloque</a></em> (1963)<br/>
<cite lang="fr">Cf. par ex. EP. pp. 126, 148, 355, etc. D&rsquo;un autre point de vue, cf. Jakobson, <em>Essais de linguistique générale</em> (tr. fr. p. 116)</cite> (p. 126)
<img src="https://derridas-margins.princeton.edu/library/bloch-lecriture-et-la-psychologie-des-peuples-actes-de-colloque-1963/gallery/images/front-cover/iiif/full/372,/0/default.jpg" alt="Cover of L&rsquo;Ecriture et la psychologie des peuples: actes de colloque">&#160;<a href="#fnref:7" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:8" role="doc-endnote">
<p><span class="reftype">Footnote<span class="page">, p. 20</span></span>
<em><a href="https://derridas-margins.princeton.edu/library/bloch-lecriture-et-la-psychologie-des-peuples-actes-de-colloque-1963/#sections">Les écritures indiennes. Le monde indien et son système graphique.</a></em> (1963)<br/>
<cite lang="fr">Cf. par ex. EP. pp. 126, 148, 355, etc. D&rsquo;un autre point de vue, cf. Jakobson, <em>Essais de linguistique générale</em> (tr. fr. p. 116)</cite> (p. 148)
<img src="https://derridas-margins.princeton.edu/library/bloch-lecriture-et-la-psychologie-des-peuples-actes-de-colloque-1963/gallery/images/front-cover/iiif/full/372,/0/default.jpg" alt="Cover of Les écritures indiennes. Le monde indien et son système graphique.">&#160;<a href="#fnref:8" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:9" role="doc-endnote">
<p><span class="reftype">Footnote<span class="page">, p. 20</span></span>
<em><a href="https://derridas-margins.princeton.edu/library/bloch-lecriture-et-la-psychologie-des-peuples-actes-de-colloque-1963/">L&rsquo;Ecriture et la psychologie des peuples: actes de colloque</a></em> (1963)<br/>
<cite lang="fr">Cf. par ex. EP. pp. 126, 148, 355, etc. D&rsquo;un autre point de vue, cf. Jakobson, <em>Essais de linguistique générale</em> (tr. fr. p. 116)</cite> (p. 355)
<img src="https://derridas-margins.princeton.edu/library/bloch-lecriture-et-la-psychologie-des-peuples-actes-de-colloque-1963/gallery/images/front-cover/iiif/full/372,/0/default.jpg" alt="Cover of L&rsquo;Ecriture et la psychologie des peuples: actes de colloque">&#160;<a href="#fnref:9" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:10" role="doc-endnote">
<p><span class="reftype">Footnote<span class="page">, p. 20</span></span>
<em><a href="https://derridas-margins.princeton.edu/library/jakobson-fundamentals-of-language-1963/">Essais de linguistique générale</a></em> (1963)<br/>
Roman Jakobson<br/>
<cite lang="fr">Cf. par ex. EP. pp. 126, 148, 355, etc. D&rsquo;un autre point de vue, cf. Jakobson, <em>Essais de linguistique générale</em> (tr. fr. p. 116)</cite> (p. 116)
<img src="https://derridas-margins.princeton.edu/library/jakobson-fundamentals-of-language-1963/gallery/images/front-cover/thumbnail/" alt="Cover of Essais de linguistique générale">&#160;<a href="#fnref:10" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:11" role="doc-endnote">
<p><span class="reftype">Quotation<span class="page">, p. 21</span></span>
<em><a href="https://derridas-margins.princeton.edu/library/aristotle-organon-categories-de-linterpretation-1959/">Organon: Catégories, De L&rsquo;interprétation</a></em> (1959)<br/>
Aristotle<br/>
<cite lang="fr">Si, pour Aristote, par exemple, « les sons émis par la voix (<em>τὰ ἐν τῇ φωνῇ</em>) sont les symboles des états de l&rsquo;âme (<em>παθήματα τῆς ψυχῆς</em>) et les mots écrits les symboles des mots émis par la voix » (<em>De l&rsquo;interprétation</em> 1, 16 a 3), c&rsquo;est que la voix, productrice des <em>premiers symboles</em>, a un rapport de proximité essentielle et immédiate avec l&rsquo;âme.</cite> (p. 77)
<img src="https://derridas-margins.princeton.edu/library/aristotle-organon-categories-de-linterpretation-1959/gallery/images/front-cover/iiif/full/313,/0/default.jpg" alt="Cover of Organon: Catégories, De L&rsquo;interprétation">&#160;<a href="#fnref:11" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:12" role="doc-endnote">
<p><span class="reftype">Quotation<span class="page">, p. 21</span></span>
<em><a href="https://derridas-margins.princeton.edu/library/aristotle-organon-categories-de-linterpretation-1959/">Organon: Catégories, De L&rsquo;interprétation</a></em> (1959)<br/>
Aristotle<br/>
<cite lang="fr">« De même que l&rsquo;écriture n&rsquo;est pas la même pour tous les hommes, les mots parlés ne sont pas non plus les mêmes, alors que les états de l&rsquo;âme dont ces expressions sont <em>immédiatement les signes</em> (<em>σημεὶα πρώτως</em>) sont identiques chez tous, comme sont identiques aussi les choses dont ces états sont les images » (16 a. Nous soulignons).</cite> (p. 78)
<img src="https://derridas-margins.princeton.edu/library/aristotle-organon-categories-de-linterpretation-1959/gallery/images/front-cover/iiif/full/313,/0/default.jpg" alt="Cover of Organon: Catégories, De L&rsquo;interprétation">&#160;<a href="#fnref:12" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:13" role="doc-endnote">
<p><span class="reftype">Quotation<span class="page">, p. 22</span></span>
<em><a href="https://derridas-margins.princeton.edu/library/hegel-vorlesungen-uber-die-asthetik-1944/">Esthétique, III, I.</a></em> (1944)<br/>
Georg Wilhelm Friedrich Hegel<br/>
<cite lang="fr">« Ce mouvement idéal, par lequel, dirait-on, se manifeste la simple subjectivité, l&rsquo;âme du corps résonnant, l&rsquo;oreille le perçoit de la même manière théorique que celle dont l&rsquo;œil perçoit la couleur ou la forme, l&rsquo;intériorité de l&rsquo;objet devenant ainsi celle du sujet lui-même » (<em>Esthétique</em>, III, I., tr. fr. p. 16).</cite> (p. 16)
<img src="https://derridas-margins.princeton.edu/library/hegel-vorlesungen-uber-die-asthetik-1944/gallery/images/front-cover/thumbnail/" alt="Cover of Esthétique, III, I.">&#160;<a href="#fnref:13" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:14" role="doc-endnote">
<p><span class="reftype">Quotation<span class="page">, p. 22</span></span>
<em><a href="https://derridas-margins.princeton.edu/library/hegel-vorlesungen-uber-die-asthetik-1944/">Esthétique, III, I.</a></em> (1944)<br/>
Georg Wilhelm Friedrich Hegel<br/>
<cite lang="fr">« … L&rsquo;oreille au contraire, sans se tourner pratiquement vers les objets, perçoit le résultat de ce tremblement intérieur du corps par lequel se manifeste et se révèle, non la figure matérielle, mais une première idéalité venant de l&rsquo;âme » (p. 296).</cite> (p. 296)
<img src="https://derridas-margins.princeton.edu/library/hegel-vorlesungen-uber-die-asthetik-1944/gallery/images/front-cover/thumbnail/" alt="Cover of Esthétique, III, I.">&#160;<a href="#fnref:14" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:15" role="doc-endnote">
<p><span class="reftype">Footnote<span class="page">, p. 22</span></span>
<em><a href="https://derridas-margins.princeton.edu/library/?query=aubenque-le-probleme-de-letre-chez-aristote-1962&amp;is_extant=false">Le problème de l&rsquo;être chez Aristote</a></em> <br/>
Pierre Aubenque<br/>
<cite lang="fr">C&rsquo;est ce que montre Pierre Aubenque (<em>Le problème de l&rsquo;être chez Aristote</em>, p. 106 sq.). Au cours d&rsquo;une remarquable analyse, dont nous nous inspirons ici, P. Aubenque note en effet : « Dans d&rsquo;autres textes, il est vrai, Aristote qualifie de symbole le rapport du langage aux choses : &ldquo;Il n&rsquo;est pas possible d&rsquo;apporter dans la discussion les choses elles-mêmes, mais, au lieu des choses, nous devons nous servir de leurs noms comme de symboles.&rdquo; L&rsquo;intermédiaire que constituait l&rsquo;état d&rsquo;âme et ici supprimé ou du moins négligé, mais cette suppression est légitime, puisque les états d&rsquo;âme se comportant comme les choses, celles-ci peuvent leur être immédiatement substituées. En revanche, on ne peut pas substituer, sans plus, le nom à la chose … » (p. 107-108).</cite> (p. 106-108)&#160;<a href="#fnref:15" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:16" role="doc-endnote">
<p><span class="reftype">Footnote<span class="page">, p. 22</span></span>
<em><a href="https://derridas-margins.princeton.edu/library/?query=aubenque-le-probleme-de-letre-chez-aristote-1962&amp;is_extant=false">Le problème de l&rsquo;être chez Aristote</a></em> <br/>
Pierre Aubenque<br/>
<cite lang="fr">C&rsquo;est ce que montre Pierre Aubenque (<em>Le problème de l&rsquo;être chez Aristote</em>, p. 106 sq.). Au cours d&rsquo;une remarquable analyse, dont nous nous inspirons ici, P. Aubenque note en effet : « Dans d&rsquo;autres textes, il est vrai, Aristote qualifie de symbole le rapport du langage aux choses : &ldquo;Il n&rsquo;est pas possible d&rsquo;apporter dans la discussion les choses elles-mêmes, mais, au lieu des choses, nous devons nous servir de leurs noms comme de symboles.&rdquo; L&rsquo;intermédiaire que constituait l&rsquo;état d&rsquo;âme et ici supprimé ou du moins négligé, mais cette suppression est légitime, puisque les états d&rsquo;âme se comportant comme les choses, celles-ci peuvent leur être immédiatement substituées. En revanche, on ne peut pas substituer, sans plus, le nom à la chose … » (p. 107-108).</cite> (p. 107-108)&#160;<a href="#fnref:16" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:17" role="doc-endnote">
<p><span class="reftype">Quotation<span class="page">, p. 24</span></span>
<em><a href="https://derridas-margins.princeton.edu/library/jakobson-fundamentals-of-language-1963/">Essais de linguistique générale</a></em> (1963)<br/>
Roman Jakobson<br/>
<cite lang="fr">La pensée structuraliste moderne l&rsquo;a clairement établi : le langage est un système de signes, la linguistique est partie intégrante de la science des signes, la <em>sémiotique</em> (ou, dans les termes de Saussure, la <em>sémiologie</em>). La définition médiévale – aliquid stat pro aliquo – que notre époque a ressuscité, s&rsquo;est montrée toujours valable et féconde. C&rsquo;est ainsi que la marque constitutive de tout signe en général, du signe linguistique en particulier, réside dans son caractère double : chaque unité linguistique est bipartite et comporte deux aspects ; l&rsquo;un sensible et l&rsquo;autre intelligible – d&rsquo;une part le signans (le <em>signifiant</em> de Saussure), d&rsquo;autre part le <em>signatum</em> (le signifié). Ces deux éléments constitutifs du signe linguistique (et du signe en général) se supposent et s&rsquo;appellent nécessairement l&rsquo;un l&rsquo;autre. »</cite> (p. 162)
<img src="https://derridas-margins.princeton.edu/library/jakobson-fundamentals-of-language-1963/gallery/images/front-cover/thumbnail/" alt="Cover of Essais de linguistique générale">&#160;<a href="#fnref:17" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:18" role="doc-endnote">
<p><span class="reftype">Footnote<span class="page">, p. 24</span></span>
<em><a href="https://derridas-margins.princeton.edu/library/?query=ortigues-le-discours-et-le-symbole-1962&amp;is_extant=false">Le discours et le symbole</a></em> (1962)<br/>
Edmond Ortigues<br/>
<cite lang="fr">Sur ce problème, sur la tradition du concept du signe et sur l&rsquo;originalité de l&rsquo;apport saussurien à l&rsquo;intérieur de cette continuité, cf. Ortigues, <em>op. cit</em>, p. 54 sq.</cite> (p. 54)&#160;<a href="#fnref:18" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:19" role="doc-endnote">
<p><span class="reftype">Quotation<span class="page">, p. 26</span></span>
<em><a href="https://derridas-margins.princeton.edu/library/plato-phaedrus-1964/">Phaedrus</a></em> (1964)<br/>
Plato<br/>
<cite lang="fr">l&rsquo;écriture de la vérité dans l&rsquo;âme, opposée par le <em>Phèdre</em> (278 a) à la mauvaise écriture (à l&rsquo;écriture au sens « propre » et courant, à l&rsquo;écriture « sensible », « dans l&rsquo;espace »)</cite> (p. 170)
<img src="https://derridas-margins.princeton.edu/library/plato-phaedrus-1964/gallery/images/00000001tif/thumbnail/" alt="Cover of Phaedrus">&#160;<a href="#fnref:19" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:20" role="doc-endnote">
<p><span class="reftype">Quotation<span class="page">, p. 26</span></span>
<em><a href="https://derridas-margins.princeton.edu/library/plato-phaedrus-1938/">Phèdre</a></em> <br/>
Plato<br/>
<cite lang="fr">l&rsquo;écriture de la vérité dans l&rsquo;âme, opposée par le <em>Phèdre</em> (278 a) à la mauvaise écriture (à l&rsquo;écriture au sens « propre » et courant, à l&rsquo;écriture « sensible », « dans l&rsquo;espace »)</cite> (p. 289)
<img src="https://derridas-margins.princeton.edu/library/plato-phaedrus-1938/gallery/images/front-cover/iiif/full/290,/0/default.jpg" alt="Cover of Phèdre">&#160;<a href="#fnref:20" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:21" role="doc-endnote">
<p><span class="reftype">Quotation<span class="page">, p. 26</span></span>
<em><a href="https://derridas-margins.princeton.edu/library/plato-phaedrus-1961/">Phèdre</a></em> (1961)<br/>
Plato<br/>
<cite lang="fr">l&rsquo;écriture de la vérité dans l&rsquo;âme, opposée par le <em>Phèdre</em> (278 a) à la mauvaise écriture (à l&rsquo;écriture au sens « propre » et courant, à l&rsquo;écriture « sensible », « dans l&rsquo;espace »)</cite> (p. 94)
<img src="https://derridas-margins.princeton.edu/library/plato-phaedrus-1961/gallery/images/front-cover/thumbnail/" alt="Cover of Phèdre">&#160;<a href="#fnref:21" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:22" role="doc-endnote">
<p><span class="reftype">Quotation<span class="page">, p. 26</span></span>
<em><a href="https://derridas-margins.princeton.edu/library/curtius-la-litterature-europeenne-et-le-moyen-age-latin-1956/">La littérature européenne et le Moyen Âge latin</a></em> (1956)<br/>
Ernst Robert Curtius<br/>
<cite lang="fr">Dans <em>Le symbolisme du livre</em>, ce beau chapitre de *La littérature européenne et le Moyen Âge latin, E. R. Curtius décrit avec une grande richesse d&rsquo;exemples l&rsquo;évolution qui conduit du <em>Phèdre</em> à Calderon, jusqu&rsquo;à paraître « inverser la situation » (tr. fr. p. 372) par la « nouvelle considération dont jouissait le livre » (p. 374).</cite> (p. 372)
<img src="https://derridas-margins.princeton.edu/library/curtius-la-litterature-europeenne-et-le-moyen-age-latin-1956/gallery/images/front-cover/thumbnail/" alt="Cover of La littérature européenne et le Moyen Âge latin">&#160;<a href="#fnref:22" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:23" role="doc-endnote">
<p><span class="reftype">Quotation<span class="page">, p. 26</span></span>
<em><a href="https://derridas-margins.princeton.edu/library/curtius-la-litterature-europeenne-et-le-moyen-age-latin-1956/">La littérature européenne et le Moyen Âge latin</a></em> (1956)<br/>
Ernst Robert Curtius<br/>
<cite lang="fr">Dans <em>Le symbolisme du livre</em>, ce beau chapitre de *La littérature européenne et le Moyen Âge latin, E. R. Curtius décrit avec une grande richesse d&rsquo;exemples l&rsquo;évolution qui conduit du <em>Phèdre</em> à Calderon, jusqu&rsquo;à paraître « inverser la situation » (tr. fr. p. 372) par la « nouvelle considération dont jouissait le livre » (p. 374).</cite> (p. 476)
<img src="https://derridas-margins.princeton.edu/library/curtius-la-litterature-europeenne-et-le-moyen-age-latin-1956/gallery/images/front-cover/thumbnail/" alt="Cover of La littérature européenne et le Moyen Âge latin">&#160;<a href="#fnref:23" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:24" role="doc-endnote">
<p><span class="reftype">Quotation<span class="page">, p. 26</span></span>
<em><a href="https://derridas-margins.princeton.edu/library/curtius-la-litterature-europeenne-et-le-moyen-age-latin-1956/">La littérature européenne et le Moyen Âge latin</a></em> (1956)<br/>
Ernst Robert Curtius<br/>
<cite lang="fr">Dans <em>Le symbolisme du livre</em>, ce beau chapitre de *La littérature européenne et le Moyen Âge latin, E. R. Curtius décrit avec une grande richesse d&rsquo;exemples l&rsquo;évolution qui conduit du <em>Phèdre</em> à Calderon, jusqu&rsquo;à paraître « inverser la situation » (tr. fr. p. 372) par la « nouvelle considération dont jouissait le livre » (p. 374).</cite> (p. 476)
<img src="https://derridas-margins.princeton.edu/library/curtius-la-litterature-europeenne-et-le-moyen-age-latin-1956/gallery/images/front-cover/thumbnail/" alt="Cover of La littérature européenne et le Moyen Âge latin">&#160;<a href="#fnref:24" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:25" role="doc-endnote">
<p><span class="reftype">Quotation<span class="page">, p. 27</span></span>
<em><a href="https://derridas-margins.princeton.edu/library/levinas-difficile-liberte-essais-sur-le-judaisme-1963/">Difficile liberté</a></em> (1963)<br/>
Emmanuel Levinas<br/>
<cite lang="fr">Rabbi Eliezer a dit : « Si toutes les mers étaient d&rsquo;encre, tous les étangs plantés de calames, si le ciel et la terre étaient des parchemins et si tous les humains exerçaient l&rsquo;art d&rsquo;écrire – ils n&rsquo;épuiseraient pas la Thora apprise par moi, alors que la Thora elle-même ne s&rsquo;en trouve diminuée que d&rsquo;autant qu&rsquo;emporte la pointe du pinceau trempé dans la mer. »</cite> (p. 44)
<img src="https://derridas-margins.princeton.edu/library/levinas-difficile-liberte-essais-sur-le-judaisme-1963/gallery/images/front-cover/thumbnail/" alt="Cover of Difficile liberté">&#160;<a href="#fnref:25" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:26" role="doc-endnote">
<p><span class="reftype">Quotation<span class="page">, p. 27</span></span>
<em><a href="https://derridas-margins.princeton.edu/library/?query=galilei-il-saggiatore-1623&amp;is_extant=false">Il Saggiatore</a></em> (1623)<br/>
Galileo Galilei<br/>
<cite lang="fr">« La nature est écrite en langage mathématique. »</cite>&#160;<a href="#fnref:26" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:27" role="doc-endnote">
<p><span class="reftype">Quotation<span class="page">, p. 27</span></span>
<em><a href="https://derridas-margins.princeton.edu/library/descartes-discours-de-la-methode-1943/">Discours de la méthode</a></em> (1943)<br/>
René Descartes<br/>
<cite lang="fr">« … à lire le grand livre du monde… »</cite> (p. 51)
<img src="https://derridas-margins.princeton.edu/library/descartes-discours-de-la-methode-1943/gallery/images/front-cover/iiif/full/291,/0/default.jpg" alt="Cover of Discours de la méthode">&#160;<a href="#fnref:27" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:28" role="doc-endnote">
<p><span class="reftype">Quotation<span class="page">, p. 27</span></span>
<em><a href="https://derridas-margins.princeton.edu/library/descartes-discours-de-la-methode-1961/">Discours de la méthode</a></em> (1961)<br/>
René Descartes<br/>
<cite lang="fr">« … à lire le grand livre du monde… »</cite> (p. 51)
<img src="https://derridas-margins.princeton.edu/library/descartes-discours-de-la-methode-1961/gallery/images/front-cover/iiif/full/291,/0/default.jpg" alt="Cover of Discours de la méthode">&#160;<a href="#fnref:28" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:29" role="doc-endnote">
<p><span class="reftype">Quotation<span class="page">, p. 27</span></span>
<em><a href="https://derridas-margins.princeton.edu/library/hume-dialogues-concerning-natural-religion-1964/">Dialogues sur la religion naturelle</a></em> (1964)<br/>
David Hume<br/>
<cite lang="fr">« Et ce livre qu&rsquo;est la nature contient une grande et inexplicable énigme, plutôt qu&rsquo;aucun discours ou raisonnement intelligible. »</cite> (p. 73)
<img src="https://derridas-margins.princeton.edu/library/hume-dialogues-concerning-natural-religion-1964/gallery/images/front-cover/thumbnail/" alt="Cover of Dialogues sur la religion naturelle">&#160;<a href="#fnref:29" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:30" role="doc-endnote">
<p><span class="reftype">Quotation<span class="page">, p. 27</span></span>
<em><a href="https://derridas-margins.princeton.edu/library/?query=bonnet-la-palingenesie-philosophique-1769&amp;is_extant=false">La palingénésie philosophique</a></em> <br/>
Charles Bonnet<br/>
<cite lang="fr">« Il me paraît plus philosophique de présumer que notre terre est un livre que le grand Être a donné à lire à des intelligences qui nous sont fort supérieures, et où elles étudient à fond les traits infiniment multiples et variés de son adorable sagesse. »</cite>&#160;<a href="#fnref:30" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:31" role="doc-endnote">
<p><span class="reftype">Quotation<span class="page">, p. 27</span></span>
<em><a href="https://derridas-margins.princeton.edu/library/?query=von-schubert-la-symbolique-du-reve-die-symbolik-des-traumes-1815&amp;is_extant=false">La symbolique du rêve/ Die Symbolik des Traumes</a></em> (1815)<br/>
Gotthilf Heinrich von Schubert<br/>
<cite lang="fr">« Cette langue faite d&rsquo;images et d&rsquo;hiéroglyphes, dont se sert la Sagesse suprême dans toutes ses révélations à l&rsquo;humanité – qui se retrouve dans le langage tout voisin de la Poésie – et qui, dans notre condition actuelle, ressemble davantage à l&rsquo;expression métaphorique du rêve qu&rsquo;à la prose de la veille, – on peut se demander si cette langue n&rsquo;est pas la véritable langue de la religion supérieure. Si, tandis que nous nous croyons éveillés, nous ne sommes pas plongés dans un sommeil millénaire, ou au moins dans l&rsquo;écho de ses rêves, où nous ne percevons de la langue de Dieu que quelques paroles isolées et obscures, comme un dormeur perçoit les discours de son entourage. »</cite>&#160;<a href="#fnref:31" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</section>
]]></content></entry></feed>