<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom"><generator uri="https://gohugo.io/" version="0.72.0">Hugo</generator><title type="html">Issue One on Startwords</title><link href="https://startwords.cdh.princeton.edu/issues/1/" rel="alternate" type="text/html" title="HTML"/><link href="https://startwords.cdh.princeton.edu/issues/1/index.xml" rel="alternate" type="application/rss+xml" title="RSS"/><link href="https://startwords.cdh.princeton.edu/issues/1/atom.xml" rel="self" type="application/atom+xml" title="Atom"/><updated>2020-10-23T20:34:48+00:00</updated><rights>This work is licensed under a Creative Commons Attribution 4.0 International License.</rights><author><name>Center for Digital Humanities at Princeton</name><email>cdh-info@princeton.edu</email></author><id>https://startwords.cdh.princeton.edu/issues/1/</id><entry><title type="html">Data Beyond Vision</title><link href="https://startwords.cdh.princeton.edu/issues/1/data-beyond-vision/?utm_source=atom_feed" rel="alternate" type="text/html"/><id>https://startwords.cdh.princeton.edu/issues/1/data-beyond-vision/</id><author><name>Rebecca Sutton Koeser</name></author><author><name>Gissoo Doroudian</name></author><author><name>Nick Budak</name></author><author><name>Xinyi Li</name></author><published>2020-10-01T00:00:00+00:00</published><updated>2020-10-23T16:32:45-04:00</updated><content type="html"><![CDATA[<p>How do we represent tangible objects in a visual medium? We use words, pictures, and diagrams. We describe, share, show, and fail.</p>
<p>Humanists continue to expand the range of objects they study, but the range of scholarly outputs has not seen a similar expansion. While there are movements within Digital Humanities to consider nontraditional formats, the presentation and publishing of these experimental works (such as installations and project demos) is still secondary or sidelined, where it exists at all. What would it look like to consider non-textual research outputs as first-order scholarly work? The historian David Staley suggests the terms “interpretive objects” or “humanistic objects” for creative scholarly acts that are not limited to text<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>; Catherine D’Ignazio and Lauren Klein offer the broader term “rhetorical objects.”<sup id="fnref:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup>  Innovative work like this is carefully researched and theorized. It deserves scholarly engagement and intellectual rigor even if it does not fit into established modes of scholarly communication.</p>
<p>Academic research has a long history of textual practice and citation that we haven’t yet figured out how to adapt to non-textual scholarship. The <a href="https://openhumanitiesdata.metajnl.com/">Journal of Open Humanities Data</a> and The <a href="https://joss.theoj.org/">Journal of Open Source Software</a> can both be seen as steps in this direction: they provide venues for the review and publication of data and software, respectively, accompanied by brief “metapapers.” But even these rely on transforming the content they review—data and software—into text in order to function! What are the implications if we truly expand the range of accepted scholarly outputs to include such interpretive objects as data structures, databases, software, datasets, physical objects, and augmented reality experiences? Will scholars need to become experts in all these modes, or can we find a way to become conversant in multiple forms of argumentation, as with other important scholarly theories?</p>
<p>The pieces that follow describe four different data physicalizations, which we consider to be one class of interpretive object. This is an exploration of our work as we wrestle with how to present physical objects in a non-physical medium, objects meant to be held, touched, or viewed from different angles. Not quite metapaper, manual, or manifesto — these are guides towards reading and thinking in creative new scholarly modes.<sup id="fnref:3"><a href="#fn:3" class="footnote-ref" role="doc-noteref">3</a></sup></p>
<div class="" id="interlude">
<div class="left" id="">
<p><strong>SEE</strong></p>
<p>from a distance.<br>
Cold, commanding.<br>
Sense of mastery,<br>
but optical illusions deceive.</p>
<p>Look in a mirror.<br>
and see yourself<br>
seeing.</p>
</div>
<div class="right" id="">
<p><strong>TOUCH</strong></p>
<p>up close.<br>
Intimate, incomplete.<br>
Explore partial knowledge,<br>
enlighten slowly.</p>
<p>Run fingers across skin<br>
and touch yourself<br>
touching.</p>
</div>

</div>
<p>Data physicalization represents data in physical form.<sup id="fnref:4"><a href="#fn:4" class="footnote-ref" role="doc-noteref">4</a></sup> Like other approaches to understanding and representing data, it highlights particular senses to communicate information, specifically touch and sight.<sup id="fnref:5"><a href="#fn:5" class="footnote-ref" role="doc-noteref">5</a></sup> But data physicalization is distinct from other sensory approaches in that it bridges the gap between creative, physical, and conceptual exploration, a nexus often associated with critical making.<sup id="fnref:6"><a href="#fn:6" class="footnote-ref" role="doc-noteref">6</a></sup> Data physicalizations surface the amount of labor involved with data production and representation, they lend data different perspectives and dimensions.<sup id="fnref:7"><a href="#fn:7" class="footnote-ref" role="doc-noteref">7</a></sup> These physicalizations also create an opportunity for viewers to become active participants in the making of a piece using data.</p>
<p>Data physicalization attempts to defamiliarize us from the many two-dimensional data representations we have seen by literally placing data in the <em>mise en scène</em> of a conceptual exploration. There is something unique about turning data points into physical forms and placing them in space that triggers the mind to understand data in a distinctive way.</p>
<p>











 


<figure aria-describedby="conceptmap-desc">
    <img loading="lazy" alt="Diagram defining the relationships between various data representations and the senses they incorporate; content available in description" role="img" sizes="(max-width: 768px) 100%, 80%"src="/issues/1/data-beyond-vision/images/conceptmap.svg"><figcaption>
        <p>Concept map situating data physicalization in relation to other types of data representations and interpretations. Revised from the concept map included in the poster presented by the authors at DH2019 in Utrecht. Koeser, Rebecca Sutton, Nick Budak, Gissoo Doroudian, and Xinyi Li. “Data Beyond Vision,” July 11, 2019.
        </p>
    </figcaption>
</figure>
<div class="txt-only" id="">
⩩&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;⟩
| FIGURE.
|
| CAPTION: Concept map situating data physicalization in relation to other types of data representations and interpretations. Revised from the concept map included in the poster presented by the authors at DH2019 in Utrecht.
| ATTRIBUTION: Koeser, Rebecca Sutton, Nick Budak, Gissoo Doroudian, and Xinyi Li. “Data Beyond Vision,” July 11, 2019.
| LINK: <a href="https://doi.org/10.5281/zenodo.3261531">https://doi.org/10.5281/zenodo.3261531</a>
⩩&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;⟩
</div>
<div class="sr-only" id="conceptmap-desc">
<p>Other approaches for data representation and interpretation include:</p>
<ul>
<li>Data Visualization, which focuses on storytelling by using graphical elements</li>
<li>Data Edibilization, which focuses on experiencing data through food using edible materials</li>
<li>Data Sonification, which focuses on auditory patterns by using sound</li>
<li>Data Visceralization, which focuses on physical and emotional experience by using multiple senses and affect, making it the only approach that emphasizes emotion.</li>
<li>Data Art, which focuses on representing links between data and artistic creations by using expressive frameworks and raw data.</li>
<li>Interpretive object, which focuses on revealing meanings and relationships via non-textual forms by using metaphors.</li>
</ul>

</div></p>
<p>There is an ethics of drawing on other senses. Feminist philosopher Donna Haraway describes “visualizing technologies” as the “god trick of seeing everything from nowhere.”<sup id="fnref:8"><a href="#fn:8" class="footnote-ref" role="doc-noteref">8</a></sup> Klein and D’Ignazio expand on this, demonstrating that the assumed neutrality and objectivity of even the simplest visualizations always come from a particular perspective, usually a dominant cultural view that fundamentally excludes and marginalizes.</p>
<p>This is especially the case when making data visualization accessible to vision-impaired readers. The typical solution is to provide a table with the data underlying the chart or graph. This isn’t practical for large datasets, and it’s clearly not the same experience; otherwise, we would provide the tabular data to all users. Another approach is to provide an extended description sharing the insights gained from the chart.<sup id="fnref:9"><a href="#fn:9" class="footnote-ref" role="doc-noteref">9</a></sup> This is helpful, but pre-digesting the chart in this way doesn’t allow readers to perceive and interpret the patterns and draw their own conclusions. Tactile data physicalizations provide sensory forms that offer individuals the opportunity to explore and discover patterns in the data for themselves.</p>
<p>Approaching an object like a data physicalization on display encourages bodily engagement in physical space. It encourages the person encountering it to consider multiple angles and perspectives, and it should raise questions about how the objects are meant to be read. This touching requires proximity and a certain intimacy.<sup id="fnref:10"><a href="#fn:10" class="footnote-ref" role="doc-noteref">10</a></sup> For Emmanuel Levinas, the “ocularcentrism” of western civilization has produced a false sense that vision is synonymous with objectivity; he proposes instead the metaphor of touch as the basis for ethical engagement with the Other. Ocularcentrism requires distance or separation and encourages objectification and mastery<sup id="fnref:11"><a href="#fn:11" class="footnote-ref" role="doc-noteref">11</a></sup> of that which is viewed. French feminist philosopher Luce Irigaray extends this metaphor<sup id="fnref:12"><a href="#fn:12" class="footnote-ref" role="doc-noteref">12</a></sup> in her notion of the “caress”, which “weds without consum(mat)ing”. Because touch requires intimacy, boundaries, and consent, it offers connection without the taint of mastery.<sup id="fnref:13"><a href="#fn:13" class="footnote-ref" role="doc-noteref">13</a></sup></p>
<hr>
<p>These are not artist statements because this is not art; these objects might look like Data Art, but the goals and methods are different. This is representation, correspondence, laborious translation. These are our attempts to communicate our goals, to help you <em>read</em> and interpret these unfamiliar objects, and to be challenged by the potential of physicalization.</p>
<p>We invite you to participate in the embodiment and visible labor of data work. Download the following models and instructions, use your hands to recreate the data physicalizations we developed, or use them as inspiration to make your own interpretive objects. If you make any of these physicalizations, please share them on social media with the hashtag <a href="https://twitter.com/search?q=(%23DataBeyondVision)">#DataBeyondVision</a>.</p>
<div class="icon-nav" id="">
<span class="help">Choose an object</span>
<a href="#folding"><img src="images/icon-folding.svg" alt="read folding section"></a>
<a href="#modeling"><img src="images/icon-printing.svg" alt="read modeling section"></a>
<a href="#weaving"><img src="images/icon-weaving.svg" alt="read weaving section"></a>
<a href="#stacking"><img src="images/icon-stacking.svg" alt="read stacking section"></a>
</div>
<h2 id="folding">Folding in the Lesser-Known Members of the Shakespeare and Company Library</h2>
<p><em>Nick Budak, Xinyi Li</em></p>
<h3 id="goal">Goal</h3>
<p>The Shakespeare and Company lending library is most often known by its famous members — writers such as Gertrude Stein, James Joyce, Ernest Hemingway, Aimé Césaire, Simone de Beauvoir. We wanted to highlight the activity of the relatively unknown members — frequently women — who in fact represent a much larger portion of the library&rsquo;s day-to-day activity and thus arguably better represent it. This piece makes use of unit origami<sup id="fnref:14"><a href="#fn:14" class="footnote-ref" role="doc-noteref">14</a></sup> to create a larger, cohesive form from small folded units, mirroring the relationship between a single member and the overall membership of the library.</p>
<p>











 








<figure>
    <img loading="lazy" alt="Folded origami model of a green cube intersecting a white octahedron covered with printed text." role="img" sizes="(max-width: 768px) 100%, 80%"srcset="/issues/1/data-beyond-vision/images/folding-installation-photo_hue8cc9d37f77dd4cd10109019f3675f97_9534334_500x0_resize_q75_box.jpg 500w,
    /issues/1/data-beyond-vision/images/folding-installation-photo_hue8cc9d37f77dd4cd10109019f3675f97_9534334_800x0_resize_q75_box.jpg 800w,
    /issues/1/data-beyond-vision/images/folding-installation-photo_hue8cc9d37f77dd4cd10109019f3675f97_9534334_1200x0_resize_q75_box.jpg 1200w,
    /issues/1/data-beyond-vision/images/folding-installation-photo_hue8cc9d37f77dd4cd10109019f3675f97_9534334_1500x0_resize_q75_box.jpg 1500w,
    /issues/1/data-beyond-vision/images/folding-installation-photo_hue8cc9d37f77dd4cd10109019f3675f97_9534334_1800x0_resize_q75_box.jpg 1800w,
    /issues/1/data-beyond-vision/images/folding-installation-photo.jpg 5472w"
     class="landscape"><figcaption>
        <p>Completed piece on display at the Center for Digital Humanities, with early drafts visible in background.
        </p>
    </figcaption>
</figure>
<div class="txt-only" id="">
⩩&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;⟩
| FIGURE. Folded origami model of a green cube intersecting a white octahedron covered with printed text.
|
| CAPTION: Completed piece on display at the Center for Digital Humanities, with early drafts visible in background.
| ATTRIBUTION: Photo by Shelley Szwast.
⩩&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;⟩
</div></p>
<h3 id="description">Description</h3>
<p>The physicalization contrasts the activity of the better-known members of the lending library — those linked by researchers to an entry in the <a href="https://viaf.org/">Virtual International Authority File (VIAF)</a><sup id="fnref:15"><a href="#fn:15" class="footnote-ref" role="doc-noteref">15</a></sup> — with the activity of relatively unknown members with no known authority record.<sup id="fnref:16"><a href="#fn:16" class="footnote-ref" role="doc-noteref">16</a></sup> Activity is represented by the total number of borrowing events that would plausibly have brought members into the library, namely checking out and returning books. Names of the lesser known members are printed on the paper used to create the octahedron as a way of corporealizing and “re-humanizing” humanities data.<sup id="fnref:17"><a href="#fn:17" class="footnote-ref" role="doc-noteref">17</a></sup> By holding the physicalization in two different ways, the user can “grasp” two separate sets of data: the octahedron (non-famous members) and the cube (famous members). The ratio of the volumes of these two solids reflects the use of the library by these two different groups.<sup id="fnref:18"><a href="#fn:18" class="footnote-ref" role="doc-noteref">18</a></sup></p>
<p>
<div class="sketchfab-embed-wrapper">
    <iframe
        id="sketchfab-9c96fadd27c34a11902f0a1281ea0ab4"
        aria-label="Two different still images of the model rotated in the 3d viewer, emphasizing the two shapes combined in the object, the cube and the octahedron."
        frameborder="0"
        allow="autoplay; fullscreen; vr"
        mozallowfullscreen="true"
        webkitallowfullscreen="true"
        loading="lazy"
        src="https://sketchfab.com/models/9c96fadd27c34a11902f0a1281ea0ab4/embed?autospin=0.2&amp;autostart=0&amp;camera=0&amp;preload=1&amp;ui_controls=1&amp;ui_infos=1&amp;ui_inspector=1&amp;ui_stop=1&amp;ui_watermark=1&amp;ui_watermark_link=1">
    </iframe>
    
    
</div>

<div class="txt-only" id="">
⩩&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;⟩
| FIGURE. 3-D model of a green cube intersecting a white octahedron covered with printed text.
⩩&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;⟩
</div></p>
<h3 id="insights">Insights</h3>
<p>











 


<figure aria-describedby="pie-desc">
    <img loading="lazy" alt="A pie chart with a 70% majority section labeled “no VIAF” in green, with the remainder labeled “VIAF”." role="img" sizes="(max-width: 768px) 100%, 80%"style="max-height: 400px"src="/issues/1/data-beyond-vision/images/folding_viaf_pie_v2-01.svg"><figcaption>
        <p>A pie chart representing the proportions of members with and without VIAF identification.
        </p>
    </figcaption>
</figure>
<div class="txt-only" id="">
⩩&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;⟩
| FIGURE. A pie chart with a 70% majority section labeled “no VIAF” in green, with the remainder labeled “VIAF”.
|
| CAPTION: A pie chart representing the proportions of members with and without VIAF identification.
⩩&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;⟩
</div>
<div class="sr-only" id="pie-desc">
The majority section of the pie chart represents the 14,583 library members who we identified as “lesser-known” because they are not listed in VIAF. The minority section represents the 6,248 members who are listed in VIAF, often because they were involved with a well-known creative work.
</div></p>
<p>A pie chart can be used to present the same ratio of data conveyed in the physicalization; this representation is useful when we want to illustrate a situation where we know the totality of the data. Pie charts also depict a world where data fits neatly into mutually exclusive categories. The act of grasping the two intersecting solids in our physicalization is a response to this approach: the membership data of the lending library is a work in progress, updated as researchers comb through archives that are fragmentary and incomplete. One cannot see all sides of a three-dimensional solid simultaneously. By representing our data as intersecting solids, we instead mirror the fuzzy distinction between “famous” and “non-famous” members, acknowledging the intersection of the varied identities of the library’s members.<sup id="fnref:19"><a href="#fn:19" class="footnote-ref" role="doc-noteref">19</a></sup></p>
<h3 id="next-steps">Next Steps</h3>
<p>Using cut, punched, or embossed paper would make the piece more tactile; instead of simply printing names, unique patterns could be added to represent membership and borrowing activities for individual members. In the future, we could use generative methods to create unique folding patterns for individual library member activity and make them available via print-on-demand, which would enable viewers to become participants and turn folding into an act of recovery of the stories of the lesser-known library members.<sup id="fnref:20"><a href="#fn:20" class="footnote-ref" role="doc-noteref">20</a></sup></p>
<div class="icon-nav" id="">
<span class="help">Choose a different object</span>
<a href="#modeling"><img src="images/icon-printing.svg" alt="read modeling section"></a>
<a href="#weaving"><img src="images/icon-weaving.svg" alt="read weaving section"></a>
<a href="#stacking"><img src="images/icon-stacking.svg" alt="read stacking section"></a>
</div>
<h2 id="modeling">Modeling Shakespeare and Company Library Membership</h2>
<p><em>Rebecca Sutton Koeser</em></p>
<h3 id="goal-1">Goal</h3>
<p>











 








<figure>
    <img loading="lazy" alt="3D printed object and accompanying 3D printed labels laid out on a table; this side view shows labels for the years, 1919–1942." role="img" sizes="(max-width: 768px) 100%, 80%"srcset="/issues/1/data-beyond-vision/images/modeling-side-view_hu5bc641453e1033078d4f48224daca5b0_4425375_500x0_resize_q75_box.jpg 500w,
    /issues/1/data-beyond-vision/images/modeling-side-view_hu5bc641453e1033078d4f48224daca5b0_4425375_800x0_resize_q75_box.jpg 800w,
    /issues/1/data-beyond-vision/images/modeling-side-view_hu5bc641453e1033078d4f48224daca5b0_4425375_1200x0_resize_q75_box.jpg 1200w,
    /issues/1/data-beyond-vision/images/modeling-side-view_hu5bc641453e1033078d4f48224daca5b0_4425375_1500x0_resize_q75_box.jpg 1500w,
    /issues/1/data-beyond-vision/images/modeling-side-view_hu5bc641453e1033078d4f48224daca5b0_4425375_1800x0_resize_q75_box.jpg 1800w,
    /issues/1/data-beyond-vision/images/modeling-side-view.jpg 3400w"
     class="landscape"><figcaption>
        <p>Side view of 3D printed lollipop chart with labels and statement.
        </p>
    </figcaption>
</figure>
<div class="txt-only" id="">
⩩&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;⟩
| FIGURE. 3D printed object and accompanying 3D printed labels laid out on a table; this side view shows labels for the years, 1919–1942.
|
| CAPTION: Side view of 3D printed lollipop chart with labels and statement.
| ATTRIBUTION: Photo by Shelley Szwast.
⩩&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;⟩
</div></p>
<p>This data physicalization demonstrates the affordances of three dimensions for representing data: time series data are displayed with sequential months and years adjacent to each other, which makes it easier to discern seasonal and annual trends. I hope to inspire others to try experimental approaches to representing data; writing software to generate printable 3D models directly from the data makes the process reproducible, and may eventually enable others to create and print their own physicalizations. The tactile nature of the object suggests the possibilities of 3D printing to create more accessible representations of data.</p>
<p>











 








<figure>
    <img loading="lazy" alt="Alternating rows of white and green “lollipops” fade into the distance and out of focus, with the white data points noticeably larger in the foreground." role="img" sizes="(max-width: 768px) 100%, 80%"srcset="/issues/1/data-beyond-vision/images/modeling-close-up_hub2dfc5608e8305f7eaaaae3e90a5c8a5_5473478_500x0_resize_q75_box.jpg 500w,
    /issues/1/data-beyond-vision/images/modeling-close-up_hub2dfc5608e8305f7eaaaae3e90a5c8a5_5473478_800x0_resize_q75_box.jpg 800w,
    /issues/1/data-beyond-vision/images/modeling-close-up_hub2dfc5608e8305f7eaaaae3e90a5c8a5_5473478_1200x0_resize_q75_box.jpg 1200w,
    /issues/1/data-beyond-vision/images/modeling-close-up_hub2dfc5608e8305f7eaaaae3e90a5c8a5_5473478_1500x0_resize_q75_box.jpg 1500w,
    /issues/1/data-beyond-vision/images/modeling-close-up_hub2dfc5608e8305f7eaaaae3e90a5c8a5_5473478_1800x0_resize_q75_box.jpg 1800w,
    /issues/1/data-beyond-vision/images/modeling-close-up.jpg 3400w"
     class="landscape"><figcaption>
        <p>Close up of 3D printed lollipop chart with labels.
        </p>
    </figcaption>
</figure>
<div class="txt-only" id="">
⩩&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;⟩
| FIGURE. Alternating rows of white and green “lollipops” fade into the distance and out of focus, with the white data points noticeably larger in the foreground.
|
| CAPTION: Close up of 3D printed lollipop chart with labels.
| ATTRIBUTION: Photo by Shelley Szwast.
⩩&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;⟩
</div></p>
<h3 id="description-1">Description</h3>
<p>This is a two-variable, three-dimensional lollipop chart<sup id="fnref:21"><a href="#fn:21" class="footnote-ref" role="doc-noteref">21</a></sup> showing the membership of the Shakespeare and Company lending library, by month and year, from November 1919 when Sylvia Beach opened her bookshop to its official closing in 1941. Membership data is drawn from two different sources, both of which are incomplete: broad membership information comes from <a href="https://shakespeareandco.princeton.edu/sources/logbooks/">logbooks</a> (although logbooks for 1930, parts of 1931-32, and 1937 are missing); detailed borrowing histories come from <a href="https://shakespeareandco.princeton.edu/sources/cards/">lending library cards</a> for a subset of members.<sup id="fnref:22"><a href="#fn:22" class="footnote-ref" role="doc-noteref">22</a></sup> The white octahedrons represent the number of members with an active membership in each month; the green icospheres<sup id="fnref:23"><a href="#fn:23" class="footnote-ref" role="doc-noteref">23</a></sup> correspond to the number of members with borrowing activity in each month. For any month where the value is zero, there is no lollipop. Representing the two different datasets as adjacent, half lollipops exposes the discrepancies between the stories these sources tell us about the membership of the library without privileging either of them.<sup id="fnref:24"><a href="#fn:24" class="footnote-ref" role="doc-noteref">24</a></sup> Using two different shapes makes the two parts of the physicalization distinguishable to touch. The two lollipop charts are designed to be printed independently and then assembled, so that any 3D printer can be used. In this version, the two pieces slide together; this is both a simplification and an improvement over the previous version, where one piece was placed on top of the other.<sup id="fnref:25"><a href="#fn:25" class="footnote-ref" role="doc-noteref">25</a></sup></p>
<p>
<div class="sketchfab-embed-wrapper">
    <iframe
        id="sketchfab-89985d66f7244d87b7edbe5fd6266f0d"
        aria-label="3-D model of Shakespeare and Company membership lollipop chart."
        frameborder="0"
        allow="autoplay; fullscreen; vr"
        mozallowfullscreen="true"
        webkitallowfullscreen="true"
        loading="lazy"
        src="https://sketchfab.com/models/89985d66f7244d87b7edbe5fd6266f0d/embed?autospin=0.2&amp;autostart=0&amp;camera=0&amp;preload=1&amp;ui_controls=1&amp;ui_infos=1&amp;ui_inspector=1&amp;ui_stop=1&amp;ui_watermark=1&amp;ui_watermark_link=1">
    </iframe>
    
    
    <figure class="preview">
        <img src="images/modeling-3d-alt.jpg" alt="3D printed object and accompanying 3D printed labels laid out on a table; this side view shows labels for the years, 1919–1942."/>
        <figcaption><p>The online version of this essay includes an interactive 3D viewer displaying a model of this object.</p></figcaption>
    </figure>
    
</div>

<div class="txt-only" id="">
⩩&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;⟩
| FIGURE. 3-D model of Shakespeare and Company membership lollipop chart.
⩩&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;⟩
</div></p>
<h3 id="insights-1">Insights</h3>
<p>











 


<figure aria-describedby="bars-desc">
    <img loading="lazy" alt="Bar chart showing members with borrowing activity and total members each month" role="img" sizes="(max-width: 768px) 100%, 80%"src="/issues/1/data-beyond-vision/images/membership-book-activity-combined_1919-19411.svg"><figcaption>
        <p>Shakespeare and Company lending library members with borrowing activity and members, 1919–1941. From Kotin and Koeser, “The Shakespeare and Company Lending Library Cards in Context.” <a href="http://shakespeareandco.princeton.edu/analysis/2020/03/shakespeare-and-company-lending-library-cards-context/">http://shakespeareandco.princeton.edu/analysis/2020/03/shakespeare-and-company-lending-library-cards-context/</a>.
        </p>
    </figcaption>
</figure>
<div class="txt-only" id="">
⩩&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;⟩
| FIGURE. Bar chart showing members with borrowing activity and total members each month.
|
| CAPTION: Shakespeare and Company lending library members with borrowing activity and members, 1919–1941.
| ATTRIBUTION: Kotin and Koeser, “The Shakespeare and Company Lending Library Cards in Context.”
| LINK: <a href="http://shakespeareandco.princeton.edu/analysis/2020/03/shakespeare-and-company-lending-library-cards-context/">http://shakespeareandco.princeton.edu/analysis/2020/03/shakespeare-and-company-lending-library-cards-context/</a>
⩩&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;⟩
</div>
<div class="sr-only" id="bars-desc">
Plotting documented membership accounts against borrowing activity shows the differences in members tracked across the two sources. The Shakespeare and Company Project has information about the borrowing activity of 11% of lending library members. For the 1920s, the percentage is lower: only 6%. But in the 1930s, the percentage is higher: 23%. Some months show more members with borrowing activity than total members because information on the cards overlaps  gaps in logbook coverage.
</div></p>
<p>The same membership data can be presented in a two-variable bar chart. Overall trends are easy to see, and both representations of the data make it possible to compare the two data series against each other. Seasonal trends are visible in the bar chart, but it’s difficult to identify distinct months; in contrast, changing perspective on the 3D lollipop chart allows focusing on yearly or monthly trends. Missing data in one variable is visible in both, but seems more striking in the 3D version where the base of the piece is bare without any lollipop tops.  At the current scale, touching the piece requires focusing attention on just a portion of the object but invites exploration, which can proceed in any direction.<sup id="fnref:26"><a href="#fn:26" class="footnote-ref" role="doc-noteref">26</a></sup> While the bar chart demands sequential reading from left to right, the 3D printed object doesn’t provide or demand a particular starting point or sequence.</p>
<p>The bar chart conveys a sense of certitude and exactness that does not reflect the missing and partial data that underlies it; the 3D printed object, with its irregularities and fragility, is more representative of the contingent, historical data.<sup id="fnref:27"><a href="#fn:27" class="footnote-ref" role="doc-noteref">27</a></sup></p>
<h3 id="next-steps-1">Next Steps</h3>
<p>The current version uses different shapes for the two variables, but adding textures would make the model even more tactile. Simple 3D printed labels with text and braille<sup id="fnref:28"><a href="#fn:28" class="footnote-ref" role="doc-noteref">28</a></sup> have been added for display alongside the piece, but they could be incorporated directly on the model, and refined to provide a scale for the axes. The 3D printed objects could also be augmented with other media: lights or sound could convey the intensity of borrowing activity, or threads connecting months to represent the number of subscription renewals and convey a sense of continuity. The Python code used to create these models could be generalized for reuse, and eventually made available as a Blender plugin.<sup id="fnref:29"><a href="#fn:29" class="footnote-ref" role="doc-noteref">29</a></sup> New shapes or approaches could be used to leverage innovations in 3D modeling, such as generative design, to create objects that are more inviting to touch and even more distinct from 2D data visualizations. 3D models could be revised for fabrication with CNC machines to create objects out of wood instead of plastic, which could make them more inviting to touch.</p>
<p><a href="https://startwords.cdh.princeton.edu/issues/1/print-a-model-of-the-shakespeare-and-company-lending-library-membership/">Make one &gt;</a></p>
<div class="icon-nav" id="">
<span class="help">Choose a different object</span>
<a href="#folding"><img src="images/icon-folding.svg" alt="read folding section"></a>
<a href="#weaving"><img src="images/icon-weaving.svg" alt="read weaving section"></a>
<a href="#stacking"><img src="images/icon-stacking.svg" alt="read stacking section"></a>
</div>
<h2 id="weaving">Weaving Derrida’s References</h2>
<blockquote>
<p>… we all of us, grave or light, get our thoughts entangled in metaphors…
<cite> George Eliot, Middlemarch</cite></p>
</blockquote>
<p><em>Rebecca Sutton Koeser, Gissoo Doroudian</em></p>
<h3 id="goal-2">Goal</h3>
<p>With this piece, we aim to literalize the metaphor of weaving as writing, embedded in the very words textile and text<sup id="fnref:30"><a href="#fn:30" class="footnote-ref" role="doc-noteref">30</a></sup>, by representing Derrida’s intertextuality as a woven tapestry. The textures of the yarn and woven fabric invite touch, but by showing an in-progress weaving with the pattern and instructions provided, we move viewers beyond seeing and touching to enable them to become participants in reconstructing the data. Showing the weaving in progress also foregrounds the labor of data work, since curation, collection, and visualization all take an enormous amount of work and skill, often from a range of different individuals.</p>
<p><div class="deepzoom" id="openseadragon-23" style="height: 10em" aria-label="Interactive zoomable viewer displaying a blue scarf with alternating bands of varied threads."></div>
<script>
    window.addEventListener("DOMContentLoaded", function() {
        OpenSeadragon({
            id: "openseadragon-23",
            prefixUrl: "https://cdn.jsdelivr.net/npm/openseadragon@2.4/build/openseadragon/images/",
            preserveViewport: true,
            visibilityRatio:    1,
            minZoomLevel:       1,
            defaultZoomLevel:   1,
            gestureSettingsMouse: { scrollToZoom: false },
            tileSources: "https:\/\/iiif.princeton.edu\/loris\/iiif\/2\/figgy_prod%2F58%2F51%2Fd4%2F5851d48b225b42699a13181c778a6095%2Fintermediate_file.jp2\/info.json",
        });
    });
</script>


<figure class="deepzoom-preview">
    <img src="images/weaving-deepzoom-alt.jpg" alt="Composite of two images from the high resolution image shown in the deep zoom viewer: one showing the full length of the woven piece, and another with a close up showing the threads and different weaving patterns."/>
    <figcaption><p>The online version of this essay includes an interactive deep zoom viewer displaying a high resolution capture of this object.</p></figcaption>
</figure>

<div class="txt-only" id="">
⩩&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;⟩
| FIGURE. Interactive zoomable viewer displaying a blue scarf with alternating bands of varied threads.
⩩&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;⟩
</div></p>
<h3 id="description-2">Description</h3>
<p>This weaving represents the references in chapter one of Jacques Derrida’s <em>de la Grammatologie</em> (1967). The references have been cataloged and categorized by the research team of Derrida’s Margins.<sup id="fnref:31"><a href="#fn:31" class="footnote-ref" role="doc-noteref">31</a></sup> Each type of reference (epigraph, citation, quotation, footnote) is represented by a distinct yarn and weaving pattern. Derrida’s highly intertextual writing suggested the idea of weaving.<sup id="fnref:32"><a href="#fn:32" class="footnote-ref" role="doc-noteref">32</a></sup> Using yarn to symbolize the foundational work of deconstructionism, which operates by finding the place where a text unravels, gives additional depth to this physicalization.</p>
<p>Working with textiles is often stereotyped as female activity, therefore this piece also raises questions of gender and other false binaries such as art versus craft, high and low tech. Based on anthropological research, women produced most of the textiles in the ancient world, but that work can be read as female authorship involved in the earliest textual practices.<sup id="fnref:33"><a href="#fn:33" class="footnote-ref" role="doc-noteref">33</a></sup> The loom itself runs the gamut from high and low technology: a backstrap loom can be assembled at home from dowels, rods, and cords; and yet, Joseph-Marie Jacquard’s 1801 power loom, which used punch cards to automatically create elaborate woven patterns, was an important precursor to early computers.</p>
<p>











 








<figure>
    <img loading="lazy" alt="The weaver sits in front of a table top loom; one hand lifts two strand of the warp yarn, the other stretches out the yarn being looped around it." role="img" sizes="(max-width: 768px) 100%, 80%"srcset="/issues/1/data-beyond-vision/images/weaving-soumak_hu4c20ea29d73279e64865a8a2b7a14231_9638085_500x0_resize_q75_box.jpg 500w,
    /issues/1/data-beyond-vision/images/weaving-soumak_hu4c20ea29d73279e64865a8a2b7a14231_9638085_800x0_resize_q75_box.jpg 800w,
    /issues/1/data-beyond-vision/images/weaving-soumak_hu4c20ea29d73279e64865a8a2b7a14231_9638085_1200x0_resize_q75_box.jpg 1200w,
    /issues/1/data-beyond-vision/images/weaving-soumak_hu4c20ea29d73279e64865a8a2b7a14231_9638085_1500x0_resize_q75_box.jpg 1500w,
    /issues/1/data-beyond-vision/images/weaving-soumak_hu4c20ea29d73279e64865a8a2b7a14231_9638085_1800x0_resize_q75_box.jpg 1800w,
    /issues/1/data-beyond-vision/images/weaving-soumak.jpg 3400w"
     class="landscape"><figcaption>
        <p>Gissoo, creating a Soumak weave.
        </p>
    </figcaption>
</figure>
<div class="txt-only" id="">
⩩&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;⟩
| FIGURE. The weaver sits in front of a table top loom; one hand lifts two strand of the warp yarn, the other stretches out the yarn being looped around it.
|
| CAPTION: Gissoo, creating a Soumak weave.
⩩&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;⟩
</div></p>
<h3 id="insights-2">Insights</h3>
<p>The data encoded in the weaving could be represented as a stacked bar chart, a familiar and easily available choice for communicating types and quantities. However, it may be the least effective for communicating the depth and conceptual nuance of data on multiple levels.</p>
<p>











 


<figure aria-describedby="refs-desc">
    <img loading="lazy" alt="Stacked bar chart showing number and kind of references by page." role="img" sizes="(max-width: 768px) 100%, 80%"style="max-height: 500px"src="/issues/1/data-beyond-vision/images/derrida-refsbytype-chap1.svg"><figcaption>
        <p>References in chapter 1 of Of Grammatology by page and type. (Chapter 1 begins on page 15).
        </p>
    </figcaption>
</figure>
<div class="txt-only" id="">
⩩&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;⟩
| FIGURE. Stacked bar chart showing number and kind of references by page.
|
| CAPTION: References in chapter 1 of Of Grammatology by page and type. (Chapter 1 begins on page 15).
⩩&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;⟩
</div>
<div class="sr-only" id="refs-desc">
The chart shows that quotations are the most common type of reference in chapter one, and a few pages include six or more quotations. Footnotes are the next most common reference; there is only one epigraph, on the first page in the chapter, and one citation, on page 35. Only six pages have no references at all, and many pages have more than one.
</div></p>
<p>The ability to feel the density and frequency of each type of reference, color coded above, creates a unique experience for each participant, specific to their own perspective. These organic experiences bring to light the depth and complexities of the original work as well as the labor involved with gathering this data. This woven piece, which represents the first half (thirteen pages) of the first chapter of <em>Of Grammatology</em> is 37 inches long, a little more than 3 feet. The physical nature of this data representation required that materials and dimensions be carefully calculated and measured.<sup id="fnref:34"><a href="#fn:34" class="footnote-ref" role="doc-noteref">34</a></sup> The process of creating this piece is embodied and experiential, which naturally leads to conversations that effortlessly surface the labor of data work and the depth of the original text. Unfortunately, this is less likely to happen naturally when creating data visualizations.</p>
<h3 id="next-steps-2">Next Steps</h3>
<p>Adding conductive thread and sensors could turn the weaving into an interface, so that touching the fabric would bring up the relevant reference on an associated screen. Data weavings could also be augmented with other media, such as lights and sound to convey other aspects of the same or related data. Incorporating other work on automated weaving and knitting machines would add to the variety of options for data textiles.</p>
<p><a href="https://startwords.cdh.princeton.edu/issues/1/weave-derridas-references/">Make one &gt;</a></p>
<div class="icon-nav" id="">
<span class="help">Choose a different object</span>
<a href="#folding"><img src="images/icon-folding.svg" alt="read folding section"></a>
<a href="#modeling"><img src="images/icon-printing.svg" alt="read modeling section"></a>
<a href="#stacking"><img src="images/icon-stacking.svg" alt="read stacking section"></a>
</div>
<h2 id="stacking">Stacking New and Continuing Membership Activities of the Shakespeare and Company Lending Library</h2>
<p><em>Xinyi Li</em></p>
<h3 id="goal-3">Goal</h3>
<p>This piece aims to reveal the continuity and growth of Sylvia Beach’s lending library by showing the extent of activity and recorded membership based on logbooks and lending library cards. Multiple variables are encoded in the dimensions of stacking boxes based on the technique of pop-up box folds. By exhibiting the evolution of the library over time while contrasting activities of new and old members, this piece enables multiple ways to compare and interpret the data from diverse perspectives. By transforming a flat surface to a three-dimensional form with play of light and shadows, this production technique serves as a metaphor for the larger purpose of the <a href="https://shakespeareandco.princeton.edu/">Shakespeare and Company Project</a> — bringing archival data to life and facilitating rich interpretations.</p>
<p>











 


<figure>
    <img loading="lazy" alt="Animated GIF with the camera panning revealing different portions of the paper model." role="img" sizes="(max-width: 768px) 100%, 80%"src="/issues/1/data-beyond-vision/images/stacking-horizontal-pan.gif"><figcaption>
        <p>Overview of a folded model representing the lending library membership activities from 1919–1941.
        </p>
    </figcaption>
</figure>
<div class="txt-only" id="">
⩩&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;⟩
| FIGURE. Animated GIF with the camera panning revealing different portions of the paper model.
|
| CAPTION: Overview of a folded model representing the lending library membership activities from 1919–1941.
⩩&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;⟩
</div></p>
<h3 id="description-3">Description</h3>
<p><a href="https://shakespeareandco.princeton.edu/">Shakespeare and Company Project</a> lending library membership data from 1919 to 1941 are represented as a hybrid of time-series and stacked bar charts showing part-to-whole relationships made from paper and folding. Each unit, a cuboid in space and sometimes its stacking child, represents one year and displays nine variables for that year. The height corresponds to the number of active members recorded in the <a href="https://shakespeareandco.princeton.edu/sources/logbooks/">logbooks</a>; the depth depicts the number of members with borrowing activity, according to each member’s <a href="https://shakespeareandco.princeton.edu/sources/cards/">lending library card</a>; the length along the timeline is based on the total number of borrowing events.<sup id="fnref:35"><a href="#fn:35" class="footnote-ref" role="doc-noteref">35</a></sup> Each of the variables is split into two parts: previous members who have renewed a membership contrasted with new members. The upper portion shows the growth and the activities of new readers. Viewers can see the rise and fall of members, inspect the difference between members with borrowing activity and the members as represented in the logbooks, compare the growth over time by viewing the stacking part from the front, and survey the involvement of continuing members versus new members, to name a few possibilities. In some cases, a small number of new members were very active readers based on their borrowing activity.</p>
<p>











 








<figure>
    <img loading="lazy" alt="Textual labels overlaying a 3d rendering of a unit of the folded model along its three directions." role="img" sizes="(max-width: 768px) 100%, 80%"srcset="/issues/1/data-beyond-vision/images/stacking-photo-legend_hu82654c780d94fbe639e7d55a501ef41b_40394428_500x0_resize_box_2.png 500w,
    /issues/1/data-beyond-vision/images/stacking-photo-legend_hu82654c780d94fbe639e7d55a501ef41b_40394428_800x0_resize_box_2.png 800w,
    /issues/1/data-beyond-vision/images/stacking-photo-legend_hu82654c780d94fbe639e7d55a501ef41b_40394428_1200x0_resize_box_2.png 1200w,
    /issues/1/data-beyond-vision/images/stacking-photo-legend_hu82654c780d94fbe639e7d55a501ef41b_40394428_1500x0_resize_box_2.png 1500w,
    /issues/1/data-beyond-vision/images/stacking-photo-legend_hu82654c780d94fbe639e7d55a501ef41b_40394428_1800x0_resize_box_2.png 1800w,
    /issues/1/data-beyond-vision/images/stacking-photo-legend.png 6980w"
     class="landscape"><figcaption>
        <p>Legend showing how to read the information represented in three dimensions.
        </p>
    </figcaption>
</figure>
<div class="txt-only" id="">
⩩&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;⟩
| FIGURE. Textual labels overlaying a 3d rendering of a unit of the folded model along its three directions.
|
| CAPTION: Legend showing how to read the information represented in three dimensions.
⩩&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;⟩
</div></p>
<p>This physicalization made use of kirigami technique, which transforms single sheets of paper into three-dimensional forms. Data was mapped to the shapes with <a href="http://data-illustrator.com/">Data Illustrator</a>, semi-manual calculation, and vector drawing. The materiality and the process have a poetic connection to the subject matter, metaphorically: stories and knowledge can be embedded on flat papers, but the act of reading unfolds the surface into interpretive space even beyond three dimensions.</p>
<p>
<div class="sketchfab-embed-wrapper">
    <iframe
        id="sketchfab-96403a4659414537b470f03da96d7a88"
        aria-label="3D model showing a folded long paper as base, with opened cuts folded into additional panels."
        frameborder="0"
        allow="autoplay; fullscreen; vr"
        mozallowfullscreen="true"
        webkitallowfullscreen="true"
        loading="lazy"
        src="https://sketchfab.com/models/96403a4659414537b470f03da96d7a88/embed?autospin=0.2&amp;autostart=0&amp;camera=0&amp;preload=1&amp;ui_controls=1&amp;ui_infos=1&amp;ui_inspector=1&amp;ui_stop=1&amp;ui_watermark=1&amp;ui_watermark_link=1">
    </iframe>
    
    
    <figure class="preview">
        <img src="images/modeling-3d-alt.jpg" alt="Three photos from multiple angles showing a folded long paper as base, with opened cuts folded into additional panels."/>
        <figcaption><p>The online version of this essay includes an interactive 3D viewer displaying a model of this object.</p></figcaption>
    </figure>
    
</div>

<div class="txt-only" id="">
⩩&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;⟩
| FIGURE. 3D model showing a folded long paper as base, with opened cuts folded into additional panels.
⩩&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;⟩
</div></p>
<h3 id="insights-3">Insights</h3>
<p>











 


<figure aria-describedby="stackedbar-desc">
    <img loading="lazy" alt="A series of stacked bar charts comparing the number of members, numbers of borrowers, and borrowing events, and the portion of new and renewed members among each of these categories." role="img" sizes="(max-width: 768px) 100%, 80%"src="/issues/1/data-beyond-vision/images/2d-stacked-bar-v2-01.svg"><figcaption>
        <p>Membership activities of Shakespeare and Company Lending Library from 1919–194 represented as stacked bar charts.
        </p>
    </figcaption>
</figure>
<div class="txt-only" id="">
⩩&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;⟩
| FIGURE. A series of stacked bar charts comparing the number of members, numbers of borrowers, and borrowing events, and the portion of new and renewed members among each of these categories.
|
| CAPTION: Membership activities of Shakespeare and Company Lending Library from 1919–194 represented as stacked bar charts.
⩩&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;⟩
</div>
<div class="sr-only" id="stackedbar-desc">
Members with borrowing events constitute a fraction of all the members in the earlier years. The overall number of borrowing events increases gradually from 1919 to 1926, drops off slightly, then evidently increases from 1934 to 1939, even though the number of members drops drastically after 1929. It’s not easy to compare book borrowing by new members across the years.
</div></p>
<p>With current off-the-shelf visualization tools like the ones that come with Google Sheets, these three data series can generate three separate stacked bar charts. Since the numbers have different ranges, the vertical axes are drawn in different scales, which makes comparison across series impossible. The aggregate version presented here required manual adjustment to combine the separated charts and to make the Y axes comparable. In this 2D version, various activities of the growing membership body are not linked, and it’s difficult to draw connections between active members and the intensity of their activities because spatially these bars are not adjacent to each other. In the conventional pie charts, although the part-whole relationship between new membership activity and all activity is apparent, comparing across the three types of activities is not possible.</p>
<p>











 


<figure aria-describedby="pieseries-desc">
    <img loading="lazy" alt="A series of pie charts comparing the number of members, numbers of borrowers, borrowing events, and the portion of new and renewed members among each of these categories." role="img" sizes="(max-width: 768px) 100%, 80%"src="/issues/1/data-beyond-vision/images/2d-pie_v2-01.svg"><figcaption>
        <p>Membership activities of Shakespeare and Company Lending Library between 1919 and 1941 represented as pie charts.
        </p>
    </figcaption>
</figure>
<div class="txt-only" id="">
⩩&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;⟩
| FIGURE. A series of pie charts comparing the number of members, numbers of borrowers, borrowing events, and the portion of new and renewed members among each of these categories.
|
| CAPTION: Membership activities of Shakespeare and Company Lending Library between 1919 and 1941 represented as pie charts.
⩩&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;⟩
</div>
<div class="sr-only" id="pieseries-desc">
Overall, renewed members outsize new members before 1929, followed by five years with nearly two times more new members than the renewed. Members with borrowing events represent a fraction of all the members in the early years between 1919 and 1929. Then members with borrowing events grow and become more comparable to the size of all members, which sizes down drastically after 1929. Borrows from new members outsize renewed members since 1934. It is not easy to compare the proportion of growth across the years.
</div></p>
<p>Extending into physical space allows data to be encoded in three axes and provides multiple possible angles to view the piece, depending on the relationships one is interested in, between logbook members, members with lending library card activities, and borrowing events. The separation of renewing and new members makes it possible to juxtapose and compare activities between the two groups of members. Spatial factors communicate different facets of the data, and color coding is no longer required.</p>
<p>Throughout the process of developing this project as practice-based research, making and reflecting are in constant oscillation, and knowing happens in actions. As I worked through this piece and observed the artifact, new questions emerged: how do we measure the level of liveliness of the lending library? Is it by the number of members or by the number of borrowing events? Instead of drawing comparisons by the lengths along each axis, perhaps this physicalization also introduces another way to look at the vibrancy of the lending library: through the volumes and relative sizes of the cuboids and rectangles, which factor in both the number of members and the borrowing activity.</p>
<h3 id="next-steps-3">Next Steps</h3>
<p>The pattern generation process is very programming-friendly and the materials required are also easily accessible. The data encoding process could be automated by custom code, which could then be made available as a tool for presenting part-to-whole relationships in other data sets. With the addition of dynamic media such as projection mapping, this piece could convey more context and narratives around the lending library.</p>
<p><a href="https://startwords.cdh.princeton.edu/issues/1/stack-shakespeare-and-company-membership-activities/">Make one &gt;</a></p>
<div class="icon-nav" id="">
<span class="help">Choose a different object</span>
<a href="#folding"><img src="images/icon-folding.svg" alt="read folding section"></a>
<a href="#modeling"><img src="images/icon-printing.svg" alt="read modeling section"></a>
<a href="#weaving"><img src="images/icon-weaving.svg" alt="read weaving section"></a>
</div>
<h2 id="acknowledgements">Acknowledgements</h2>
<p>Photos from the data physicalizations on display and Gissoo weaving are by Shelley Szwast. The high resolution capture of the data weaving used for the deep zoom and margin image was created by Princeton University Library, Digital Imaging Studio. The photo of the CDH main space with empty tables is by Mana Winters. The custom visuals for this essay were created by Gissoo Doroudian; the icons for each section were created by Gissoo Doroudian and revised by Doroudian and Xinyi Li. All other photos, charts, and models were created by the authors.</p>
<p>Thanks to our collaborators on the <a href="https://shakespeareandco.princeton.edu/about/credits/">Shakespeare and Company Project team</a> and <a href="https://derridas-margins.princeton.edu/credits/">Derrida’s Margins project team</a> for their work to create the data we have experimented with and physicalized here; to the <a href="http://ach2019.ach.org/cfp-call-for-participation-en/">ACH2019 conference organizers for the generous CFP</a> with the option of installations, which led in part to this work; and to the <a href="https://cdh.princeton.edu/">Center for Digital Humanities at Princeton</a> and our colleagues there for the tremendous support and encouragement for this project. Special thanks to our colleagues at Princeton University Libraries, Meghan Testerman and Annette Jushchuk, for participating in a weaving exhibition test run and giving us feedback to improve the instructions.</p>
<section class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1" role="doc-endnote">
<p>Staley, David. “On the ‘Maker Turn’ in the Humanities.” In <em>Making Things and Drawing Boundaries</em>, edited by Jentery Sayers, 32–41. Experiments in the Digital Humanities. University of Minnesota Press, 2017. <a href="https://doi.org/10.5749/j.ctt1pwt6wq.5">https://doi.org/10.5749/j.ctt1pwt6wq.5</a>. <a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:2" role="doc-endnote">
<p>“Any communicating object that reflects choices about the selection and representation of reality is a rhetorical object.” <em>Data Feminism</em>, p.78. <a href="#fnref:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:3" role="doc-endnote">
<p>These pieces are based on statements included as part of the “Data Beyond Vision” installation presented at ACH2019, which were partly inspired by artist statements. However, we have considerably expanded and adapted them and moved beyond that format. <a href="#fnref:3" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:4" role="doc-endnote">
<p>The term data physicalization can be understood in three ways: a “physical artifact whose geometry or material properties encode data”; the process of giving physical form to data, or the research research area combining data visualization and tangible user interfaces.  See Jansen, Yvonne, Pierre Dragicevic, Petra Isenberg, Jason Alexander, Abhijit Karnik, Johan Kildal, Sriram Subramanian, and Kasper Hornbæk. “Opportunities and Challenges for Data Physicalization.” In Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems - CHI ’15, 3227–36. Seoul, Republic of Korea: ACM Press, 2015. <a href="https://doi.org/10.1145/2702123.2702180">https://doi.org/10.1145/2702123.2702180</a>. <a href="#fnref:4" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:5" role="doc-endnote">
<p>To get a better sense of the variety and historic range of data physicalizations, browse a gallery of physical visualizations and related artifacts at <a href="http://dataphys.org/list/gallery/">http://dataphys.org/list/gallery/</a>. <a href="#fnref:5" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:6" role="doc-endnote">
<p>Read more about “Critical Making”, which was coined by Matt Ratto, at <a href="https://criticalmaking.com/matt-ratto/">https://criticalmaking.com/matt-ratto/</a>. <a href="#fnref:6" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:7" role="doc-endnote">
<p>This work is strongly aligned with the principles of data feminism;  in particular, elevating emotion and embodiment; considering context; and making labor visible. D’Ignazio, Catherine, and Lauren F. Klein. <em>Data Feminism</em>. Strong Ideas Series. Cambridge, Massachusetts: The MIT Press, 2020. <a href="#fnref:7" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:8" role="doc-endnote">
<p>Haraway, Donna. &ldquo;Situated Knowledges: The Science Question in Feminism and the Privilege of Partial Perspective.&rdquo; Feminist Studies 14, no. 3 (1988): 575-99. Accessed October 2, 2020. doi:10.2307/3178066. <a href="#fnref:8" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:9" role="doc-endnote">
<p>We’re trying out this approach on research partnership projects we’ve worked on at the Center for Digital Humanities at Princeton. Read the <a href="https://github.com/princeton-cdh/mep-django/issues/404">GitHub issue where we discussed the implementation</a>, the <a href="https://www.sarasoueidan.com/blog/accessible-data-charts-for-khan-academy-2018-annual-report/">article that inspired our approach</a>, and an example of it in use in a <a href="https://prosody.princeton.edu/editorial/2020/01/visualizing-collections/">Princeton Prosody Archive Editorial essay</a>. <a href="#fnref:9" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:10" role="doc-endnote">
<p>The difficulty and unfamiliarity of this intimacy may be demonstrated in part by our experience with displaying these objects. We often have to encourage and reassure people that they are allowed to touch these items, even though there are signs clearly posted inviting just that. <a href="#fnref:10" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:11" role="doc-endnote">
<p>Mastery is a problematic term, as African-Americans and members of other discriminated groups know well, and as the racial unrest in the U.S. this summer has made White Americans more aware. Klein and D’Ignazio also point out that it has a gendered component as well, with the master stereotype associated with men across many Western cultures. For a discussion of “master” and its unfortunate use in technology, see a guide “Toward anti-racist technical terminology” published by The Association for Computers and the Humanities (ACH). <a href="https://ach.org/toward-anti-racist-technical-terminology/">https://ach.org/toward-anti-racist-technical-terminology/</a> <a href="#fnref:11" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:12" role="doc-endnote">
<p>“Levinas is one of few philosophers to displace the metaphor of vision dominating ontological accounts of intersubjectivity into a metaphor of touch … which resonates with Irigaray’s own reformulation of subject-object relations in the figure of the two lips.” Ince, Kate. “Questions to Luce Irigaray.” <em>Hypatia</em> 11, no. 2 (1996): 122–40. <a href="http://www.jstor.org/stable/3810267">http://www.jstor.org/stable/3810267</a> <a href="#fnref:12" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:13" role="doc-endnote">
<p>“This gesture … which weds without consum(mat)ing .. may be called: the touch of the caress.  … this touch binds and unbinds two others in a flesh that is still and always untouched by mastery.” Irigaray, Luce. “The Fecundity of the Caress A Reading of Levinas, <em>Totality and Infinity</em>, ‘Phenomenology of Eros.’” In <em>An Ethics of Sexual Difference</em>. Ithaca: Cornell Press, 1993. <a href="#fnref:13" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:14" role="doc-endnote">
<p>This technique, also called “modular origami”, uses separate sheets folded into repeated interlocking small forms. The practice is attested as early as the 18th century, but gained popularity in the 1960s with the work of Robert Neale in the US and Mitsunobu Sonobe in Japan. Our model uses forms from Tomoko Fuse’s book <em>Unit Origami: Multidimensional Transformations</em>. <a href="#fnref:14" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:15" role="doc-endnote">
<p>VIAF aggregates records from multiple national libraries with authoritative names for people, organizations, and titles. Typically only people associated with published works, such as authors and translators, have records in VIAF; we used this as a proxy for some degree of fame, even though there are plenty of names in VIAF that are not strictly famous. <a href="#fnref:15" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:16" role="doc-endnote">
<p>This work is based on pre-release versions of the datasets now published as: Kotin, Joshua, Rebecca Sutton Koeser, Carl Adair, Serena Alagappan, Jean Bauer, Oliver J. Browne, Nick Budak, Harriet Calver, Jin Chow, Ian Davis, Gissoo Doroudian, Currie Engel, Elspeth Green, Benjamin Hicks, Madeleine E. Joelson, Carolyn Kelly, Sara Krolewski, Xinyi Li, Ellie Maag, Cate Mahoney, Jesse D. McCarthy, Mary Naydan, Isabel Ruehl, Sylvie Thode, Camey VanSant, and Clifford E. Wulfman. <em>Shakespeare and Company Project Dataset: Lending Library Members, Books, Events</em>. Version 1.0. July 2020. Distributed by DataSpace, Princeton University. <a href="https://doi.org/10.34770/pe9w-x904">https://doi.org/10.34770/pe9w-x904</a>. For more information, see <a href="https://shakespeareandco.princeton.edu/about/data/">https://shakespeareandco.princeton.edu/about/data/</a> <a href="#fnref:16" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:17" role="doc-endnote">
<p>This is inspired in part by ethical principles from the Colored Conventions Project, which asks researchers using their data to “contextualize and narrate the conditions of the people who appear as ‘data’ and to name them when possible.” <a href="https://coloredconventions.org/about-records/ccp-corpus/">https://coloredconventions.org/about-records/ccp-corpus/</a> <a href="#fnref:17" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:18" role="doc-endnote">
<p>We wanted to include a 3D model of this physicalization in order to provide some semblance of virtually grasping and rotating the object. Because we didn’t have a way to capture the actual object in 3D, we created a model of it in Blender; this was fairly straightforward, since it consists of two simple shapes. <a href="#fnref:18" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:19" role="doc-endnote">
<p>For more on the strengths and weaknesses of the pie chart, see Johnson, Steve. “The Case Against Pie Charts,” March 3, 2017. <a href="https://accelerate.uofuhealth.utah.edu/connect/steves-dojo-7-the-case-against-pie-charts">https://accelerate.uofuhealth.utah.edu/connect/steves-dojo-7-the-case-against-pie-charts</a> <a href="#fnref:19" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:20" role="doc-endnote">
<p>We do not provide a how-to for this object out of respect for the copyright of origami authors, who often spend years developing and refining single designs. The three-dimensional forms used to make this piece are a combination of two modular origami units which are the original creations of the brilliant Tomoko Fuse, and can be found in her book <em>Unit Origami: Multidimensional Transformations</em>. The octahedron is formed from eight units with triangular windows (p. 109), and these windows are filled with eight so-called E-b units (p. 233) that create the illusion of an intersecting cube. When assembling from your own paper, you can print <a href="https://startwords.cdh.princeton.edu/issues/1/data-beyond-vision/non_viaf_names.pdf">a document containing the names of the non-VIAF members of the library</a> onto the paper before folding the octahedron. Sheets of 8.5” x 11” copy paper can become difficult to manipulate when folded many times; thinner paper is easier to work with. <a href="#fnref:20" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:21" role="doc-endnote">
<p>A <a href="https://datavizproject.com/data-type/lollipop-chart/">lollipop chart</a> is a bar chart variant that uses dots to mark the values. Earlier prototypes of this model were based on bar charts, but I discovered that the space between bars in a lollipop chart made it easier to “read” the 3D version, since they obscure less of the model visually. <a href="#fnref:21" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:22" role="doc-endnote">
<p>This work is based on pre-release versions of the <a href="https://shakespeareandco.princeton.edu/about/data/">datasets now available</a>. Kotin et al., Shakespeare and Company Project Dataset: Lending Library Members, Books, Events, <a href="https://doi.org/10.34770/pe9w-x904">https://doi.org/10.34770/pe9w-x904</a> <a href="#fnref:22" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:23" role="doc-endnote">
<p>We use white and green in our physicalizations of data from the Shakespeare and Company Project because green is the most iconic color used in the site design. <img src="images/scp_colors_dark.png" alt="Color palette from Shakespeare and company project."> <a href="#fnref:23" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:24" role="doc-endnote">
<p>To better understand the Shakespeare and Company Project sources, read: Shakespeare and Company Project. “Lending Library Cards.” Center for Digital Humanities, Princeton University, November 20, 2019. <a href="https://shakespeareandco.princeton.edu/sources/cards/;">https://shakespeareandco.princeton.edu/sources/cards/;</a> and Shakespeare and Company Project. “Logbooks.” Center for Digital Humanities, Princeton University, November 20, 2019. <a href="https://shakespeareandco.princeton.edu/sources/logbooks/">https://shakespeareandco.princeton.edu/sources/logbooks/</a>. To understand how the Project data from those sources fit together, read Kotin, Joshua and Rebecca Sutton Koeser. “The Shakespeare and Company Lending Library Cards in Context.” Shakespeare and Company Project, version 1.2.3. Center for Digital Humanities, Princeton University. March 9, 2020. <a href="http://shakespeareandco.princeton.edu/analysis/2020/03/shakespeare-and-company-lending-library-cards-context/">http://shakespeareandco.princeton.edu/analysis/2020/03/shakespeare-and-company-lending-library-cards-context/</a>. <a href="#fnref:24" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:25" role="doc-endnote">
<p>The previous version was more complicated to print; the overlapping framework interfered with small data points, and the tightly interlocking parts did not scale well. <img src="images/modeling-ach2019-side-view.jpg" alt="Side view of early model version draft for ACH 2019 conference."> <img src="images/modeling-ach2019-top-view.jpg" alt="Top view of early model version draft for ACH 2019 conference."> <a href="#fnref:25" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:26" role="doc-endnote">
<p>Due to COVID-19, I’m writing and revising this from my home office without physical access to the object in question. I find myself closing my eyes and extending my fingers to focus on my memories of touching the object. <a href="#fnref:26" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:27" role="doc-endnote">
<p>For an exploration of the subjectivity, uncertainty and interpretation implicit in data, read Rebecca Munson’s essay in this issue of <em>Startwords</em>. For an overview of common techniques for representing uncertainty visually, see Yau, Nathan. “Visualizing the Uncertainty in Data.” <em>FlowingData</em> (blog), January 8, 2018. <a href="https://flowingdata.com/2018/01/08/visualizing-the-uncertainty-in-data/">https://flowingdata.com/2018/01/08/visualizing-the-uncertainty-in-data/</a>. For more on the difficulty people have in recognizing uncertainty in data visualization, see D’Ignazio and Klein on “Visceralizing Uncertainty” in <em>Data Feminism</em>, p.88. <a href="#fnref:27" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:28" role="doc-endnote">
<p>These have not yet been tested by anyone who reads braille. <a href="#fnref:28" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:29" role="doc-endnote">
<p><a href="https://www.blender.org/">Blender</a> is an open source 3D modeling creation suite which includes a Python API. I experimented with multiple other solutions for generating 3D models programmatically, including <a href="https://www.openscad.org/">OpenSCAD</a> and <a href="https://github.com/dbrgn/tangible">Tangible</a>, but found they were too limited and couldn’t handle the size of model I needed to generate for this dataset, so I eventually settled on Blender and Python. The blender interface makes it possible to view and modify models generated from code, there is <a href="https://docs.blender.org/api/current/">documentation for the Python API</a>, and I found many helpful answers on <a href="https://blender.stackexchange.com/">Blender Stack Exchange</a>. <a href="#fnref:29" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:30" role="doc-endnote">
<p>The word “text” comes from Latin <em>textus</em>, literally “thing woven” and from the verb <em>texere</em>, “to weave.” According to Kathryn Sullivan Kruger, “the connection between weaving (textiles) and language (texts) becomes so entangled as to be almost impossible to separate. In many languages, including English, the verb to weave defines not just the making of textiles, but any creative act.” (from <em>Weaving the Word: The Metaphorics of Weaving and Female Textual Production</em>, 2001).
To play on one of Derrida’s most famous statements, “il n&rsquo;y a pas de hors-textile.” <a href="#fnref:30" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:31" role="doc-endnote">
<p>Chenoweth, Katie, Alexander Baron-Raiffe, Renée Altergott, Chloé Vettier, Chad Córdova, Rebecca Sutton Koeser, Jean Bauer, and Benjamin Hicks. 2018. “References in Jacques Derrida&rsquo;s De La Grammatologie”. Figshare. <a href="https://doi.org/10.6084/m9.figshare.7180448.v1">https://doi.org/10.6084/m9.figshare.7180448.v1</a> <a href="#fnref:31" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:32" role="doc-endnote">
<p>For a deeper exploration of textile metaphors in Derrida’s work, see Caroline Rooney’s “Deconstruction and Weaving” in <em>Deconstructions</em> (2000). <a href="https://doi.org/10.1007/978-1-137-06095-2_14">https://doi.org/10.1007/978-1-137-06095-2_14</a> <a href="#fnref:32" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:33" role="doc-endnote">
<p>See Kathryn Sullivan Kruger’s <em>Weaving the Word: The Metaphorics of Weaving and Female Textual Production</em> (2001). <a href="#fnref:33" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:34" role="doc-endnote">
<p>When we first did the math on the weaving and measured, we discovered that doing all of chapter one would require a warp longer than three tables end-to-end in the CDH main space, which is why we scaled back to just half of the chapter. <img src="images/cdh-empty-tables.jpg" alt="read of empty tables in main space at CDH."> <a href="#fnref:34" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:35" role="doc-endnote">
<p>This work is based on pre-release versions of the <a href="https://shakespeareandco.princeton.edu/about/data/">datasets now available</a>. Kotin et al., Shakespeare and Company Project Dataset: Lending Library Members, Books, Events, <a href="https://doi.org/10.34770/pe9w-x904">https://doi.org/10.34770/pe9w-x904</a> <a href="#fnref:35" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</section>]]></content></entry><entry><title type="html">Print a model of the Shakespeare and Company Lending Library Membership</title><link href="https://startwords.cdh.princeton.edu/issues/1/print-a-model-of-the-shakespeare-and-company-lending-library-membership/?utm_source=atom_feed" rel="alternate" type="text/html"/><link href="https://startwords.cdh.princeton.edu/issues/1/stack-shakespeare-and-company-membership-activities/?utm_source=atom_feed" rel="related" type="text/html" title="Stack Shakespeare and Company Membership Activities"/><link href="https://startwords.cdh.princeton.edu/issues/1/weave-derridas-references/?utm_source=atom_feed" rel="related" type="text/html" title="Weave Derrida's References"/><id>https://startwords.cdh.princeton.edu/issues/1/print-a-model-of-the-shakespeare-and-company-lending-library-membership/</id><author><name>Rebecca Sutton Koeser</name></author><published>2020-10-01T00:00:00+00:00</published><updated>2020-10-23T16:32:45-04:00</updated><content type="html"><![CDATA[<p>











 








<figure>
    <img loading="lazy" alt="Alternating rows of white and green “lollipops” fade into the distance and out of focus, with the white data points noticeably larger in the foreground." role="img" sizes="(max-width: 768px) 100%, 80%"srcset="/issues/1/print-a-model-of-the-shakespeare-and-company-lending-library-membership/images/modeling-close-up_hub2dfc5608e8305f7eaaaae3e90a5c8a5_5473478_500x0_resize_q75_box.jpg 500w,
    /issues/1/print-a-model-of-the-shakespeare-and-company-lending-library-membership/images/modeling-close-up_hub2dfc5608e8305f7eaaaae3e90a5c8a5_5473478_800x0_resize_q75_box.jpg 800w,
    /issues/1/print-a-model-of-the-shakespeare-and-company-lending-library-membership/images/modeling-close-up_hub2dfc5608e8305f7eaaaae3e90a5c8a5_5473478_1200x0_resize_q75_box.jpg 1200w,
    /issues/1/print-a-model-of-the-shakespeare-and-company-lending-library-membership/images/modeling-close-up_hub2dfc5608e8305f7eaaaae3e90a5c8a5_5473478_1500x0_resize_q75_box.jpg 1500w,
    /issues/1/print-a-model-of-the-shakespeare-and-company-lending-library-membership/images/modeling-close-up_hub2dfc5608e8305f7eaaaae3e90a5c8a5_5473478_1800x0_resize_q75_box.jpg 1800w,
    /issues/1/print-a-model-of-the-shakespeare-and-company-lending-library-membership/images/modeling-close-up.jpg 3400w"
     class="landscape"><figcaption>
        <p>Close up of 3D printed lollipop chart with labels.<span class="attribution">Photo by Shelley Szwast</span>
        </p>
    </figcaption>
</figure>
<div class="txt-only" id="">
⩩&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;⟩
| FIGURE. Alternating rows of white and green “lollipops” fade into the distance and out of focus, with the white data points noticeably larger in the foreground.
|
| CAPTION: Close up of 3D printed lollipop chart with labels.
| ATTRIBUTION: Photo by Shelley Szwast
⩩&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;⟩
</div></p>
<p>Print a model of Shakespeare and Company lending library membership by date, as described in <a href="https://startwords.cdh.princeton.edu/issues/1/data-beyond-vision">Data Beyond Vision</a>.</p>
<p>We invite you to participate in the embodiment and visible labor of data work. Download the following models and instructions, use your hands to recreate the data physicalizations we developed, or use them as inspiration to make your own interpretive objects. If you make any of these physicalizations, please share them on social media with the hashtag <a href="https://twitter.com/search?q=(%23DataBeyondVision)">#DataBeyondVision</a>.</p>
<h2 id="tools">Tools</h2>
<ul>
<li>3D printer (single or dual filament)</li>
<li>Slicing software (e.g. <a href="https://ultimaker.com/software/ultimaker-cura">Cura</a> or <a href="https://www.simplify3d.com/">Simplify3D</a>)</li>
<li>Blade or file (for removing filament artifacts)</li>
</ul>
<h2 id="supplies">Supplies</h2>
<ul>
<li>3D printing filament in two different colors</li>
</ul>
<h2 id="steps">Steps</h2>
<ol>
<li>Download the <a href="DataBeyondVision-lollipop-members-3Dprint.zip">zip file with 3D models</a> and extract the files.</li>
<li>Load <code>comb-lolly-cards-a.stl</code> into your slicing software and rotate and scale it so that it fits along the long dimension of your print bed. Make a note of the scale factor you use.</li>
<li>Load and slice the other three parts of the lollipop chart (<code>comb-lolly-cards-b.stl</code>, <code>comb-lolly-members-a.stl</code>, and <code>comb-lolly-members-b.stl</code>), scaling them with the same scale factor you used for the first model.</li>
<li>Print the two card models in the same color.</li>
<li>Print the two member models in the second color.</li>
<li>Clean up any printing artifacts or threads on the lollipops.</li>
<li>If you want to print labels, slice and print the appropriate set for your printer (dual filament or single). Dual print models are provided as base and text, to be combined in your slicing software.</li>
<li>Arrange the comb models and labels on a table or other display.</li>
</ol>
<h2 id="yield">Yield</h2>
<p>3D printed model of Shakespeare and Company Library Membership</p>
<p>
<div class="sketchfab-embed-wrapper">
    <iframe
        id="sketchfab-89985d66f7244d87b7edbe5fd6266f0d"
        aria-label="3-D model of Shakespeare and Company membership lollipop chart."
        frameborder="0"
        allow="autoplay; fullscreen; vr"
        mozallowfullscreen="true"
        webkitallowfullscreen="true"
        loading="lazy"
        src="https://sketchfab.com/models/89985d66f7244d87b7edbe5fd6266f0d/embed?autospin=0.2&amp;autostart=0&amp;camera=0&amp;preload=1&amp;ui_controls=1&amp;ui_infos=1&amp;ui_inspector=1&amp;ui_stop=1&amp;ui_watermark=1&amp;ui_watermark_link=1">
    </iframe>
    
    
    <figure class="preview">
        <img src="images/modeling-3d-alt.jpg" alt="3D printed object and accompanying 3D printed labels laid out on a table; this side view shows labels for the years, 1919–1942."/>
        <figcaption><p>The online version of this essay includes an interactive 3D viewer displaying a model of this object.</p></figcaption>
    </figure>
    
</div>

<div class="txt-only" id="">
⩩&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;⟩
| FIGURE. 3-D model of Shakespeare and Company membership lollipop chart.
⩩&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;⟩
</div></p>
]]></content></entry><entry><title type="html">Stack Shakespeare and Company Membership Activities</title><link href="https://startwords.cdh.princeton.edu/issues/1/stack-shakespeare-and-company-membership-activities/?utm_source=atom_feed" rel="alternate" type="text/html"/><link href="https://startwords.cdh.princeton.edu/issues/1/print-a-model-of-the-shakespeare-and-company-lending-library-membership/?utm_source=atom_feed" rel="related" type="text/html" title="Print a model of the Shakespeare and Company Lending Library Membership"/><link href="https://startwords.cdh.princeton.edu/issues/1/weave-derridas-references/?utm_source=atom_feed" rel="related" type="text/html" title="Weave Derrida's References"/><id>https://startwords.cdh.princeton.edu/issues/1/stack-shakespeare-and-company-membership-activities/</id><author><name>Xinyi Li</name></author><author><name>Rebecca Sutton Koeser</name></author><published>2020-10-01T00:00:00+00:00</published><updated>2020-10-23T16:32:45-04:00</updated><content type="html"><![CDATA[<p>











 








<figure>
    <img loading="lazy" alt="A partition of a paper model against dark background with years printed on the base." role="img" sizes="(max-width: 768px) 100%, 80%"srcset="/issues/1/stack-shakespeare-and-company-membership-activities/images/stacking-part_v2_hu1697ab991fe780752a9ac253a846b640_6198895_500x0_resize_q75_box.jpg 500w,
    /issues/1/stack-shakespeare-and-company-membership-activities/images/stacking-part_v2_hu1697ab991fe780752a9ac253a846b640_6198895_800x0_resize_q75_box.jpg 800w,
    /issues/1/stack-shakespeare-and-company-membership-activities/images/stacking-part_v2_hu1697ab991fe780752a9ac253a846b640_6198895_1200x0_resize_q75_box.jpg 1200w,
    /issues/1/stack-shakespeare-and-company-membership-activities/images/stacking-part_v2_hu1697ab991fe780752a9ac253a846b640_6198895_1500x0_resize_q75_box.jpg 1500w,
    /issues/1/stack-shakespeare-and-company-membership-activities/images/stacking-part_v2_hu1697ab991fe780752a9ac253a846b640_6198895_1800x0_resize_q75_box.jpg 1800w,
    /issues/1/stack-shakespeare-and-company-membership-activities/images/stacking-part_v2.jpg 6016w"
     class="landscape"><figcaption>
        <p>Close-up of the finished model of membership activities of Shakespeare and Company Library
        </p>
    </figcaption>
</figure>
<div class="txt-only" id="">
⩩&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;⟩
| FIGURE. A partition of a paper model against dark background with years printed on the base.
|
| CAPTION: Close-up of the finished model of membership activities of Shakespeare and Company Library
⩩&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;⟩
</div></p>
<p>Create your own kirigami model of Shakespeare and Company lending library membership activities, as described in <a href="https://startwords.cdh.princeton.edu/issues/1/data-beyond-vision">Data Beyond Vision</a>.</p>
<p>We invite you to participate in the embodiment and visible labor of data work. Download the following models and instructions, use your hands to recreate the data physicalizations we developed, or use them as inspiration to make your own interpretive objects. If you make any of these physicalizations, please share them on social media with the hashtag <a href="https://twitter.com/search?q=(%23DataBeyondVision)">#DataBeyondVision</a>.</p>
<h2 id="tools">Tools</h2>
<ul>
<li>Printer</li>
<li>X-acto knife or other blade</li>
<li>Bone folder or credit card</li>
<li>Cutting matt or a stack of scrap paper</li>
</ul>
<h2 id="supplies">Supplies</h2>
<ul>
<li>5 Sheets of cover stock paper (around 75lb or 200gsm; letter size is recommended, larger also works)</li>
<li>Double-sided tape (optional)</li>
</ul>
<h2 id="steps">Steps</h2>
<ol>
<li>Download <a href="stacking-chart_instructions.pdf">the PDF</a></li>
<li>Print on cardstock paper at actual size</li>
<li>Cut along the vertical solid lines</li>
<li>Fold along the horizontal dotted lines. Follow the legend for mountain and valley folds.</li>
<li>Set up on a table or shelf</li>
<li>For best results, set on a table against a wall and use double-stick tape to fix to table and wall surface (optional)</li>
</ol>
<h2 id="yield">Yield</h2>
<p>kirigami model of New and Continuing Shakespeare and Company Library Membership Activities

<div class="sketchfab-embed-wrapper">
    <iframe
        id="sketchfab-96403a4659414537b470f03da96d7a88"
        aria-label="3D model showing a folded long paper as base, with opened cuts folded into additional panels."
        frameborder="0"
        allow="autoplay; fullscreen; vr"
        mozallowfullscreen="true"
        webkitallowfullscreen="true"
        loading="lazy"
        src="https://sketchfab.com/models/96403a4659414537b470f03da96d7a88/embed?autospin=0.2&amp;autostart=0&amp;camera=0&amp;preload=1&amp;ui_controls=1&amp;ui_infos=1&amp;ui_inspector=1&amp;ui_stop=1&amp;ui_watermark=1&amp;ui_watermark_link=1">
    </iframe>
    
    
    <figure class="preview">
        <img src="images/modeling-3d-alt.jpg" alt="Three photos from multiple angles showing a folded long paper as base, with opened cuts folded into additional panels."/>
        <figcaption><p>The online version of this essay includes an interactive 3D viewer displaying a model of this object.</p></figcaption>
    </figure>
    
</div>

<div class="txt-only" id="">
⩩&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;⟩
| FIGURE. 3D model showing a folded long paper as base, with opened cuts folded into additional panels.
⩩&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;⟩
</div></p>
]]></content></entry><entry><title type="html">Their Data, Ourselves: Illness as Information</title><link href="https://startwords.cdh.princeton.edu/issues/1/their-data-ourselves/?utm_source=atom_feed" rel="alternate" type="text/html"/><id>https://startwords.cdh.princeton.edu/issues/1/their-data-ourselves/</id><author><name>Rebecca Munson</name></author><published>2020-10-01T00:00:00+00:00</published><updated>2020-10-23T16:32:45-04:00</updated><content type="html"><![CDATA[<p>When I was growing up I liked to read about dying children. I’m not talking about the Victorian orphan kind of dying, not the dying of storybooks, but children who were terminally ill.</p>
<p>I was twelve and fixated on books written by an author with the improbable name of Lurlene McDaniel. The first book I encountered was <em>Six Months to Live</em>, which chronicled the life of a popular teenager in the wake of her diagnosis with leukemia. Not all of McDaniel&rsquo;s characters had cancer; they wrestled with all kinds of chronic illnesses (cystic fibrosis, hemophilia, diabetes) as well as the untimely death of loved ones from causes including suicide. McDaniel&rsquo;s books were about grief and communities formed through crisis.</p>
<p>These books would have been perfect for a budding hypochondriac, or for a reader inclined towards purple prose and melodrama, but I read them instead for medical details, taking mental notes on how to recognize signs and symptoms and stockpiling already-outdated knowledge about treatment options. Rather than imagining myself as the sick main character, I occupied the position of the doctor, a role I planned (at the time) to take on later in real life. It turned out, though, that I would have to be the protagonist anyway.</p>
<p>I was diagnosed with Stage 4 breast cancer in January 2019. I was thirty-four at the time, with zero family history and no warning signs aside from the lump I hoped fervently would be a cyst. Immediately, I was launched into a world at once familiar and alien. I had grown up among doctors and research scientists in the orbit of Washington University School of Medicine, largely because my father is a medical ethicist with an abiding interest in the practical applications of his work. I had even worked in a research laboratory there from ages sixteen to twenty, studying&mdash;of all things&mdash;the genetics of breast cancer.</p>

<blockquote class="pull left">
    …my best chance at coping with cancer was to make sure I was a research subject, to transform my body as rapidly as possible into the right kind of data.
</blockquote>
<p>Is it any wonder, then, that I investigated my treatment options as though I were the PI on an exploratory grant rather than a cancer patient? The type of breast cancer I have (triple negative) is particularly rare and intractable. At the time of my diagnosis it had already progressed to its most advanced stage with metastases to lungs, liver, and bones. It was immediately clear that finding promising clinical trials would be my best option. My parents and I (all academics) and circle of friends (ditto) kicked into research mode, scouring databases and firing off emails to friends from conferences, people from our past, even casual acquaintances who might have a line on newer, more successful treatments. The numbers were not good. We wanted some better numbers.</p>
<p>As I made phone calls to oncologists and combed through the clinical trials database, I performed a distancing maneuver that I first began practicing when reading Lurlene McDaniel; I became a clinical observer of a diseased body, only this time it was my own. I mentally dissected it, narrowing it down to the cancerous focal points that became all that mattered. I lay repeatedly in CT and MRI machines and held my breath through biopsies with only local anesthetics, willing myself out of the body I was at the same time trying so hard to save.</p>
<p>I became at once both object and analyst, alienating my self (with her feelings about her body and her illness) from my body as a source of information about potential causes and, hopefully, potential cures. In some ways it was the extreme of Cartesian dualism—I would think as the large magnets in the MRI machine echoed all around me, that my consciousness should roam so freely while I tried my hardest not to move a muscle in order to produce as clear an image of my body as possible. I was the mind-body problem made flesh, and then abstracted from flesh into numbers that could be either parsed by a machine or interpreted by a human.</p>
<p>Where did this data sit on the spectrum of mental and physical properties? My cancer was physical but, like an electron or snippet of DNA, it was not directly observable without the aid of technologies nor communicable without the intervention of an interpreter. In each of the two trials in which I&rsquo;ve been a subject I have contributed both pieces of my body&mdash;samples of tissue to be used at the discretion of researchers&mdash;and data generated from it. Because I am a participant in clinical trials, the status of my embodied data possesses an enduring significance, since it has the potential to influence the funding and availability of future cancer therapies, even the lifespan of future patients.</p>
<p>We all agreed that my best chance at coping with cancer was to make sure I was a research subject, to transform my body as rapidly as possible into the right kind of data: not a mortality statistic but an experimental resource.</p>
<hr>
<p>Cancer is invisible and so are data.</p>
<p>Neither exists in the sense of being detectable, nameable, or identifiable until plucked from their surroundings and marked out with a significance determined by the observer. The observer marks a data point as distinctive, distinguishing the &ldquo;that&rdquo; from the &ldquo;not-that&rdquo; of everything around it. Even if a data point is meant to be representative, to stand in for a larger phenomenon, the act of selecting it renders the data point distinctive. The data you select&mdash;and the data you don&rsquo;t&mdash;say something about you as well as about them. Data are not objective phenomena. It is for this reason that digital humanities scholar Johanna Drucker has suggested that it is perhaps more accurate to think of data as <em>capta</em> to indicate their situatedness&mdash;that they are seized and, from the moment of demarcation, imbued with an interpretive viewpoint.<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup></p>
<p>The introduction of the interpretive viewpoint in medicine is called diagnosis. During the initial diagnostic phase, as I received phone call after phone call with more bad news, I spent some time thinking about how &ldquo;diagnosis&rdquo; sounded like a term familiar to me from my PhD in Renaissance literature, one that showed up mostly in discussions of tragedies: anagnorisis, meaning &ldquo;recognition,&rdquo; referring to the moment of a critical discovery about a character&rsquo;s own circumstances.</p>

<blockquote class="pull right">
    Any promise of transparency or intelligibility must be counterbalanced by the knowledge that all data have a viewpoint because they have an observer.
</blockquote>
<p>You will not recognize that you have cancer until someone tells you. You may have a suspicion that something is not quite right, but you require professional assessment. Assessment comes in the form of quantification, which requires abstraction. Your physical body is transformed into radiological images by technologies that allow trained specialists to measure and quantify, to compare averages and standard variations, and to relay that information back to you in language that leads, invariably, to another set of numbers concerned with averages and likelihoods. Where is the line between &ldquo;normal&rdquo; and &ldquo;pathological&rdquo;? In whose view is a treatment &ldquo;better&rdquo; or &ldquo;worse&rdquo;? When the questions are of life and death, it is more than a little disconcerting to realize that the answer depends very much on who you&rsquo;re asking.</p>
<p>Cancer exists before it is named, just like data. And even at its moment of detection (capture) its fixity is illusory: it is in cancer&rsquo;s nature to grow and change, just like data. The moment of visibility for both is firmly situated in time, place, and the subject position of the interpreter. Take, for example, the open question of how extensively cancer may have spread to my liver. Unusually for my age, I was actually tested for cancer in 2016, in search of answers to a years-long chronic fatigue for which I still have no good explanation. The bone marrow biopsy showed no cause for concern and even though there was a lesion on my liver, measuring 29mm x 28mm, the conclusion was that it was a benign growth called a hemangioma. (I stand by this view, if only because a cancerous growth on my liver, a canary in a coal mine, would have become significantly worse over the course of three years given how aggressive cancer has been elsewhere in my body in the time since my diagnosis.)</p>
<p>My first CT after diagnosis in January 2019 showed the liver lesion to be 29mm x 35mm, a finding that the radiologist remarked might represent growth (and therefore metastasis) or might not, since a difference of 6mm could be caused by different positioning during the scan or different measurements by different doctors. The lesion continued to remain stable on my next CTs, but in March 2019 an additional spot was detected on the right inferior lobe, measuring 12mm. By June 2019 that spot was reported to be 28mm, confirming that my liver had been affected. In December the second lesion was measured under 5mm, part of a larger pattern of regression that meant the treatment was working (which it had been doing but would not continue to do past that month). A third spot on the left lobe was recorded in three scans, showing up as 5mm August 2019, 4mm in September, and 3mm in November. By December that third spot went unremarked. The large lesion from 2016, however, merely waxed and waned, never clocking in at more than 35mm or fewer than 27mm, numbers easily attributable to variation in imaging or interpretation.</p>
<p>So was the original liver lesion a benign hemangioma, a coincidence unrelated to the cancer that would metastasize years later, or the first sign that a breast cancer concealed in single, unmassed (and therefore undetectable) cells had already done so? Did the 2016 scan produce bad data, or rather bad capta? Was the interpretation of the image biased by the fact that I was young (thirty-one) and, aside from mysterious, debilitating fatigue, healthy? Should I have acted differently? Should my doctors? The ramifications of these questions for my diagnosis and emotional response to it are profound: a cancer that had been present since 2016 would look relatively less aggressive compared to one that was new as of 2019; being misdiagnosed and living with cancer for three years would compound my fear (and guilt) that my situation was preventable.</p>
<p>There is no way to know, though the probability is strong that the first lesion was and remains benign. But that uncertainty is the constant condition of the body as data. Any promise of transparency or intelligibility must be counterbalanced by the knowledge that all data have a viewpoint because they have an observer.</p>
<hr>
<p>In <em>The Undying</em>, her account of treatment for triple-negative breast cancer, the poet Anne Boyer writes that &ldquo;a patient is a system-containing object within a series of interlocking systems full of other system-containing objects&rdquo; and that &ldquo;to take a thing or set of things from one system and reclassify these as elements in another also resembles diagnosis, which takes information from our bodies and rearranges what came from inside of us into a system imposed from far away.”<sup id="fnref:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup> Cancer is caused by the body&rsquo;s own cells growing out of control, a hostile takeover from within that violates the rules of the system already in place. Reclassified, your own cells are a disease and your own body a weapon. Reclassified, you are not an individual but a patient and your body not a collection of sensations but a rich mine of information.</p>

<blockquote class="pull left">
    Living your life as medical data is an alienating experience particularly if, like me, you look bad on paper.
</blockquote>
<p>Once you enter the systems of modern medicine you become data to be ingested, part of the larger dataset of those who have previously been ill, been treated, and lived or died. This is not the &ldquo;violence of abstraction&rdquo; of which Marxist theorists wrote, yet the phrase seems equally applicable to the anonymity&mdash;the interchangeability&mdash;of those subsumed by the medical-industrial complex. Part of the reason that I sought clinical trials was that I felt that it was the best way to enable physicians to see me as an individual whose life, and whose treatment, mattered. I was eager to make myself an object of study and contribute to thwarting the disease that is threatening my life. But I was equally eager not to be simply tagged, processed, and swept through the prescribed (and not very promising) series of treatments that constituted the &ldquo;standard of care&rdquo; for my type of cancer.</p>
<p>Living your life as medical data is an alienating experience particularly if, like me, you look bad on paper. Boyer describes herself as &ldquo;a patient made of information, produced by the work of women,&rdquo; remarking on the &ldquo;paradoxical simultaneity&rdquo; of the care work and data work performed by the overwhelmingly female nursing staff in their interactions with patients.<sup id="fnref:3"><a href="#fn:3" class="footnote-ref" role="doc-noteref">3</a></sup> It is crucial to focus on the significance of the word &ldquo;made&rdquo; here. None of us exist as free-floating data points; medical data are <em>made</em>, are in fact <em>capta</em> that depend on nurses and technicians, radiologists and pathologists, and, perhaps most of all, on patients.</p>
<hr>
<p>Cancer is invisible, and so are viruses.</p>
<p>I have worked on this essay over the course of the COVID-19 pandemic. I began it in March 2020, days after my workplace went remote and fourteen months after my initial cancer diagnosis. It is now October 2020, my third line of treatment has failed, and I am moving onto another. The pandemic still ravages much of the country. Conceiving of bodies as &ldquo;made of information&rdquo; (and participating in the quantification of illness and the violence of abstraction that accompanies this process) has become a national way of life.</p>
<p>I have lived nearly two years tolerating the same kind of existential uncertainty and fear of an alien invader in the body that the world as a whole is now experiencing. I have played my own doctor, watching my body for signs that a treatment is working, or that it is not, in much the same way we monitor ourselves for symptoms. I have tried to anticipate what will happen if I become severely immunocompromised and have given up many of the pleasures that made my life better before (traveling, going out with friends) in the name of my health. I have offered my body up as data to research scientists with the goal of furthering not just my own treatment but survival prospects for the future.</p>
<p>I did not know that I was in training for a time when we would all of necessity be regarded as bodies with the potential to produce valuable data about the spread and effects of COVID-19. We are constantly starved for numbers, for data on infections and recoveries and for statistical models that may relieve us of the uncertainty we feel about the future. I cannot provide that. But I can tell you to be cautious readers of data and statistics that speak with any pretense to authority right now, even though I crave them too.</p>
<p>We are in the middle of the data. Some of us clamor loudly to be heard, to be seen and counted by institutions that deliberately overlook and under-report. For some of us, visibility entails vulnerability and the threat of unemployment or detainment weighs so heavily that illness must remain invisible, ignored or hidden. We are the data, but we do not always speak for ourselves.</p>
<p>Susan Sontag wrote in <em>Illness as Metaphor</em> that &ldquo;Everyone who is born holds dual citizenship, in the kingdom of the well and in the kingdom of the sick. Although we all prefer to use only the good passport, sooner or later each of us is obliged, at least for a spell, to identify ourselves as citizens of that other place.”<sup id="fnref:4"><a href="#fn:4" class="footnote-ref" role="doc-noteref">4</a></sup> A pandemic transcends borders but does not do away with the kingdom of the sick. As someone already resident, I can say to you: welcome. The hardest thing about being here is the grief for what we have lost, including a sense of normalcy. The best thing, though, is what we may find: community in a time of crisis.</p>
<section class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1" role="doc-endnote">
<p>Drucker, Johanna. &ldquo;Humanities Approaches to Graphical Display.&rdquo; <em>Digital Humanities Quarterly</em> 005, no. 1 (March 10, 2011). <a href="http://www.digitalhumanities.org/dhq/vol/5/1/000091/000091.html">http://www.digitalhumanities.org/dhq/vol/5/1/000091/000091.html</a> <a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:2" role="doc-endnote">
<p>Boyer, Anne. <em>The Undying: Pain, Vulnerability, Mortality, Medicine, Art, Time, Dreams, Data, Exhaustion, Cancer, and Care</em>. New York: Farrar, Straus and Giroux, 2019. p. 65 and 14. <a href="#fnref:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:3" role="doc-endnote">
<p>Boyer, <em>Undying,</em> 55. <a href="#fnref:3" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:4" role="doc-endnote">
<p>Susan Sontag, <em>Illness as Metaphor</em> (New York: Farrar, Straus and Giroux, 1978), 3. <a href="#fnref:4" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</section>]]></content></entry><entry><title type="html">Weave Derrida's References</title><link href="https://startwords.cdh.princeton.edu/issues/1/weave-derridas-references/?utm_source=atom_feed" rel="alternate" type="text/html"/><link href="https://startwords.cdh.princeton.edu/issues/1/print-a-model-of-the-shakespeare-and-company-lending-library-membership/?utm_source=atom_feed" rel="related" type="text/html" title="Print a model of the Shakespeare and Company Lending Library Membership"/><link href="https://startwords.cdh.princeton.edu/issues/1/stack-shakespeare-and-company-membership-activities/?utm_source=atom_feed" rel="related" type="text/html" title="Stack Shakespeare and Company Membership Activities"/><id>https://startwords.cdh.princeton.edu/issues/1/weave-derridas-references/</id><author><name>Gissoo Doroudian</name></author><published>2020-10-01T00:00:00+00:00</published><updated>2020-10-23T16:32:45-04:00</updated><content type="html"><![CDATA[<p>











 








<figure>
    <img loading="lazy" alt="A scarf with alternating bands of blue fabrics resting on a table." role="img" sizes="(max-width: 768px) 100%, 80%"srcset="/issues/1/weave-derridas-references/images/weaving-display_hu6e182ffdd39bfbfe34e02dfa38c31055_5080252_500x0_resize_q75_box.jpg 500w,
    /issues/1/weave-derridas-references/images/weaving-display_hu6e182ffdd39bfbfe34e02dfa38c31055_5080252_800x0_resize_q75_box.jpg 800w,
    /issues/1/weave-derridas-references/images/weaving-display_hu6e182ffdd39bfbfe34e02dfa38c31055_5080252_1200x0_resize_q75_box.jpg 1200w,
    /issues/1/weave-derridas-references/images/weaving-display_hu6e182ffdd39bfbfe34e02dfa38c31055_5080252_1500x0_resize_q75_box.jpg 1500w,
    /issues/1/weave-derridas-references/images/weaving-display_hu6e182ffdd39bfbfe34e02dfa38c31055_5080252_1800x0_resize_q75_box.jpg 1800w,
    /issues/1/weave-derridas-references/images/weaving-display.jpg 3400w"
     class="landscape"><figcaption>
        <p>Completed weaving of the first 13 pages of Derrida’s references in chapter 1 of Of Grammatology.<span class="attribution">Photo by Shelley Szwast</span>
        </p>
    </figcaption>
</figure>
<div class="txt-only" id="">
⩩&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;⟩
| FIGURE. A scarf with alternating bands of blue fabrics resting on a table.
|
| CAPTION: Completed weaving of the first 13 pages of Derrida’s references in chapter 1 of Of Grammatology
| ATTRIBUTION: Photo by Shelley Szwast
⩩&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;⟩
</div></p>
<p>Create your own data weaving of Derrida’s references in chapter 1 of <em>Of Grammatology</em>, as described in <a href="https://startwords.cdh.princeton.edu/issues/1/data-beyond-vision">Data Beyond Vision</a>.</p>
<p>We invite you to participate in the embodiment and visible labor of data work. Download the following models and instructions, use your hands to recreate the data physicalizations we developed, or use them as inspiration to make your own interpretive objects. If you make any of these physicalizations, please share them on social media with the hashtag <a href="https://twitter.com/search?q=(%23DataBeyondVision)">#DataBeyondVision</a>.</p>
<h2 id="tools">Tools</h2>
<ul>
<li>Loom – Rigid Heddle Loom is recommended for beginners. DIY backstrap loom with a string heddle is also possible.</li>
<li>Stick Shuttle (at least 1)<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup></li>
<li>Scissors</li>
<li>Long straw or thin dowel</li>
<li>Yarn needle (optional)</li>
</ul>
<h2 id="supplies">Supplies</h2>
<ul>
<li>9 bundles of yarn of 6 different colors:
<ul>
<li>4 light (size 3), 2 different colors for plain text, page separator, and warp. Be sure to choose a sturdy, smooth yarn for your warp. Yarn with 2 strands<sup id="fnref:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup> is recommended for warp.</li>
<li>1 bulky (size 5) – for epigraphs</li>
<li>2 super bulky (size 6), 2 different colors – for footnotes and citations</li>
<li>2 jumbo (size 7) – for quotations</li>
</ul>
</li>
</ul>
<h2 id="steps">Steps</h2>
<ol>
<li>Let’s learn about some <a href="#key-points-about-the-rigid-heddle-loom">key points and terms on the loom</a>, and <a href="#how-to-set-up-the-warp-on-the-loom">how to set up the warp on the loom</a>.</li>
<li>Let’s learn about the weaving types used in this piece and what each represents in the <a href="#weaving-types">“Weaving Types” section</a>.</li>
<li>Let’s weave the Derrida references page by page, covered in the <a href="https://startwords.cdh.princeton.edu/issues/1/weave-references/Pattern-Guide-for-Weaving-Derridas-Margins.pdf">“Pattern Guide for Weaving Derrida’s Margins”</a>.</li>
</ol>
<h2 id="yield">Yield</h2>
<p>Weaving of the references in chapter one of Jacques Derrida’s <em>de la Grammatologie</em> (1967).</p>
<p><div class="deepzoom" id="openseadragon-2" style="height: 10em" aria-label="Interactive zoomable viewer displaying a blue scarf with alternating bands of varied threads."></div>
<script>
    window.addEventListener("DOMContentLoaded", function() {
        OpenSeadragon({
            id: "openseadragon-2",
            prefixUrl: "https://cdn.jsdelivr.net/npm/openseadragon@2.4/build/openseadragon/images/",
            preserveViewport: true,
            visibilityRatio:    1,
            minZoomLevel:       1,
            defaultZoomLevel:   1,
            gestureSettingsMouse: { scrollToZoom: false },
            tileSources: "https:\/\/iiif.princeton.edu\/loris\/iiif\/2\/figgy_prod%2F58%2F51%2Fd4%2F5851d48b225b42699a13181c778a6095%2Fintermediate_file.jp2\/info.json",
        });
    });
</script>


<figure class="deepzoom-preview">
    <img src="images/weaving-deepzoom-alt.jpg" alt="Composite of two images from the high resolution image shown in the deep zoom viewer: one showing the full length of the woven piece, and another with a close up showing the threads and different weaving patterns."/>
    <figcaption><p>The online version of this essay includes an interactive deep zoom viewer displaying a high resolution capture of this object.</p></figcaption>
</figure>

<div class="txt-only" id="">
⩩&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;⟩
| FIGURE. Interactive zoomable viewer displaying a blue scarf with alternating bands of varied threads.
⩩&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;⟩
</div></p>
<h2 id="key-points-about-the-rigid-heddle-loom">Key points about the Rigid Heddle Loom</h2>
<p>











 








<figure>
    <img loading="lazy" alt="Wooden loom sitting on table with blue thread strung taught." role="img" sizes="(max-width: 768px) 100%, 80%"srcset="/issues/1/weave-derridas-references/images/loom-neutral-position_hu8cc7c7aed7826c8aacb143f017aeac83_3956849_500x0_resize_q75_box.jpg 500w,
    /issues/1/weave-derridas-references/images/loom-neutral-position_hu8cc7c7aed7826c8aacb143f017aeac83_3956849_800x0_resize_q75_box.jpg 800w,
    /issues/1/weave-derridas-references/images/loom-neutral-position_hu8cc7c7aed7826c8aacb143f017aeac83_3956849_1200x0_resize_q75_box.jpg 1200w,
    /issues/1/weave-derridas-references/images/loom-neutral-position_hu8cc7c7aed7826c8aacb143f017aeac83_3956849_1500x0_resize_q75_box.jpg 1500w,
    /issues/1/weave-derridas-references/images/loom-neutral-position_hu8cc7c7aed7826c8aacb143f017aeac83_3956849_1800x0_resize_q75_box.jpg 1800w,
    /issues/1/weave-derridas-references/images/loom-neutral-position.jpg 3400w"
     class="landscape"><figcaption>
        <p>Heddle in neutral position.<span class="attribution">Photo by Gissoo Doroudian, edited by Xinyi Li.</span>
        </p>
    </figcaption>
</figure>
<div class="txt-only" id="">
⩩&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;⟩
| FIGURE. Wooden loom sitting on table with blue thread strung taught.
|
| CAPTION: Heddle in neutral position.
| ATTRIBUTION: Photo by Gissoo Doroudian, edited by Xinyi Li.
⩩&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;⟩
</div>












 








<figure>
    <img loading="lazy" alt="Wooden loom sitting on table with blue thread strung taught, pulled upwards." role="img" sizes="(max-width: 768px) 100%, 80%"srcset="/issues/1/weave-derridas-references/images/loom-upper-position_hu27f9665dfeb0407193f95315e61863a7_4205073_500x0_resize_q75_box.jpg 500w,
    /issues/1/weave-derridas-references/images/loom-upper-position_hu27f9665dfeb0407193f95315e61863a7_4205073_800x0_resize_q75_box.jpg 800w,
    /issues/1/weave-derridas-references/images/loom-upper-position_hu27f9665dfeb0407193f95315e61863a7_4205073_1200x0_resize_q75_box.jpg 1200w,
    /issues/1/weave-derridas-references/images/loom-upper-position_hu27f9665dfeb0407193f95315e61863a7_4205073_1500x0_resize_q75_box.jpg 1500w,
    /issues/1/weave-derridas-references/images/loom-upper-position_hu27f9665dfeb0407193f95315e61863a7_4205073_1800x0_resize_q75_box.jpg 1800w,
    /issues/1/weave-derridas-references/images/loom-upper-position.jpg 3400w"
     class="landscape"><figcaption>
        <p>Heddle in upper position.<span class="attribution">Photo by Gissoo Doroudian, edited by Xinyi Li.</span>
        </p>
    </figcaption>
</figure>
<div class="txt-only" id="">
⩩&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;⟩
| FIGURE. Wooden loom sitting on table with blue thread strung taught, pulled upwards.
|
| CAPTION: Heddle in upper position.
| ATTRIBUTION: Photo by Gissoo Doroudian, edited by Xinyi Li.
⩩&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;⟩
</div>












 








<figure>
    <img loading="lazy" alt="Wooden loom sitting on table with blue thread strung taught, pulled downwards." role="img" sizes="(max-width: 768px) 100%, 80%"srcset="/issues/1/weave-derridas-references/images/loom-lower-position_huaab913883759ea62d53fc817d5b16562_3740196_500x0_resize_q75_box.jpg 500w,
    /issues/1/weave-derridas-references/images/loom-lower-position_huaab913883759ea62d53fc817d5b16562_3740196_800x0_resize_q75_box.jpg 800w,
    /issues/1/weave-derridas-references/images/loom-lower-position_huaab913883759ea62d53fc817d5b16562_3740196_1200x0_resize_q75_box.jpg 1200w,
    /issues/1/weave-derridas-references/images/loom-lower-position_huaab913883759ea62d53fc817d5b16562_3740196_1500x0_resize_q75_box.jpg 1500w,
    /issues/1/weave-derridas-references/images/loom-lower-position_huaab913883759ea62d53fc817d5b16562_3740196_1800x0_resize_q75_box.jpg 1800w,
    /issues/1/weave-derridas-references/images/loom-lower-position.jpg 3400w"
     class="landscape"><figcaption>
        <p>Heddle in lower position.<span class="attribution">Photo by Gissoo Doroudian, edited by Xinyi Li.</span>
        </p>
    </figcaption>
</figure>
<div class="txt-only" id="">
⩩&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;⟩
| FIGURE. Wooden loom sitting on table with blue thread strung taught, pulled downwards.
|
| CAPTION: Heddle in lower position.
| ATTRIBUTION: Photo by Gissoo Doroudian, edited by Xinyi Li.
⩩&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;⟩
</div>












 








<figure>
    <img loading="lazy" alt="Close-up of wooden loom showing long wooden rod with blue yarn wrapped around it." role="img" sizes="(max-width: 768px) 100%, 80%"srcset="/issues/1/weave-derridas-references/images/shuttle_hu517e8a7be430e6ac680aac87e5b4d973_4964328_500x0_resize_q75_box.jpg 500w,
    /issues/1/weave-derridas-references/images/shuttle_hu517e8a7be430e6ac680aac87e5b4d973_4964328_800x0_resize_q75_box.jpg 800w,
    /issues/1/weave-derridas-references/images/shuttle_hu517e8a7be430e6ac680aac87e5b4d973_4964328_1200x0_resize_q75_box.jpg 1200w,
    /issues/1/weave-derridas-references/images/shuttle_hu517e8a7be430e6ac680aac87e5b4d973_4964328_1500x0_resize_q75_box.jpg 1500w,
    /issues/1/weave-derridas-references/images/shuttle_hu517e8a7be430e6ac680aac87e5b4d973_4964328_1800x0_resize_q75_box.jpg 1800w,
    /issues/1/weave-derridas-references/images/shuttle.jpg 3400w"
     class="landscape"><figcaption>
        <p>Shuttle, a tool used to pass the yarn through the warp.<span class="attribution">Photo by Gissoo Doroudian, edited by Xinyi Li.</span>
        </p>
    </figcaption>
</figure>
<div class="txt-only" id="">
⩩&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;⟩
| FIGURE. Close-up of wooden loom showing long wooden rod with blue yarn wrapped around it.
|
| CAPTION: Shuttle, a tool used to pass the yarn through the warp.
| ATTRIBUTION: Photo by Gissoo Doroudian, edited by Xinyi Li.
⩩&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;⟩
</div>












 








<figure>
    <img loading="lazy" alt="Close-up of crossed yarn with vertical threads labeled “Warp” and horizontal yarns threads labeled “Weft”." role="img" sizes="(max-width: 768px) 100%, 80%"srcset="/issues/1/weave-derridas-references/images/warp-weft-annotated_hu7bc76d175bd5292bb8defbabd9d6bf04_5104258_500x0_resize_q75_box.jpg 500w,
    /issues/1/weave-derridas-references/images/warp-weft-annotated_hu7bc76d175bd5292bb8defbabd9d6bf04_5104258_800x0_resize_q75_box.jpg 800w,
    /issues/1/weave-derridas-references/images/warp-weft-annotated_hu7bc76d175bd5292bb8defbabd9d6bf04_5104258_1200x0_resize_q75_box.jpg 1200w,
    /issues/1/weave-derridas-references/images/warp-weft-annotated_hu7bc76d175bd5292bb8defbabd9d6bf04_5104258_1500x0_resize_q75_box.jpg 1500w,
    /issues/1/weave-derridas-references/images/warp-weft-annotated_hu7bc76d175bd5292bb8defbabd9d6bf04_5104258_1800x0_resize_q75_box.jpg 1800w,
    /issues/1/weave-derridas-references/images/warp-weft-annotated.jpg 3000w"
     class="portrait"><figcaption>
        <p>“Warp” and “Weft” yarns.<span class="attribution">Photo by Gissoo Doroudian.</span>
        </p>
    </figcaption>
</figure>
<div class="txt-only" id="">
⩩&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;⟩
| FIGURE. Close-up of crossed yarn with vertical threads labeled “Warp” and horizontal threads labeled “Weft”.
|
| CAPTION: “Warp” and “Weft” yarns.
| ATTRIBUTION: Photo by Gissoo Doroudian.
⩩&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;⟩
</div></p>
<p>The yarn <em>on which</em> you weave a piece, which acts as the base of the weaving and sits longitudinally is called “warp”; yarns you use to weave a piece are called “weft”.<sup id="fnref:3"><a href="#fn:3" class="footnote-ref" role="doc-noteref">3</a></sup></p>
<h2 id="how-to-set-up-the-warp-on-the-loom">How to set up the warp on the loom</h2>
<p>If you purchase a loom, it will most likely include setup instructions. However, below are a few great resources on how to set up the warp on a Rigid Heddle loom.</p>
<ul>
<li><a href="https://www.youtube.com/watch?v=fa1WrHOTjxY">A video that carefully demonstrates the steps visually and verbally</a></li>
<li><a href="https://www.wearingwoad.com/saori-weaving-tutorial-warping-a-rigid-heddle-loom/">An article that includes a written description of the steps </a></li>
<li><a href="https://www.ashford.co.nz/images/download_pdfs/learn_to/learn_to_weave_on_the_rigid_heddle.pdf">A downloadable PDF that includes visual and written instructions </a></li>
</ul>
<p>Note: Approximately 37 inches of warp yarn was cut and set up on the loom to weave pages 15-27, which makes up half of chapter 1 of <em>Of Grammatology</em>.</p>
<h2 id="weaving-types">Weaving Types</h2>
<p>Weaving types used in this piece:</p>
<ol>
<li><a href="#plain-weave">Plain weave</a></li>
<li><a href="#soumak-weave">Soumak weave</a></li>
<li><a href="#pile-loop-weave">Pile loop weave</a></li>
<li><a href="#rya-knot">Rya knot</a></li>
</ol>
<h3 id="plain-weave">Plain Weave</h3>
<p>Note: If the yarn is thin you can use the shuttle and the upper and lower position of the heddle to weave the Plain weave. However, if the yarn is too thick you need to leave the heddle in neutral position and use your hands to weave.</p>
<h4 id="method-1">Method #1</h4>
<p>This method was used to represent plain text (in royal blue) and page separation in (white).</p>
<p>











 








<figure>
    <img loading="lazy" alt="Composite of eight images showing various stages of weaving." role="img" sizes="(max-width: 768px) 100%, 80%"srcset="/issues/1/weave-derridas-references/images/plain-weave-thin_hu3ca7a7a934bf02e4eb10cd8d71d42ab0_6774351_500x0_resize_q75_box.jpg 500w,
    /issues/1/weave-derridas-references/images/plain-weave-thin_hu3ca7a7a934bf02e4eb10cd8d71d42ab0_6774351_800x0_resize_q75_box.jpg 800w,
    /issues/1/weave-derridas-references/images/plain-weave-thin_hu3ca7a7a934bf02e4eb10cd8d71d42ab0_6774351_1200x0_resize_q75_box.jpg 1200w,
    /issues/1/weave-derridas-references/images/plain-weave-thin_hu3ca7a7a934bf02e4eb10cd8d71d42ab0_6774351_1500x0_resize_q75_box.jpg 1500w,
    /issues/1/weave-derridas-references/images/plain-weave-thin_hu3ca7a7a934bf02e4eb10cd8d71d42ab0_6774351_1800x0_resize_q75_box.jpg 1800w,
    /issues/1/weave-derridas-references/images/plain-weave-thin.jpg 3000w"
     class="portrait"><figcaption>
        <p>How to make a Plain weave in eight steps utilizing the shuttle along with changing the heddle positions, appropriate for thinner yarns.<span class="attribution">Photos by Shelley Szwast and Gissoo Doroudian.</span>
        </p>
    </figcaption>
</figure>
<div class="txt-only" id="">
⩩&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;⟩
| FIGURE. Composite of eight images showing various stages of weaving.
|
| CAPTION: How to make a Plain weave in eight steps utilizing the shuttle along with changing the heddle positions, appropriate for thinner yarns.
| ATTRIBUTION: Photos by Shelley Szwast and Gissoo Doroudian.
⩩&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;⟩
</div></p>
<p>Heddle position: upper and lower</p>
<p>Yarn size: 3/light</p>
<p>#1-5 below correspond to the numbers on the images.</p>
<p>To create a Plain weave:</p>
<ol>
<li>Place the heddle in the upper position.</li>
<li>Insert the shuttle into the opening (called the shed) between the raised and lowered yarns.</li>
<li>Take the shuttle out the other side.</li>
<li>Press the weft into place using the heddle.</li>
<li>Place the heddle in the lower position. On the second pass back (to start the second row), going left to right, repeat the process above. (Reflected in #6-8 in the photos)</li>
</ol>
<p>The basic weave continues on in this way over as many warp yarns as you wish.</p>
<p>Note: Starting the weave from left to right going <em>over</em> the first warp yarn is better because it enables weaving in the loose end of the weft yarn easily. Starting by going under the first warp yarn would cause the weave to look not as seamless.</p>
<p>Learned and adapted from: <a href="https://www.theweavingloom.com/weaving-techniques-the-plain-weave/">https://www.theweavingloom.com/weaving-techniques-the-plain-weave/</a></p>
<h4 id="method-2">Method #2</h4>
<p>This method was used to represent quotations.</p>
<p>











 








<figure>
    <img loading="lazy" alt="Composite of four images showing various stages of weaving." role="img" sizes="(max-width: 768px) 100%, 80%"srcset="/issues/1/weave-derridas-references/images/plain-weave-thick_hu995707cad5af44648480f254d4b14b33_5182014_500x0_resize_q75_box.jpg 500w,
    /issues/1/weave-derridas-references/images/plain-weave-thick_hu995707cad5af44648480f254d4b14b33_5182014_800x0_resize_q75_box.jpg 800w,
    /issues/1/weave-derridas-references/images/plain-weave-thick_hu995707cad5af44648480f254d4b14b33_5182014_1200x0_resize_q75_box.jpg 1200w,
    /issues/1/weave-derridas-references/images/plain-weave-thick_hu995707cad5af44648480f254d4b14b33_5182014_1500x0_resize_q75_box.jpg 1500w,
    /issues/1/weave-derridas-references/images/plain-weave-thick_hu995707cad5af44648480f254d4b14b33_5182014_1800x0_resize_q75_box.jpg 1800w,
    /issues/1/weave-derridas-references/images/plain-weave-thick.jpg 3400w"
     class="landscape"><figcaption>
        <p>How to make a Plain weave in four steps utilizing the hands to pass the yarn through the warp.<span class="attribution">Photos by Gissoo Doroudian.</span>
        </p>
    </figcaption>
</figure>
<div class="txt-only" id="">
⩩&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;⟩
| FIGURE. Composite of eight images showing various stages of weaving.
|
| CAPTION: How to make a Plain weave in four steps utilizing the hands to pass the yarn through the warp.
| ATTRIBUTION: Photos by Gissoo Doroudian.
⩩&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;⟩
</div></p>
<p>Heddle position: neutral</p>
<p>Yarn size: 7/jumbo</p>
<p>(Reflected in #1 in the photos)</p>
<ol>
<li>Pull the weft yarn over the first warp yarn,</li>
<li>under the second warp yarn,</li>
<li>over the third warp yarn.</li>
</ol>
<p>Continue until you get to the end of the warp yarn. On the second pass back (to start the second row), going right to left: (Reflected in #2-4 in the photos)</p>
<ol start="4">
<li>Pass the weft yarn under the first warp yarn,</li>
<li>over the second warp yarn,</li>
<li>under the third warp yarn.</li>
</ol>
<p>Continue until the first warp yarn is met again. The basic weave continues on in this way over as many warp yarn as you wish.</p>
<p>Learned and adapted from:</p>
<p><a href="https://www.theweavingloom.com/weaving-techniques-the-plain-weave/">https://www.theweavingloom.com/weaving-techniques-the-plain-weave/</a>
<a href="https://www.youtube.com/watch?v=ZypHL7S7V80">https://www.youtube.com/watch?v=ZypHL7S7V80</a></p>
<h3 id="soumak-weave">Soumak Weave</h3>
<p>This technique was used to represent footnotes.</p>
<p>











 








<figure>
    <img loading="lazy" alt="Composite of eight images showing various stages of weaving." role="img" sizes="(max-width: 768px) 100%, 80%"srcset="/issues/1/weave-derridas-references/images/soumak-weave_hu069c7b8a2c95c170a85a583e1c032728_4634251_500x0_resize_q75_box.jpg 500w,
    /issues/1/weave-derridas-references/images/soumak-weave_hu069c7b8a2c95c170a85a583e1c032728_4634251_800x0_resize_q75_box.jpg 800w,
    /issues/1/weave-derridas-references/images/soumak-weave_hu069c7b8a2c95c170a85a583e1c032728_4634251_1200x0_resize_q75_box.jpg 1200w,
    /issues/1/weave-derridas-references/images/soumak-weave_hu069c7b8a2c95c170a85a583e1c032728_4634251_1500x0_resize_q75_box.jpg 1500w,
    /issues/1/weave-derridas-references/images/soumak-weave_hu069c7b8a2c95c170a85a583e1c032728_4634251_1800x0_resize_q75_box.jpg 1800w,
    /issues/1/weave-derridas-references/images/soumak-weave.jpg 3000w"
     class="portrait"><figcaption>
        <p>How to make a Soumak weave in eight steps.
        </p>
    </figcaption>
</figure>
<div class="txt-only" id="">
⩩&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;⟩
| FIGURE. Composite of eight images showing various stages of weaving.
|
| CAPTION: How to make a Soumak weave in eight steps.
⩩&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;⟩
</div></p>
<p>Heddle position: neutral</p>
<p>Yarn size: 6/super bulky</p>
<p>Note: images above were taken on a paper prototype loom, therefore the warp yarns are pulling more than they would on a heddle loom.</p>
<p>#1-3 below correspond to the numbers on the images.</p>
<p>The Soumak weave is the process of wrapping the weft yarn around the warp yarn.</p>
<p>To create the Soumak pattern:</p>
<ol>
<li>Place the end of the weft yarn behind the two warp yarns, with the end coming out to the front on the right-hand side of the two warp yarns.</li>
<li>Pull out the next two warp yarns. While holding the weft yarn bundling in your right hand, pass the weft yarn behind these two warp yarns from right to left.</li>
<li>After pulling the weft yarn right through to form your first slanted stitch make sure not to pull too tightly as this will distort the warp.</li>
</ol>
<p>Continue until you get to the end of the warp yarns. On the second pass back (to start the second row), going right to left,</p>
<ol start="4">
<li>At the end of the row wrap around the last two warp yarns twice. (Reflected in #6 in the photos)</li>
<li>Pull out the next two warp yarns to the left of the end and holding the yarn bundle in your left hand pass it behind the two warps from left to right. This will create a stitch that slants in the opposite direction. (Reflected in #7 in the photos)</li>
</ol>
<p>Continue until the first warp yarn is met again.</p>
<p>Learned and adapted from: <a href="https://www.youtube.com/watch?v=OaP4eQLRefk">https://www.youtube.com/watch?v=OaP4eQLRefk</a></p>
<h3 id="pile-loop-weave">Pile Loop Weave</h3>
<p>This technique was used to represent epigraphs.</p>
<p>











 








<figure>
    <img loading="lazy" alt="Composite of seven images showing various stages of weaving." role="img" sizes="(max-width: 768px) 100%, 80%"srcset="/issues/1/weave-derridas-references/images/pile-loop-weave_hu30d1a61af9886855d65d2ad3279dcb4c_4767843_500x0_resize_q75_box.jpg 500w,
    /issues/1/weave-derridas-references/images/pile-loop-weave_hu30d1a61af9886855d65d2ad3279dcb4c_4767843_800x0_resize_q75_box.jpg 800w,
    /issues/1/weave-derridas-references/images/pile-loop-weave_hu30d1a61af9886855d65d2ad3279dcb4c_4767843_1200x0_resize_q75_box.jpg 1200w,
    /issues/1/weave-derridas-references/images/pile-loop-weave_hu30d1a61af9886855d65d2ad3279dcb4c_4767843_1500x0_resize_q75_box.jpg 1500w,
    /issues/1/weave-derridas-references/images/pile-loop-weave_hu30d1a61af9886855d65d2ad3279dcb4c_4767843_1800x0_resize_q75_box.jpg 1800w,
    /issues/1/weave-derridas-references/images/pile-loop-weave.jpg 3000w"
     class="portrait"><figcaption>
        <p>How to make a Pile Loop weave in seven steps.<span class="attribution">Photos by Gissoo Doroudian.</span>
        </p>
    </figcaption>
</figure>
<div class="txt-only" id="">
⩩&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;⟩
| FIGURE. Composite of seven images showing various stages of weaving.
|
| CAPTION: How to make a Pile Loop weave in seven steps.
| ATTRIBUTION: Photos by Gissoo Doroudian.
⩩&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;⟩
</div></p>
<p>Heddle position: neutral</p>
<p>Yarn size: 5/bulky</p>
<p>Numbered list below corresponds to the numbers on the images. To create the Pile loop:</p>
<ol>
<li>Weave a row of plain weave in the area that you want your loops, using one or two strands of yarn. Please refer to the <a href="#plain-weave">“Plain Weave”</a> section for instructions. Since this yarn is thinner you can use a yarn needle to pass it through the warp as well.</li>
<li>Take the wooden dowel and pick up your “stitches” by wrapping them around it as shown.</li>
<li>Once the entire Plain weave row is on the dowel, pull the dowel down on the warp so that it brings the loops down to the support rows.</li>
<li>Gently remove the dowel so that you leave behind a row of loops.</li>
<li>Weave another Plain weave row above your loops, and repeat the steps above, while making sure not to pull the weft too much otherwise you’ll start to lose the loops you just made. (Reflected in #5-7 in the photos)</li>
</ol>
<p>Continue in this pattern until you have made all the loops you want. Once done, weave a support row of Plain weave and smash that support row down into your loops. You want to really smash the loop rows down so that your weave doesn’t get super loose once you cut it off the loom.</p>
<p>Learned and adapted from: <a href="https://www.theweavingloom.com/best-of-weaving-technique-pile-loop-weave/">https://www.theweavingloom.com/best-of-weaving-technique-pile-loop-weave/</a></p>
<h3 id="rya-knot">Rya knot</h3>
<p>This technique was used to represent citations.</p>
<p>











 








<figure>
    <img loading="lazy" alt="Composite of four images showing various stages of weaving." role="img" sizes="(max-width: 768px) 100%, 80%"srcset="/issues/1/weave-derridas-references/images/rya-knot-weave_hu1296b2fcbd700f451230e4cdd0880f6e_5437482_500x0_resize_q75_box.jpg 500w,
    /issues/1/weave-derridas-references/images/rya-knot-weave_hu1296b2fcbd700f451230e4cdd0880f6e_5437482_800x0_resize_q75_box.jpg 800w,
    /issues/1/weave-derridas-references/images/rya-knot-weave_hu1296b2fcbd700f451230e4cdd0880f6e_5437482_1200x0_resize_q75_box.jpg 1200w,
    /issues/1/weave-derridas-references/images/rya-knot-weave_hu1296b2fcbd700f451230e4cdd0880f6e_5437482_1500x0_resize_q75_box.jpg 1500w,
    /issues/1/weave-derridas-references/images/rya-knot-weave_hu1296b2fcbd700f451230e4cdd0880f6e_5437482_1800x0_resize_q75_box.jpg 1800w,
    /issues/1/weave-derridas-references/images/rya-knot-weave.jpg 3400w"
     class="landscape"><figcaption>
        <p>How to make a Rya knot in four steps.
        </p>
    </figcaption>
</figure>
<div class="txt-only" id="">
⩩&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;⟩
| FIGURE. Composite of four images showing various stages of weaving.
|
| CAPTION: How to make a Rya knot in four steps.
⩩&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;⟩
</div></p>
<p>Heddle position: neutral</p>
<p>Yarn size: 6/super bulky</p>
<p>Numbered list below corresponds to the numbers on the images. To create a Rya knot:</p>
<ol>
<li>Place strands of yarn over the warp yarns.</li>
<li>Bring the left side of your yarn behind and around two warp yarns.</li>
<li>Bring the right side of your yarn behind and around your other two warp yarns so that the ends meet up in the middle.</li>
<li>Pull the end pieces below the top knot area.</li>
</ol>
<p>Note: Before pulling ends down and tightening the top knot, make sure to match up both sides of the end pieces and then pull evenly, so that the knot ties with all ends at about the same length. Trimming is usually required for a more uniform fringe, but this helps not waste as much yarn. If starting with the rya knot (bottom up weaving), pull the end pieces below the top knot area. If you are ending with the rya knot (top down weaving) you would pull the end pieces above the top knot area.</p>
<p>Learned and adapted from: <a href="https://www.theweavingloom.com/weaving-techniques-rya-knots/">https://www.theweavingloom.com/weaving-techniques-rya-knots/</a></p>
<p>If you would like to try weaving the first chapter of Of Grammatology download the <a href="https://startwords.cdh.princeton.edu/issues/1/weave-references/Pattern-Guide-for-Weaving-Derridas-Margins.pdf">“Pattern Guide for Weaving Derrida’s Margins”</a> and follow the instructions.</p>
<section class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1" role="doc-endnote">
<p>A shuttle is a tool that is used to hold and pass the yarn through the warp. <a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:2" role="doc-endnote">
<p>A yarn is made up of several twisted strands of fiber, referred to as “plies” <a href="#fnref:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:3" role="doc-endnote">
<p>The word “weft” literally means that which is woven, and comes from an obsolete form of the word weave; the forms are similar to leave and left. “Weaving.” In Wikipedia, October 13, 2020. <a href="https://en.wikipedia.org/wiki/Weaving">https://en.wikipedia.org/wiki/Weaving</a>. &ldquo;weft, n.1&rdquo;. OED Online. September 2020. Oxford University Press. <a href="https://oed.com.princeton.edu/view/Entry/226851?rskey=95kJcl&amp;result=1">https://oed.com.princeton.edu/view/Entry/226851?rskey=95kJcl&amp;result=1</a> (accessed October 14, 2020). <a href="#fnref:3" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</section>
]]></content></entry><entry><title type="html">Weaving as interface</title><link href="https://startwords.cdh.princeton.edu/issues/1/weaving-as-interface/?utm_source=atom_feed" rel="alternate" type="text/html"/><id>https://startwords.cdh.princeton.edu/issues/1/weaving-as-interface/</id><author><name>Rebecca Sutton Koeser</name></author><author><name>Gissoo Doroudian</name></author><published>0001-01-01T00:00:00+00:00</published><updated>2020-10-23T16:32:45-04:00</updated><content type="html"><![CDATA[<html>
<head>
<title>deepzoom experiment</title>
<script src=https://cdn.jsdelivr.net/npm/openseadragon@2.4.2/build/openseadragon/openseadragon.min.js integrity="sha256-NMxPj6Qf1CWCzNQfKoFU8Jx18ToY4OWgnUO1cJWTWuw=" crossorigin="anonymous"></script>
<!--<link rel="stylesheet" href-"https://derridas-margins.princeton.edu/static/CACHE/css/output.fd22c024c95d.css" type="text/css"/> -->
<style>
    body {
        background-color: black;
    }

    .highlight {
        /*border: 3px solid yellow;*/
    }
    .highlight:hover {
        border: 3px solid yellow;
    }

    .pnum {
        text-decoration: none;
        color: white;
        font-size: 22pt;
    }
/*    .pnum::after {
        content: '1';
        font-size: 22pt;
        display: block;
        color: white;
    }
*/

    .reference {
        position: absolute;
        padding: 20px;
        left: 0;
        bottom: 0;
        width: 450px;
        height: 350px;
        background-color: white;
        z-index: 3;
        opacity: 0;

       -webkit-transition: opacity 1.5s ease-in-out;
       -moz-transition: opacity 1.5s ease-in-out;
       -ms-transition: opacity 1.5s ease-in-out;
       -o-transition: opacity 1.5s ease-in-out;
    }

    .reference.loading {
        opacity: 0.5;
    }

    .reference.show {
        opacity: 1;
    }

</style>
</head>
<body>
<div class="reference"></div>

<div class="deepzoom" id="openseadragon-2" style="height:90vh"></div>

<!-- page numbers to overlay -->
<!-- TODO: generate these and the overlays with code -->
<div class="pages">
    <span id="p1">1</span>
    <span id="p2">2</span>
    <span id="p3">3</span>
    <span id="p4">4</span>
    <span id="p5">5</span>
    <span id="p6">6</span>
</div>


<!-- needed to make this work

- resolve CORS issue with derrida's site references
- styles for reference cards within this site
- touch events (hide reference card)

- may need to adjust zoom / pan per device (mobile)

- mobile style for reference card overlay

-->


<script>

var viewer = OpenSeadragon({
    id:"openseadragon-2",
    prefixUrl:"https://cdn.jsdelivr.net/npm/openseadragon@2.4/build/openseadragon/images/",
    preserveViewport: true,
    visibilityRatio: 1,
    // disallow zoom in/out
    minZoomLevel: 5,
    maxZoomLevel: 5,
    defaultZoomLevel: 5,
    // disable vertical panning
    panVertical: false,
    showNavigationControl: false,

    tileSources:"https:\/\/iiif.princeton.edu\/loris\/iiif\/2\/figgy_prod%2F58%2F51%2Fd4%2F5851d48b225b42699a13181c778a6095%2Fintermediate_file.jp2\/info.json",
    overlays: [

        {
            // page1 label
            id: 'p1',
            px: 2600,
            py: 650,
            width: 50,
            height: 50,
            className: 'pnum'
        },

        {
            id: 'p2',
            px: 3793,
            py: 650,
            width: 50,
            height: 50,
            className: 'pnum'
        },
        {
            id: 'p3',
            px: 4840,
            py: 650,
            width: 50,
            height: 50,
            className: 'pnum'
        },
        {
            id: 'p4',
            px: 5862,
            py: 650,
            width: 50,
            height: 50,
            className: 'pnum'
        },
        {
            id: 'p5',
            px: 6210,
            py: 650,
            width: 50,
            height: 50,
            className: 'pnum'
        },
        {
            id: 'p6',
            px: 6570,
            py: 650,
            width: 50,
            height: 50,
            className: 'pnum'
        },

        {
            // epigram p15
            id: 'ref15a',
            px: 2560,
            py: 848,
            width: 352,
            height: 1776,
            className: 'highlight'
        },
        {
            // footnote 1 p16
            id: 'ref16a',
            px: 4359,
            py: 810,
            width: 141,
            height: 1794,
            className: 'highlight'
        },
        {
            // footnote 2 p16
            id: 'ref16b',
            px: 4500,
            py: 810,
            width: 141,
            height: 1794,
            className: 'highlight'
        },
        {
            // footnote 3 p16
            id: 'ref16c',
            px: 4642,
            py: 810,
            width: 141,
            height: 1794,
            className: 'highlight'
        },
    ],
})


viewer.addHandler("open", function () {
    console.log('opened');
    // start with left part of the weaving showing
    viewer.viewport.panTo(new OpenSeadragon.Point(0.17, 0.09), true)

    // equivalent event for touch?
    const referenceOverlays = document.querySelectorAll(".highlight");

    function showReference() {
        document.querySelector('.reference').classList.add('loading');

        console.log(this.getAttribute('id'));
        // var refID = references[this.getAttribute('id')];
        var refID = this.getAttribute('id').slice(3);
        var refUrl = '/references/de-la-grammatologie/' + refID + '/';
        // console.log(refUrl);
        console.log('https://derridas-margins.princeton.edu' + refUrl)
        // console.log('https://test-derrida.cdh.princeton.edu' + refUrl);
        // var xhr = new XMLHttpRequest();
        // xhr.onload = function() {
        //   console.log(this.responseXML.title);
        // }
        // xhr.open("GET", 'https://derridas-margins.princeton.edu' + refUrl);
        // xhr.responseType = "document";
        // xhr.send();

        fetch('https://derridas-margins.princeton.edu' + refUrl, {
        // fetch('https://test-derrida.cdh.princeton.edu' + refUrl, {
        // fetch('http://192.168.2.10:8000' + refUrl, {
            // headers: {
                // 'X-Requested-With': 'XMLHttpRequest',
            // }
        })
          // .then(response => console.log(response))
          .then(response => response.text())
          .then(function(text) {
            // console.log(data);
            // console.log(document.querySelector('.reference'));
            const ref = document.querySelector('.reference');
            console.log(text);
            ref.innerHTML = text;
            ref.classList.remove('loading');
            ref.classList.add('show');
          });
        }

    function hidereference() {
        const ref = document.querySelector('.reference');
        ref.innerHTML = '';
        ref.classList.remove('show');
    }

    for (const refOverlay of referenceOverlays) {
        refOverlay.addEventListener('touchstart', showReference)
        refOverlay.addEventListener('touchcancel', hidereference);

        refOverlay.addEventListener('mouseover', showReference)
        refOverlay.addEventListener('mouseout', hidereference);

    }

});

// viewer.addEventListener('open', function(event) {
    // console.log('binding hover listener for highlight');
// });

</script>
</body>
</html>]]></content></entry></feed>