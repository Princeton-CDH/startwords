<!doctype html><html lang=en><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=theme-color content="#3D206C"><meta http-equiv=x-ua-compatible content="IE=edge"><link rel=apple-touch-icon sizes=180x180 href=/img/favicon/apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=/img/favicon/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=/img/favicon/favicon-16x16.png><link rel=icon type=image/png sizes=384x384 href=/img/favicon/android-chrome-384x384.png><link rel=icon type=image/png sizes=192x192 href=/img/favicon/android-chrome-192x192.png><link rel=icon type=image/png sizes=150x150 href=/img/favicon/mstile-150x150.png><link rel="shortcut icon" href=/favicon.ico><link rel=manifest href=/site.webmanifest><link rel=mask-icon href=/img/favicon/safari-pinned-tab.svg color=#3d206c><link rel=schema.dc href=http://purl.org/DC/elements/1.0/><meta name=citation_public_url content="https://startwords.cdh.princeton.edu/issues/4/sonorous-medieval/"><meta name=citation_title content="Of Sonorous Medieval Chinese Texts and NLP Model Training
"><meta name=citation_date content="2023/10"><meta name=citation_author content="Budak, Nick"><meta name=citation_author_orcid content="https://orcid.org/https://orcid.org/0000-0002-4542-0899"><meta name=citation_author content="Rominger, Gian"><meta name=citation_author_orcid content="https://orcid.org/0000-0002-0952-2783"><meta name=citation_pdf_url content="https://zenodo.org/record/8408357/files/startwords-4-sonorous-medieval.pdf"><meta name=citation_doi content="10.5281/zenodo.8380841"><meta name=citation_abstract content="A distinctive set of challenges arises when training machines to process a historical language, especially one that was last spoken two millennia ago."><meta name=citation_journal_title content="Startwords"><meta name=citation_issn content="2694-2658"><meta name=citation_issue content="4"><meta name=citation_publisher content="Center for Digital Humanities, Princeton University"><meta name=DC.rights content="http://creativecommons.org/licenses/by/4.0/"><meta name=author content="Nick Budak, Gian Rominger"><meta name=generator content="Center for Digital Humanities, Princeton University"><meta name=dcterms.created content="2023-10"><link rel=preload as=font type=font/woff2 href=/fonts/IBM_Plex_Serif/ibm-plex-serif-v8-latin-regular.woff2 crossorigin><link rel=preload as=font type=font/woff2 href=/fonts/IBM_Plex_Serif/ibm-plex-serif-v8-latin-italic.woff2 crossorigin><link rel=preload as=font type=font/woff2 href=/fonts/IBM_Plex_Serif/ibm-plex-serif-v8-latin-regular.woff2 crossorigin><link rel=preload as=font type=font/woff2 href=/fonts/IBM_Plex_Serif/ibm-plex-serif-v8-latin-300.woff2 crossorigin><link rel=preload as=font type=font/woff2 href=/fonts/IBM_Plex_Serif/ibm-plex-serif-v8-latin-700.woff2 crossorigin><link rel=preload as=font type=font/woff2 href=/fonts/IBM_Plex_Serif/ibm-plex-serif-v8-latin-300italic.woff2 crossorigin><link rel=preload as=font type=font/woff2 href=/fonts/IBM_Plex_Serif/ibm-plex-serif-v8-latin-500italic.woff2 crossorigin><link rel=preload as=font type=font/woff2 href=/fonts/IBM_Plex_Serif/ibm-plex-serif-v8-latin-700italic.woff2 crossorigin><link rel=preload as=font type=font/woff2 href=/fonts/IBM_Plex_Serif/ibm-plex-serif-v8-latin-500.woff2 crossorigin><link rel=preload as=font type=font/woff2 href=/fonts/Source_Sans_Pro/source-sans-pro-v13-latin-regular.woff2 crossorigin><link rel=preload as=font type=font/woff2 href=/fonts/Source_Sans_Pro/source-sans-pro-v13-latin-900.woff2 crossorigin><link rel=preload as=font type=font/woff2 href=/fonts/Source_Sans_Pro/source-sans-pro-v13-latin-300.woff2 crossorigin><link rel=preconnect href=https://cdn.jsdelivr.net><title>Of Sonorous Medieval Chinese Texts and NLP Model Training</title><meta name=description content="Startwords Issue 4, October 2023. A research periodical irregularly published by the Center for Digital Humanities at Princeton. "><meta property="og:title" content="Of Sonorous Medieval Chinese Texts and NLP Model Training
"><meta property="og:description" content="A distinctive set of challenges arises when training machines to process a historical language, especially one that was last spoken two millennia ago."><meta property="og:type" content="article"><meta property="og:url" content="https://startwords.cdh.princeton.edu/issues/4/sonorous-medieval/"><meta property="og:image" content="https://startwords.cdh.princeton.edu/issues/4/sonorous-medieval/images/sonorous-medieval-social.png"><meta property="article:section" content="issues"><meta property="article:published_time" content="2023-10-02T00:00:00+00:00"><meta property="article:modified_time" content="2023-10-04T15:48:34-04:00"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://startwords.cdh.princeton.edu/issues/4/sonorous-medieval/images/sonorous-medieval-social.png"><meta name=twitter:title content="Of Sonorous Medieval Chinese Texts and NLP Model Training
"><meta name=twitter:description content="A distinctive set of challenges arises when training machines to process a historical language, especially one that was last spoken two millennia ago."><link rel=stylesheet href=/style.css><link rel=stylesheet href=/print.css media=print><link rel=preload href=/issues/4/sonorous-medieval/style.css as=style><link rel=stylesheet href=/issues/4/sonorous-medieval/style.css><script src=/js/polyfills.js></script><script defer src=/js/bundle.js></script>
<script async src="https://www.googletagmanager.com/gtag/js?id=G-0XGPQFYSR7"></script>
<script>var doNotTrack=!1;if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-0XGPQFYSR7",{anonymize_ip:!1,cookie_domain:"startwords.cdh.princeton.edu",cookie_flags:"SameSite=None;Secure"})}</script><script defer src=https://cdn.jsdelivr.net/npm/openseadragon@2.4.2/build/openseadragon/openseadragon.min.js integrity="sha256-NMxPj6Qf1CWCzNQfKoFU8Jx18ToY4OWgnUO1cJWTWuw=" crossorigin=anonymous></script>
<script defer type=text/javascript src=/issues/4/sonorous-medieval/audio.js></script>
<link rel=alternate type=text/plain href=/issues/4/sonorous-medieval/index.txt></head><body class=article><header><nav class=main aria-label=main><ul><li class=home><a href=/><img class=logo src=/img/logos/startwords.svg alt=Home width=15 height=33></a></li><li class=issues><a href=/issues/>Issues</a></li></ul></nav></header><main><article><div class=grid><header><p class=number><a href=/issues/4/>Issue 4</a></p><p class=theme>PALIMPSESTS</p><h1>Of Sonorous Medieval Chinese Texts and NLP Model Training</h1><p><ul class=authors><li><address>Nick Budak</address><a href=/authors/#BudakNick aria-label="author info" title="author info"><i class=ph-link-thin></i></a></li><li><address>Gian Rominger</address><a href=/authors/#RomingerGian aria-label="author info" title="author info"><i class=ph-link-thin></i></a></li></ul></p><p><time class=pubdate datetime=2023-10>October 2023</time></p><ul class=tags></ul><p><a href=http://doi.org/10.5281/zenodo.8380841 rel=alternate class=doi>10.5281/zenodo.8380841</a></p><p class=formats><a href=/issues/4/sonorous-medieval/index.txt rel=alternate type=text/plain>TXT</a>
<a href=https://zenodo.org/record/8408357/files/startwords-4-sonorous-medieval.pdf rel=alternate type=application/pdf>PDF</a></p></header><section class=print-only><a class=first-page-header href=/ aria-label=Startwords><img alt=Startwords src=/pdf-logotype.svg></a>
<a class=page-header href=/ aria-label=Startwords><img alt=Startwords src=/pdf-logo.svg></a>
<a href=http://doi.org/10.5281/zenodo.8380841 rel=alternate class=page-doi>doi:10.5281/zenodo.8380841</a></section><div class=text-container><p>A distinctive set of challenges arises when training machines to process a historical language, especially one that was last spoken two millennia ago. One of the core issues embedded in natural language processing (NLP) models for historical languages is the acute lack of annotated datasets, despite the long scholastic and exegetical traditions for some of these languages. This article focuses on a specific historical language with an extensive commentarial tradition: premodern forms of Chinese spanning the Warring States (476&ndash;221 BCE) and early imperial (221 BCE&ndash;220 CE) periods. By highlighting the challenges of this particular language and our approach to building an NLP model that aims to overcome these difficulties, we will argue how textual commentaries from the medieval period can be used for NLP model training purposes.</p><p>It may at first appear that the goal of an NLP model for historical languages consists in building the largest model and extracting the highest accuracy score from it. Conventional wisdom holds that larger is better when it comes to datasets, particularly for modern languages, in order to build a seemingly complete picture of the target language.<sup id=fnref:1><a href=#fn:1 class=footnote-ref role=doc-noteref>1</a></sup> It may be equally tempting to rely on the currently dominant focus in NLP by building contextual representations of meaning in the form of word embeddings. (This is nowhere more apparent than in the currently ubiquitous assertion that &ldquo;attention is all you need&rdquo; in the Transformer architecture.<sup id=fnref:2><a href=#fn:2 class=footnote-ref role=doc-noteref>2</a></sup>)</p><p>But when approaching a language like Old Chinese, the architecture and hyperparameters<sup id=fnref:3><a href=#fn:3 class=footnote-ref role=doc-noteref>3</a></sup> of the model itself are, at best, of secondary concern. In reality, the bulk of time and effort is devoted to questions of data curation and the painstaking labor necessary to identify and annotate the unique qualities of this language.<sup id=fnref:4><a href=#fn:4 class=footnote-ref role=doc-noteref>4</a></sup> As we will see, the question of meaning in context is far more complex than counting the collection of words surrounding the one we happen to be interested in, as the Transformer architecture would imply. Additional considerations include questions like: Who will curate the corpus of texts? How will this corpus be made machine readable? What portions will be used for the training and evaluation of the model?</p><p>In the project we introduce here<sup id=fnref:5><a href=#fn:5 class=footnote-ref role=doc-noteref>5</a></sup> &mdash; the result of a collaboration between a software engineer and a philologist &mdash; we generate an NLP model based on data derived from premodern Chinese annotations. In many ways, we have found that questions facing the twenty-first-century researcher equipped with large language models and Python libraries echo those of the sixth-century scholar using brush and ink.</p><h2 id=i>I.</h2><p>Let&rsquo;s begin by describing some of the distinctive features of Old Chinese, a language that survives in a corpus of ancient texts that can be dated to the centuries preceding and during the first dynasties of Imperial China, or roughly 476 BCE to 220 CE. These written texts survive either as documents that were transmitted and copied through the millennia, or as recently excavated or otherwise surfaced manuscripts.<sup id=fnref:6><a href=#fn:6 class=footnote-ref role=doc-noteref>6</a></sup></p><p><figure><div class="deepzoom shadow" id=openseadragon-0 style=height:50em aria-label="Interactive zoomable viewer showing four wooden tablets in clerical script."></div><script>window.addEventListener("DOMContentLoaded",function(){OpenSeadragon({id:"openseadragon-0",prefixUrl:"https://cdn.jsdelivr.net/npm/openseadragon@2.4/build/openseadragon/images/",preserveViewport:!0,visibilityRatio:1,minZoomLevel:1,defaultZoomLevel:1,gestureSettingsMouse:{scrollToZoom:!1},tileSources:"https://ids.si.edu/ids/iiif/FS-F1981.4a-e/info.json"})})</script><figcaption><p><strong>Figure 1.</strong> Four Wooden Tablets in clerical script, <a href=https://asia-archive.si.edu/object/F1981.4a-e/>Freer Gallery of Art</a> (accessed August 20, 2023).</p></figcaption></figure><figure class=deepzoom-preview><img src=https://ids.si.edu/ids/iiif/FS-F1981.4a-e/full/1500,/0/default.jpg alt="four wooden tablets in clerical script." loading=lazy><figcaption><p><strong>Figure 1.</strong> Four Wooden Tablets in clerical script, <a href=https://asia-archive.si.edu/object/F1981.4a-e/>Freer Gallery of Art</a> (accessed August 20, 2023).</p><p><small>The online version of this essay includes an interactive deep zoom viewer displaying a high resolution version of this image.</small></p></figcaption></figure><div class=txt-only>#&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;
| FIGURE. Interactive zoomable viewer showing four wooden tablets in clerical script.
|
| CAPTION: <strong>Figure 1.</strong> Four Wooden Tablets in clerical script.
| ATTRIBUTION: Freer Gallery of Art
| LINK: <a href=https://asia-archive.si.edu/object/F1981.4a-e/>https://asia-archive.si.edu/object/F1981.4a-e/</a>
#&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;</div></p><p>For heuristic purposes, we use the term &ldquo;Old Chinese&rdquo; for the underlying language, and like other stages of the Chinese language family, it is marked by the usage of Chinese characters or glyphs. As a writing system, Chinese glyphs have remained largely stable from the Han dynasty (202 BCE&ndash;220 CE) to the present day, with the greatest change occurring in 1956 in the form of the People&rsquo;s Republic of China&rsquo;s script reform and the introduction of simplified characters. A text from the early twentieth century may thus on the surface appear indistinguishable from a genuinely ancient piece of writing. This is in particular the case due to the venerated status of a few classical texts, largely from pre-imperial China, which served as models for later literary forms of writing up until the twentieth century. Existing NLP models for premodern Chinese assume a seemingly enduring and unchanging use of the written language, grouped under the notions of &ldquo;Literary&rdquo; or &ldquo;Classical Chinese&rdquo; (<em>wen yan</em> 文言 and <em>gudian Hanyu</em> 古典漢語).<sup id=fnref:7><a href=#fn:7 class=footnote-ref role=doc-noteref>7</a></sup> But this understanding of a never-changing and static language is not just ahistorical and incorrect; it also misses the point of what Chinese glyphs inherently represent: like other forms of writing, they are a conventionalized system used to represent the dynamic utterances of a language.</p><p>In this sense, <em>sound</em> is crucial to reading early Chinese texts, and the content of these texts is often inextricably linked to the topic of sound: the Chinese classics and texts of the genre of Masters literature (<em>zi shu</em> 子書) are astoundingly rich in puns, rhymes, and wordplay.<sup id=fnref:8><a href=#fn:8 class=footnote-ref role=doc-noteref>8</a></sup></p><p>Often, these texts present themselves as representing speech, and many of them may have had performative functions and poetic features that remain largely hidden, simply due to the fact that the Chinese writing system only poorly reflects its phonological features.<sup id=fnref:9><a href=#fn:9 class=footnote-ref role=doc-noteref>9</a></sup> The conceit of continuous access to written heritage is thus a mirage.</p><blockquote class="pull left">The sound system of the language underwent significant changes even as its graphemes remained static.</blockquote><p>So how can we access the sounds of a language that lost its last native speakers millennia ago? Chinese &mdash; like other languages &mdash; has changed over time. More specifically, the sound system of the language underwent significant changes even as its graphemes remained static. Old Chinese phonology is therefore a reconstructed system, derived from documentary evidence. In this context, heteronyms pose an issue also present in modern forms of Chinese: characters whose pronunciation and meaning change based on context, defying attempts to convert them directly into phonemes.<sup id=fnref:10><a href=#fn:10 class=footnote-ref role=doc-noteref>10</a></sup> One of the best-known examples of such a homograph is the glyph 樂, which can be read &mdash; depending on context &mdash; as either <em>lè</em> (&ldquo;joy&rdquo;) or <em>yuè</em> (&ldquo;music&rdquo;) in modern Standard Chinese, which can be reconstructed as *[rˤ]awk or *[ŋ]ˤrawk in Old Chinese.</p><div class=interlude id=fig2><table class=side-scroll><caption><b>Figure 2.</b> Heteronyms in ancient and modern languages.</caption><tbody><tr class=languages><td rowspan=2></td><th colspan=2>Old Chinese</th><th colspan=2>US English</th></tr><tr class=words><td colspan=2 lang=zh>樂</td><td colspan=2>excuse</td></tr><tr class=gloss><th scope=row>meaning</th><td>music</td><td>joy</td><td>to forgive</td><td>justification</td></tr><tr class=translit><th scope=row>sound</th><td>*[ŋ]ˤrawk</td><td>*[r]ˤawk</td><td>/ɪksˈkjuz/</td><td>/ɪksˈkjus/</td></tr></tbody></table></div><p>Another problem is the graphic variation common in early forms of Chinese, especially prior to the large-scale standardization of orthography during the third to first centuries BCE. In other words, while one glyph could be pronounced multiple ways, the <em>same</em> word could additionally be written with different glyphs in ancient texts. The same textual passage &mdash; say, a line of a poem &mdash; could hence be written with rather different glyphs.<sup id=fnref:11><a href=#fn:11 class=footnote-ref role=doc-noteref>11</a></sup> Thus without a model that incorporates homographs, graphic variation, and other contextual understandings of phonology, the (often quite complex) puns, rhymes, and wordplays of ancient texts remain hidden below their surface forms. More crucially, however, unstandardized recurrences &mdash; not just of named entities, but of entire parallel passages &mdash; may go unnoticed.<sup id=fnref:12><a href=#fn:12 class=footnote-ref role=doc-noteref>12</a></sup></p><div class=interlude id=fig3><p class=caption><b>Figure 3.</b> Textual parallels across three early Chinese texts,
both on a grapheme level and on that of phonology alone. The phrase
“he did not speak for three years” (solid underline) occurs across these
texts, using the same glyphs. Passages with wavy and dotted underlines
utilize different glyphs, but largely overlap on a phonological level.</p><p class=caption>For these examples, see David Schaberg, “Speaking of Documents:
<em>Shu</em> Citations in Warring States Texts,” in <cite>Origins of Chinese Political
Philosophy: Studies in the Composition and Thought of the ‘Shangshu’
(Classic of Documents)</cite>, ed. Martin Kern and Dirk Meyer (Leiden: Brill, 2017), 320–59.</p><blockquote><div class=source><p lang=zh>作其即位，乃或<span class=g2>亮陰</span>，<span class=par>三年不言</span>。其惟不言，言乃<span class=g1>雍</span>。</p></div><div class=notes><p class=translation>At the start, when he ascended the throne, then, it is said,
<span class=g2>the light was obscured</span> and
<span class=par>for three years he did not speak</span>. His
acting without words was thus <span class=g1>harmonious</span>.</p><footer>From the chapter “Do not Indulge” (<i>wu yi </i><span lang=zh>毋逸</span>), from the
<cite class=book>Book of Documents</cite> (<cite class=book>Shang shu</cite> <span lang=zh>尚書</span>)</footer></div></blockquote><blockquote><div class=source><p lang=zh>書云：高宗<span class=par>三年不言</span>，言乃<span class=g1>歡</span>。</p></div><div class=notes><p class=translation>The <cite class=book>Documents</cite> state: ‘Gaozong
<span class=par>did not speak for three years</span>. When he did
speak, he was <span class=g1>joyous</span>.’</p><footer>From the chapter “Tan Gong II” (<span lang=zh>檀弓下</span>), from the
<cite class=book>Book of Rites</cite> (<cite class=book>Li ji</cite> <span lang=zh>禮記</span>)</footer></div></blockquote><blockquote><div class=source><p lang=zh>高宗，天子也。即位<span class=g2>諒闇</span>，<span class=par>三年不言</span>。</p></div><div class=notes><p class=translation>Gaozong was Heaven’s Son. When he ascended the throne,
<span class=g2>it was truly dark</span>, and
<span class=par>for three years he did not speak</span>.</p><footer>From <cite class=book>Master Lü's Spring and Autumn Annals</cite> 6/2 (<cite class=book>Lü shi chunqiu</cite> <span lang=zh>呂氏春秋</span>)</footer></div></blockquote></div><p>Fortunately, previous scholarship has grappled with many of these issues, and historical secondary sources offer an intriguing source of semi-structured data in the form of commentaries, dictionaries, and other scholarly work. The <em>Qieyun</em> 切韻, a rhyme dictionary compiled in 601 CE, is an important example: it records normative reading practices that represent a compromise between then-current Northern and Southern styles of pronouncing of glyphs in the classical texts from early China. Modern reconstructions of Old Chinese phonology draw heavily on the <em>Qieyun</em> and its later redactions, as these texts provide a formal structure and closed system of phonological distinctions for the underlying Middle Chinese.</p><blockquote class="pull right">The often quite complex puns, rhymes, and wordplays of ancient texts remain hidden below their surface forms.</blockquote><p>The stability of the script also led to problems over time. In China, generations of medieval and early modern writers were trained to memorize the Odes of the ancient <em>Shi jing</em> 詩經 &mdash; called the <em>Classic of Poetry</em> for a good reason &mdash; but they soon grappled with the fact that these texts largely did not to rhyme when read aloud. The underlying phonology had changed.<sup id=fnref:13><a href=#fn:13 class=footnote-ref role=doc-noteref>13</a></sup></p><div class=interlude id=fig4><p class=caption><b>Figure 4.</b> Selected lines of the poem “Guan ju” <span lang=zh>《關雎》</span> from the
<cite class=book>Classic of Poetry</cite> (<cite class=book>Shi jing</cite> <span lang=zh>詩經</span>),
expressed through glyphs, Old Chinese and Middle Chinese phonology, and the pinyin romanization system of
Standard Mandarin Chinese. Rhyming words are underlined with their matching vowel sounds glowing; note in
particular the disappearing rhymes in selection 1 from Middle
Chinese to Modern Chinese, and in selection 2 from Old Chinese
to Middle Chinese.</p><table><caption>1. Guan-guan [goes] the osprey, on the river’s islet.<p class=sr-only>Rhyming “u” sounds at the end of the two four-character lines are preserved in Old Chinese and Middle Chinese, but in Modern Chinese the selection has no rhyming words.</p></caption><thead><tr><th scope=col aria-label=Character></th><th scope=col>Old Chinese</th><th scope=col>Middle Chinese</th><th scope=col>Modern Chinese</th></tr></thead><tbody><tr><td lang=zh>關</td><td>*k<sup>ʕ</sup>ro[n]</td><td>kwaen</td><td class=pinyin>guān</td></tr><tr><td lang=zh>關</td><td>*k<sup>ʕ</sup>ro[n]</td><td>kwaen</td><td class=pinyin>guān</td></tr><tr><td lang=zh>雎</td><td>*[tsh]a</td><td>tshjo</td><td class=pinyin>jū</td></tr><tr class=rhyme-line><td lang=zh>鳩</td><td class=rhyme>*[k](r)<span class=vowel>u</span></td><td class=rhyme>kj<span class=vowel>u</span>w</td><td class=pinyin>jiū</td></tr><tr><td lang=zh>在</td><td>*[dz]<sup>ʕ</sup>әʔ</td><td>dzojX</td><td class=pinyin>zài</td></tr><tr><td lang=zh>河</td><td>*[C.g]<sup>ʕ</sup>aj</td><td>ha</td><td class=pinyin>hé</td></tr><tr><td lang=zh>之</td><td>*tә</td><td>tsyi</td><td class=pinyin>zhī</td></tr><tr class=rhyme-line><td lang=zh>洲</td><td class=rhyme>*t<span class=vowel>u</span></td><td class=rhyme>tsy<span class=vowel>u</span>w</td><td class=pinyin>zhōu</td></tr></tbody></table><table><caption>2. Seeking her, [he] did not find [her]; Waking and sleeping, he thinks longingly [of her].<p class=sr-only>Rhyming “ə” sounds in the final two words of both lines appear in Old Chinese, but in both Middle Chinese and Modern Chinese the poem has no rhyming sounds.</p></caption><thead><tr><th scope=col aria-label=Character></th><th scope=col>Old Chinese</th><th scope=col>Middle Chinese</th><th scope=col>Modern Chinese</th></tr></thead><tbody><tr><td lang=zh>求</td><td>*g(r)u</td><td>gjuw</td><td class=pinyin>qiú</td></tr><tr><td lang=zh>之</td><td>*tә</td><td>tsyi</td><td class=pinyin>zhī</td></tr><tr class=rhyme-line><td lang=zh>不</td><td class=rhyme>*p<span class=vowel>ə</span></td><td>pjuw</td><td class=pinyin>bù</td></tr><tr class=rhyme-line><td lang=zh>得</td><td class=rhyme>*t<sup>ʕ</sup><span class=vowel>ә</span>k</td><td>tok</td><td class=pinyin>dé</td></tr><tr><td lang=zh>寤</td><td>*ŋ<sup>ʕ</sup>a-s</td><td>nguH</td><td class=pinyin>wù</td></tr><tr><td lang=zh>寐</td><td>*mi[t]-s</td><td>mjijH</td><td class=pinyin>mèi</td></tr><tr class=rhyme-line><td lang=zh>思</td><td class=rhyme>*[s]<span class=vowel>ə</span></td><td>si</td><td class=pinyin>sī</td></tr><tr class=rhyme-line><td lang=zh>服</td><td class=rhyme>*[b]<span class=vowel>ə</span>k</td><td>bjuwk</td><td class=pinyin>fú</td></tr></tbody></table></div><h2 id=ii>II.</h2><p>Instead of annotating early Chinese texts manually to disambiguate these problems in reading a given passage, we decided to rely entirely on traditional Chinese scholarship on the ancient classics as a data source. In order for such premodern scholarship to be fruitfully utilized as a data source for NLP training purposes, and for such scholarship to address the problem of disambiguating different readings, several criteria must be met. Initially, the source text must provide phonological data as explicitly as possible &mdash; after all, our aim is to assemble a language model that meaningfully reflects not just the glyphs used, but also their underlying sounds. Secondly, older scholarly sources are better; however, unlike Middle Chinese, which offers a convenient textual starting point in the form of the <em>Qieyun,</em> approaching Old Chinese inevitably includes Middle Chinese data, given the significantly closer temporal proximity of medieval scholars &mdash; like the <em>Qieyun</em>&rsquo;s compilator Lu Fayan 陸法言 (ca. 581&ndash;618) &mdash; to the ancient classics. Thirdly, data is needed on pronunciations given in realistic contexts in order to overcome the problems of homographs and graphic variation. That way, a future model of ours can use this contextual information to improve its accuracy.</p><p>One early work appears to fulfill all of these criteria: the <em>Jingdian Shiwen</em> 經典釋文, completed in 583 CE by the scholar Lu Deming 陸德明 (d. 630). This monumental commentary provides tens of thousands of phonological, semantic, and bibliographic notes across a representative selection of sixteen ancient classical texts. The material being annotated is broad, ranging from poetic odes (the <em>Shi jing</em>) and historical chronicles (the <em>Chunqiu</em> 春秋 and its commentaries) to an ancient dictionary (the <em>Erya</em> 爾雅). Lu Deming&rsquo;s analysis draws from some 230 sources, some of which are not attested in any other work.<sup id=fnref:14><a href=#fn:14 class=footnote-ref role=doc-noteref>14</a></sup></p><blockquote class="pull left">Lu Deming’s meticulous attention to detail produced what is effectively a machine-readable dataset millennia before such machines would exist.</blockquote><p>The <em>Jingdian Shiwen</em> wrestles with some of the same problems we face today, as its commentarial style disambiguates homographs and the inconsistencies presented by graphic variation in the texts it studies. While Lu Deming lived during a tumultuous period that spanned multiple imperial dynasties and spawned many competing schools of thought on how the classics should be read, his explanatory annotations eventually received official recognition and earned him posthumous fame and a commendation from emperor Taizong 太宗 (598&ndash;649) of the Tang dynasty 唐 (618&ndash;907 CE).<sup id=fnref:15><a href=#fn:15 class=footnote-ref role=doc-noteref>15</a></sup></p><p>The <em>Jingdian Shiwen</em> utilizes a relatively novel form of commentary: rather than reproducing the source text in full, it instead lists only what we call headwords, which are short excerpts, ranging from single glyphs to short passages. Each of these short sequences of glyphs is paired with a corresponding annotation. Each headword is distinctive enough to be matched to its location in the full text of the original source. The <em>Jingdian Shiwen</em> is thus a semi-structured text that provides sequences of glyphs that can be located in specific contexts in the source texts, and supplies annotations for a specific glyph in the relevant sequence.<sup id=fnref:16><a href=#fn:16 class=footnote-ref role=doc-noteref>16</a></sup> By essentially compressing the source texts in this way, the <em>Jingdian Shiwen</em> manages to cover almost 900,000 characters of primary-source material in just over 100,000 characters of excerpt. The resulting &ldquo;compression ratio&rdquo; is 13:1.<sup id=fnref:17><a href=#fn:17 class=footnote-ref role=doc-noteref>17</a></sup></p><p><figure><div class="deepzoom shadow" id=openseadragon-8 style=height:40em aria-label="Interactive zoomable viewer showing folio of vertical Chinese script with large characters and half-width notes in a smaller font size."></div><script>window.addEventListener("DOMContentLoaded",function(){OpenSeadragon({id:"openseadragon-8",prefixUrl:"https://cdn.jsdelivr.net/npm/openseadragon@2.4/build/openseadragon/images/",preserveViewport:!0,visibilityRatio:1,minZoomLevel:1,defaultZoomLevel:1,gestureSettingsMouse:{scrollToZoom:!1},tileSources:"https://ids.lib.harvard.edu/ids/iiif/16417478/info.json"})})</script><figcaption><p><strong>Figure 5.</strong> Folio from 1680 printing of the <em>Jingdian Shiwen</em>, with headwords rendered in large glyphs, and annotations immediately following in half-width running in two columns; from <a href=https://iiif.lib.harvard.edu/manifests/view/drs:16416657$80i>Harvard-Yenching Library, Harvard University</a> (accessed September 3, 2023)</p></figcaption></figure><figure class=deepzoom-preview><img src=https://ids.lib.harvard.edu/ids/iiif/16417478/full/1500,/0/default.jpg alt="Folio view of vertical Chinese script with large characters and half-width notes in a smaller font size" loading=lazy><figcaption><p><strong>Figure 5.</strong> Folio from 1680 printing of the <em>Jingdian Shiwen</em>, with headwords rendered in large glyphs, and annotations immediately following in half-width running in two columns; from <a href=https://iiif.lib.harvard.edu/manifests/view/drs:16416657$80i>Harvard-Yenching Library, Harvard University</a> (accessed September 3, 2023)</p><p><small>The online version of this essay includes an interactive deep zoom viewer displaying a high resolution version of this image.</small></p></figcaption></figure><div class=txt-only>#&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;
| FIGURE. Interactive zoomable viewer showing folio of vertical Chinese script with large characters and half-width notes in a smaller font size.
|
| CAPTION: <strong>Figure 5.</strong> Folio from 1680 printing of the <em>Jingdian Shiwen</em>, with headwords rendered in large glyphs, and annotations immediately following in half-width running in two columns.
| ATTRIBUTION: Harvard-Yenching Library, Harvard University
| LINK: <a href=https://iiif.lib.harvard.edu/manifests/view/drs:16416657$80i>https://iiif.lib.harvard.edu/manifests/view/drs:16416657$80i</a>
#&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;</div></p><p>While earlier dictionaries primarily glossed glyphs by providing similar-sounding glyphs to indicate their reading, the <em>Jingdian Shiwen</em> employed a rather novel way of indicating pronunciation: the <em>fanqie</em> 反切 system.<sup id=fnref:18><a href=#fn:18 class=footnote-ref role=doc-noteref>18</a></sup> This method of noting a glyph&rsquo;s phonology separates a syllable into its initial consonant on the one hand, and its rhyme and tone on the other. No longer constrained to providing pronunciations by finding a word that overlapped exactly in sound, the <em>fanqie</em> system allowed scholars such as Lu Deming to instead choose common graphs for the initial and rhyme plus tone independently. Given the reliance on the Chinese script, both initial and rhyme plus tone are expressed through a common glyph.</p><div class=interlude id=fig6><div><aside class=card><header>Say <em>east</em> in Middle Chinese</header><p class=large><audio src=assets/tuwng.mp3></audio>
<button class=play aria-label="listen to tuwng"></button>
<span class=tek lang=zh>東</span> tuwŋ</p><p class=large><span class=tek><span lang=zh>德</span> +</span> <span lang=zh>紅</span> = <span lang=zh>東</span></p><p class=phonetic><span class=tek><audio src=assets/tok.mp3></audio><button class=play aria-label="listen to tok"></button>
t<span class=fade>ok</span></span>
<audio src=assets/huwng.mp3></audio><button class=play aria-label="listen to huwng"></button>
<span class=fade>h</span>uwŋ</p></aside><aside class=card><header>Say <em>fight</em> in English</header><p class=large><audio src=assets/fight.mp3></audio>
<button class=play aria-label="listen to fight"></button>
<span class=fish>Fight</span> /fʌɪt/</p><p class=large><span class=fish>Fish +</span> light = fight</p><p class=phonetic><audio src=assets/fish.mp3></audio><button class=play aria-label="listen to fish"></button>
<span class=fish>/f<span class=fade>ɪʃ</span>/</span>
<audio src=assets/light.mp3></audio><button class=play aria-label="listen to light"></button>
/<span class=fade>l</span>ʌɪt/</span></p></aside><p class=caption><b>Figure 6.</b> How the <em>fanqie</em> pronunciation system works</p></div></div><p>In this way, the <em>Jingdian Shiwen</em> is both comprehensive and concise in the way it provides phonological data in context. We believe it provides enough data to train an NLP model. The key question is then how to extract this data; while Lu Deming&rsquo;s meticulous attention to detail produced what is effectively a machine-readable dataset millennia before such machines would exist, adjusting the specific format still necessitates significant labor on our part.</p><h2 id=iii>III.</h2><p>The first obstacle we face in turning the <em>Jingdian Shiwen</em> into phonological training data is the need for a digitized version of this text. Fortunately, the Kanseki Repository, an online database of premodern Chinese texts, offers digitized editions of over nine thousand works, including the <em>Jingdian Shiwen</em> and the source texts it annotates.<sup id=fnref:19><a href=#fn:19 class=footnote-ref role=doc-noteref>19</a></sup> This repository usually offers multiple editions for each work, in addition to interpretive versions that attempt to merge the editions into a state-of-the-art copy of the text. In keeping with the repository&rsquo;s permissive licensing and spirit of &ldquo;electronic texts by researchers, for researchers,&rdquo; our own work is available under an open license and published on GitHub.<sup id=fnref:20><a href=#fn:20 class=footnote-ref role=doc-noteref>20</a></sup></p><p>Only with such a digitized version of the <em>Jingdian Shiwen</em> and related texts can we approach the key question of how to extract useful phonological data from Lu Deming&rsquo;s commentary. A look at the content of this text highlights why this question is crucial: while close to one-third of the roughly 55,000 notes in the <em>Jingdian Shiwen</em> consist solely of a reading gloss (thus providing a reading aid to indicate pronunciation), the remainder is more complex and addresses multiple concerns. Some annotations feature semantic glosses, and others highlight instances in which additional works reproduce a glyph differently or include citations to the interpretations of other scholars. Many annotations combine these different elements. More importantly, the <em>Jingdian Shiwen</em> contains yet another form of abridgement: instead of reproducing the same annotation multiple times, the text attaches qualifiers to indicate that a given reading applies every time a human reader encounters the given string of glyphs in a specific section of the source text. These qualifiers act as multipliers for the data, effectively extending the commentary to cover whole swaths of text not explicitly noted elsewhere.</p><div class=interlude id=fig7><p class=caption><b>Figure 7.</b> An example showing the richness of annotations in the <cite class=book>Jingdian Shiwen</cite> <span lang=zh>經典釋文</span>, and the common patterns they take.</p><div class=text><div class="head segment"><div class=source><p lang=zh>相摩</p></div><div class=notes><div class=label>Headword</div></div></div><div class="graphic segment"><div class=source><p lang=zh>本又作磨</p></div><div class=notes><div class=translation>Edition[s] also write it [<span lang=zh>摩</span>] as “<span lang=zh>磨</span>”</div><div class=label>Graphic</div></div></div><div class="phon segment"><div class=source><p lang=zh>末何反</p></div><div class=notes><div class=translation>it is pronounced like <span lang=zh>末</span> + <span lang=zh>何</span> [ma]</div><div class=label>Phonological</div></div></div><div class="person segment"><div class=source><p lang=zh>京</p></div><div class=notes><div class=translation>Jing</div><div class=label>Person</div></div></div><div class="semantic segment"><div class=source><p lang=zh>云相磑切也</p></div><div class=notes><div class=translation>says that it means “milled against one another”</div><div class=label>Semantic</div></div></div><div class="phon segment"><div class=source><p lang=zh>磑音古代反</p></div><div class=notes><div class=translation>“mill” <span lang=zh>[磑]</span> is pronounced like <span lang=zh>古</span> + <span lang=zh>代</span> [gojH]</div><div class=label>Phonological</div></div></div><div class="person segment"><div class=source><p lang=zh>馬</p></div><div class=notes><div class=translation>Ma</div><div class=label>Person</div></div></div><div class="semantic segment"><div class=source><p lang=zh>云摩切也</p></div><div class=notes><div class=translation>says that it means “ground up”</div><div class=label>Semantic</div></div></div><div class="person segment"><div class=source><p lang=zh>鄭</p></div><div class=notes><div class=translation>Zheng[’s]</div><div class=label>Person</div></div></div><div class="work segment"><div class=source><p lang=zh>注禮記</p></div><div class=notes><div class=translation>commentary on the <cite class=book>Book of Rites</cite></div><div class=label>Work</div></div></div><div class="semantic segment"><div class=source><p lang=zh>云迫也</p></div><div class=notes><div class=translation>says that it means “compelled”</div><div class=label>Semantic</div></div></div><div class="phon segment"><div class=source><p lang=zh>迫音百</p></div><div class=notes><div class=translation>“compel” <span lang=zh>[迫]</span> is pronounced like <span lang=zh>百</span> [paek]</div><div class=label>Phonological</div></div></div></div></div><p>Our approach to handling these complexities is to train a special-purpose model equipped to parse the terse style of the <em>Jingdian Shiwen</em>&rsquo;s highly structured annotations. We use the Prodigy annotation tool to note parts of speech and syntactic relationships in the commentary, and pair it with the spaCy NLP library to create a custom processing pipeline.<sup id=fnref:21><a href=#fn:21 class=footnote-ref role=doc-noteref>21</a></sup> By applying this micro-model to the annotation corpus, each individual reading gloss can be extracted and paired with qualifying data. A notable side effect of this approach is that it simultaneously produces a citation network dataset: references that the <em>Jingdian Shiwen</em> makes to other texts and authors can be extracted from the text along with phonological data.</p><p>Once we have extracted all of the relevant phonological data, the task still remains to transform it into reconstructed forms of first Middle Chinese, and then Old Chinese. This is a process involving a few considerations: while the reading glosses of the <em>Jingdian Shiwen</em> &mdash; given directly and in <em>fanqie</em> form &mdash; reflect Middle Chinese, these glosses can also be used to make some inferences about the earlier Old Chinese. In order to strengthen these inferences, we use the reading glosses provided by the <em>Jingdian Shiwen</em> as disambiguation data and cross-reference these glosses with both contemporary rhyme dictionaries like the <em>Qieyun</em> and modern historical linguistic data (primarily William H. Baxter and Laurent Sagart&rsquo;s 2014 reconstruction of Old Chinese<sup id=fnref:22><a href=#fn:22 class=footnote-ref role=doc-noteref>22</a></sup>). The overall goal is to stay as true as possible to the source material: if the rhyming portion of a syllable can be determined, but its initial consonant is represented ambiguously in the <em>Jingdian Shiwen</em>, we attempt to capture that ambiguity in the data.</p><blockquote class="pull right">We borrow a strategy from the modern science of bioinformatics: specifically, genetic algorithms designed to find the best overall “alignment” of sequences of amino acids (or, in our case, sequences of glyphs).</blockquote><p>Finally, in order to create a fully machine-readable dataset, we reunite the annotations of the <em>Jingdian Shiwen</em> with the full text of the classical works that it annotates. Because of the <em>Jingdian Shiwen</em>&rsquo;s tendency to economize on space by attaching comments to excerpted headwords, identifying the precise locations in the text where the headwords occur is necessary to match the annotations to their original context. To do this, we borrow a strategy from the modern science of bioinformatics: specifically, genetic algorithms designed to find the best overall &ldquo;alignment&rdquo; of sequences of amino acids (or, in our case, sequences of glyphs).<sup id=fnref:23><a href=#fn:23 class=footnote-ref role=doc-noteref>23</a></sup> Once the headwords have been matched to their original positions in the source text, we copy over their corresponding phonological data to obtain a dataset of reading glosses in their historical context.</p><p>In using historical secondary sources for training an NLP model, we have found that even sources compiled millennia ago can still be considered by their very nature semi-structured data of the type needed to construct a model. The constrained, formulaic syntax of dictionaries and commentaries &mdash; an unnatural language designed to be quickly parsed by a human reader &mdash; lends itself equally well to parsing by relatively simple algorithms. For historical languages, secondary sources may even form a substantial part of the entire known body of the language, providing invaluable contemporary context to their literary counterparts.</p><p>Our project continues the practice of reading classical texts as data, but with a different aim than previous iterations of this practice: our goal is to produce a machine-learning algorithm. Some of the outlined steps that we have used to parse the <em>Jingdian Shiwen</em> are still works in progress, and additionally, some of the most difficult work remains to be approached. Constructing a statistical model that can represent all the complexities of current hypotheses regarding Old Chinese syllables will strain the limits of contemporary NLP platforms, most of which have no concept whatsoever of phonology. Our aim here is to persuade our peers that this task, and others like it in other languages, is not just possible but wholly worthwhile for researchers in the humanities. For this reason, we believe that further collaboration &mdash; with digital humanists, philologists, and others interested in expanding the debates around ancient texts to incorporate sound &mdash; is one of the most generative approaches to making use of NLP frameworks in the study of ancient texts.</p><h2 id=acknowledgments>Acknowledgments</h2><p>This work was made possible through our participation in the “<a href=https://newnlp.princeton.edu/>New Languages for NLP: Building Linguistic Diversity in the Digital Humanities</a>,” a National Endowment for Humanities Institute for Advanced Topics in the Digital Humanities. Our thanks to the organizers, Natalia Ermolaev and Andrew Janco, and to Toma Tasovac, Quinn Dombrowski, and David Lassner. We also thank Gissoo Doroudian and Rebecca Sutton Koeser for their design and implementation of the figures of this article, in a lively exchange with Nick Budak. Figure 4 was further based on the work of Jeffrey R. Tharsen, whose work more generally has inspired many of the thoughts in this article. Lastly, thank you to Grant Wythoff for his erudite editorial work.</p><div class=footnotes role=doc-endnotes><hr><ol><li id=fn:1><p>Compare, however, the danger of this tendency, as shown by Emily M. Bender et al., &ldquo;On the Dangers of Stochastic Parrots: Can Language Models Be Too Big? 🦜,&rdquo; <em>FAccT &lsquo;21: Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency</em> (New York: Association for Computing Machinery, 2021), 610&ndash;23, <a href=https://doi.org/10.1145/3442188.3445922>https://doi.org/10.1145/3442188.3445922</a>.&#160;<a href=#fnref:1 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:2><p>This phrase is referring to the idea that in order to get a sense of the meaning of a target word, one need only carefully to select from among its surrounding context words; it draws from the title of Ashish Vaswani et al., &ldquo;Attention Is All You Need,&rdquo; <em>NIPS'17: Proceedings of the 31st International Conference on Neural Information Processing Systems</em> (Red Hook: Curran Associates, 2017): 6000&ndash;10, <a href=https://papers.nips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf>https://papers.nips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf</a>.  &ldquo;Attention&rdquo; refers specifically to an algorithmic method of calculating the importance of context words relative to the target.&#160;<a href=#fnref:2 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:3><p>Because large language models are, in effect, collections of billions or even <em>trillions</em> of individual weights or parameters, this term is used to refer to the meta-values that are used to configure and train the model itself.&#160;<a href=#fnref:3 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:4><p>Compare, in this context, insights from Toma Tasovac et al., &ldquo;Humanistic NLP: Bridging the Gap Between Digital Humanities and Natural Language Processing&rdquo; (paper, Alliance of Digital Humanities Organizations Conference, Graz, Austria, July 13, 2023).&#160;<a href=#fnref:4 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:5><p>Nick Budak and Gian Duri Rominger, &ldquo;DIRECT: Digital Intertextual Resonances in Early Chinese Texts,&rdquo; GitHub, last modified August 17, 2023, <a href=https://github.com/direct-phonology>https://github.com/direct-phonology</a>.&#160;<a href=#fnref:5 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:6><p>Besides manuscripts stemming from archaeologically excavated sites, numerous looted manuscripts have surfaced in the last few decades. For issues regarding this trend, compare Paul R. Goldin, &ldquo;<em>Heng Xian</em> and the Problems of Studying Looted Artifacts,&rdquo; <em>Dao</em> 12 (2013): 153&ndash;60, <a href=https://doi.org/10.1007/s11712-013-9323-4>https://doi.org/10.1007/s11712-013-9323-4</a>; compare also Goldin&rsquo;s response to his critics in &ldquo;The Problem of Looted Artifacts in Chinese Studies: A Rejoinder to Critics,&rdquo; <em>Dao</em> 22 (2023): 145&ndash;51, <a href=https://doi.org/10.1007/s11712-022-09870-8>https://doi.org/10.1007/s11712-022-09870-8</a>.&#160;<a href=#fnref:6 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:7><p>Compare, for example, &ldquo;SuPar-Kanbun,&rdquo; a BERT model trained on Classical texts; see Koichi Yasuoka et al, &ldquo;Designing Universal Dependencies for Classical Chinese and Its Application.&rdquo; <em>Journal of Information Processing Society of Japan</em> 63, no. 2 (2022): 355&ndash;63, <a href=http://id.nii.ac.jp/1001/00216242/>http://id.nii.ac.jp/1001/00216242/</a>. In such models, the target language is often simply defined in opposition to modern Standard Chinese, and the training data consists of texts from across the millennia.&#160;<a href=#fnref:7 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:8><p>Pronunciation data, often rendered in the International Phonetic Alphabet, is at best noise and at worst misinformation for Transformer models; the significance of a newspaper headline like the <em>Washington Post</em>&rsquo;s description of Starbucks CEO Howard Schultz&rsquo;s 2020 campaign as being in &ldquo;a whole latte trouble&rdquo; would be completely lost. See Dana Milbank, &ldquo;Howard Schultz Brings a Whole Latte Trouble,&rdquo; <em>Washington Post</em>, January 30, 2019, <a href=https://www.washingtonpost.com/opinions/howard-schultz-brings-a-whole-latte-trouble/2019/01/30/6d45a1ee-24cb-11e9-ad53-824486280311_story.html>https://www.washingtonpost.com/opinions/howard-schultz-brings-a-whole-latte-trouble/2019/01/30/6d45a1ee-24cb-11e9-ad53-824486280311_story.html</a>. For an overview of the so-called Masters literature (<em>zi shu</em>) and issues within this genre, compare, for example, Wiebke Denecke, <em>The Dynamics of Masters Literature: Early Chinese Thought From Confucius to Han Feizi</em> (Cambridge, MA: Harvard University Press, 2010). For the importance of sound in texts, compare, for example, Wolfgang Behr, &ldquo;Three Sound-Correlated Text Structuring Devices in Pre-Qín Philosophical Prose,&rdquo; <em>Bochumer Jahrbuch zur Ostasienforschung</em> 29 (2005): 15&ndash;33, <a href=https://zora.uzh.ch/id/eprint/113766/>https://zora.uzh.ch/id/eprint/113766/</a>. For discussions of the transformative effects of sounds, music, and poetry, see Haun Saussy, <em>The Problem of a Chinese Aesthetic</em> (Stanford: Stanford University Press, 1993), 77&ndash;105; and Steven Van Zoeren, <em>Poetry and Personality. Reading, Exegesis, and Hermeneutics in Traditional China</em> (Stanford: Stanford University Press, 1991), 95&ndash;103. On the relationship between music and rulership in early China and its assumed cultivating effects, see especially Kenneth J. DeWoskin, <em>A Song for One or Two. Music and the Concept of Art in Early China</em> (Ann Arbor: University of Michigan, Center for Chinese Studies; Michigan Papers in Chinese Studies no. 42, 1982), 13&ndash;14, 85&ndash;98.&#160;<a href=#fnref:8 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:9><p>Compare, for example, Martin Kern, &ldquo;Creating a Book and Performing It: The &lsquo;Yao lüe&rsquo; Chapter of the <em>Huainanzi</em> as a Western Han <em>Fu</em>,&rdquo; in <em>The</em> Huainanzi <em>and Textual Production in Early China</em>, ed. Sarah A. Queen and Michael Puett (Leiden: Brill, 2014), 124&ndash;50.&#160;<a href=#fnref:9 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:10><p>See Frederick Liu, Han Lu, and Graham Neubig, &ldquo;Handling Homographs in Neural Machine Translation,&rdquo; in <em>Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies,</em> vol. 1 (New Orleans: Association for Computational Linguistics, 2018), 1336&ndash;45, <a href=https://aclanthology.org/N18-1121>https://aclanthology.org/N18-1121</a>.&#160;<a href=#fnref:10 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:11><p>Compare, for example, Martin Kern, &ldquo;The <em>Odes</em> in Excavated Manuscripts,&rdquo; in <em>Text and Ritual in Early China</em> (Seattle: University of Washington Press, 2005), 149&ndash;193, esp. 171. For broader overviews of the developments of Chinese writing in antiquity, compare Xigui Qiu, Gilbert Louis Mattos, and Jerry Norman, <em>Chinese Writing</em> (Berkeley: Society for the Study of Early China, 2000); William G. Boltz, <em>The Origin and the Development of the Chinese Writing System</em> (New Haven: American Oriental Society, 2003); and Imre Galambos, <em>Orthography of Early Chinese Writing: Evidence from Newly Excavated Manuscripts</em> (Budapest: Department of East Asian Studies, Eötvös Loránd University, 2006).&#160;<a href=#fnref:11 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:12><p>Compare David Schaberg, &ldquo;Speaking of Documents: <em>Shu</em> Citations in Warring States Texts,&rdquo; in <em>Origins of Chinese Political Philosophy</em>, ed. Martin Kern and Dirk Meyer (Leiden: Brill, 2017), 320&ndash;59. Compare also recent arguments regarding the applicability of the concept of <em>mouvance</em> to early Chinese textual phenomena; see Martin Kern, &ldquo;&lsquo;Xi Shuai&rsquo; 蟋蟀 (&lsquo;Cricket&rsquo;) and Its Consequences: Issues in Early Chinese Poetry and Textual Studies,&rdquo; <em>Early China</em> 42 (2019): 39&ndash;74, esp. 56&ndash;62, <a href=https://doi.org/10.1017/eac.2019.1>https://doi.org/10.1017/eac.2019.1</a>; compare also Dirk Meyer, <em>Documentation and Argument in Early China: The</em> Shangshu <em>(Venerated Documents) and the</em> Shu <em>Traditions</em> (Berlin: De Gruyter, 2021), 17&ndash;19.&#160;<a href=#fnref:12 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:13><p>For the underlying logic of representing early Chinese texts through visualizations of their phonological features, and for a fuller aural representation of the poem “Guan ju” upon which figure 4 is largely based, see Jeffrey R. Tharsen, “From Form to Sound 自形至聲: Visual and Aural Representations of Premodern Chinese Phonology and Phonorhetoric with Applications for Phonetic Scripts.” <em>International Journal of Digit Humanities</em> 4 (2023), 115–129, <a href=https://doi.org/10.1007/s42803-022-00053-8>https://doi.org/10.1007/s42803-022-00053-8</a>. Further note that the Ming dynasty scholar Chen Di 陳第 (1541–1617) used this problem of the Odes not rhyming to persuasively make the case that the Chinese language had undergone significant phonological change since ancient times; see William H. Baxter, <em>A Handbook of Old Chinese Phonology</em> (Berlin: Mouton De Gruyter, 1992), 154–55.&#160;<a href=#fnref:13 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:14><p>For more background on different premodern Chinese lexicons, compare Zev Handel, &ldquo;Early Lexicons,&rdquo; in <em>Literary Information in China: A History</em>, ed. Jack W. Chen et al., (New York: Columbia University Press, 2021), 53&ndash;64, esp. 60&ndash;61 for the <em>Qieyun</em> and sound-based lexicons; and also Victor H. Mair, &ldquo;<em>Tzu-shu</em> 字書 or <em>tzu-tien</em> 字典 [Dictionaries],&rdquo; in <em>The Indiana Companion to Traditional Chinese Literature</em>, ed. William H. Nienhauser, vol. 2 (Bloomington: Indiana University Press, 1998); for more on the <em>Jingdian Shiwen</em>, see David B. Honey, <em>Northern and Southern Dynasties, Sui, and Early Tang: The Decline of Factual Philology and the Rise of Speculative Hermeneutics</em>, vol. 3 of <em>A History of Classical Chinese Scholarship</em> (Washington: Academica Press, 2021), 215&ndash;20.&#160;<a href=#fnref:14 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:15><p>See David B. Honey&rsquo;s translation of Lu Deming&rsquo;s biography from the <em>New Tang History</em> (<em>Xin Tang shu</em> 新唐書) in <em>Decline of Factual Philology</em>, 216&ndash;19.&#160;<a href=#fnref:15 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:16><p>The use of the <em>Jingdian Shiwen</em> as a data source was pioneered by Jeffrey R. Tharsen and Hantao Wang, who categorized and segmented the <em>Jingdian Shiwen</em> systematically as a database; see Jeffrey R. Tharsen and Hantao Wang, “Digitizing the <em>Jingdian Shiwen</em>《經典釋文》: Deriving a Lexical Database from Ancient Glosses” (poster, Chicago Colloquium on Digital Humanities and Computer Science (DHCS), University of Chicago, USA, November 14, 2015. <a href=https://doi.org/10.6082/uchicago.8367>https://doi.org/10.6082/uchicago.8367</a>); see also Jeffrey R. Tharsen, “Understanding the Databases of Premodern China: Harnessing the Potential of Textual Corpora as Digital Data Sources” (paper, Digital Research in East Asian Studies: Corpora, Methods, and Challenges Conference, Leiden University, the Netherlands, July 12, 2016. <a href=https://doi.org/10.6082/uchicago.8368>https://doi.org/10.6082/uchicago.8368</a>). We were initially unaware of the work of Tharsen and Wang, and at first approached the <em>Jingdian Shiwen</em> purely from the needs of training a Natural Language Processing model. Our approach therefore utilizes a different labeling schema that was focused on the NLP model training, and a different digitized version of the source text. Nonetheless, we are grateful for Tharsen and Wang for generously sharing their data, which allowed us to compare their data and approach to ours. As part of our approach, we understand the <em>Jingdian Shiwen</em> as a dictionary, and we identify its semi-structured dictionary form also as the reason why an approach relying solely on the Transformer architecture would be misleading. Compare this to the ability of a human reader who speaks English to look up any word she may find in a source text in the <em>Oxford English Dictionary</em>. GPT-3 processes the same text differently, and the only way it learns from the dictionary as a text is in the same way it understands a sequential text like <em>Moby-Dick</em>.&#160;<a href=#fnref:16 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:17><p>For comparison, in terms of file size, the modern &ldquo;gzip&rdquo; algorithm compresses the entirety of the same corpus with a ratio of about 3:1.&#160;<a href=#fnref:17 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:18><p>This more abstract understanding of phonology may have reached Chinese scholars by way of Sanskrit and Indian linguistics, which had gained relevance with the increasing institutionalization of Chinese Buddhism in the sixth and seventh centuries; compare Mair, “<em>Tzu-shu</em> 字書,” 168.&#160;<a href=#fnref:18 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:19><p>&ldquo;About Kanseki Repository,&rdquo; Kanripo, last accessed August 21, 2023, <a href=https://www.kanripo.org/>https://www.kanripo.org/</a>.&#160;<a href=#fnref:19 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:20><p>Nick Budak and Gian Duri Rominger, &ldquo;DIRECT: Digital Intertextual Resonances in Early Chinese Texts,&rdquo; GitHub, last modified August 17, 2023, <a href=https://github.com/direct-phonology>https://github.com/direct-phonology</a>.&#160;<a href=#fnref:20 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:21><p>For the Prodigy annotation tool, see &ldquo;Prodigy 101 &mdash; Everything You Need to Know,&rdquo; Prodigy, accessed August 12, 2023, <a href=https://prodi.gy/docs>https://prodi.gy/docs</a>. For spaCy, see &ldquo;spaCy 101: Everything You Need to Know,&rdquo; spaCy, accessed August 21, 2023, <a href=https://spacy.io/usage/spacy-101>https://spacy.io/usage/spacy-101</a>.&#160;<a href=#fnref:21 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:22><p>For this reconstruction, see William H. Baxter and Laurent Sagart, <em>Old Chinese: A New Reconstruction</em> (Oxford: Oxford University Press, 2014), <a href=https://doi.org/10.1093/acprof:oso/9780199945375.001.0001>https://doi.org/10.1093/acprof:oso/9780199945375.001.0001</a>.&#160;<a href=#fnref:22 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:23><p>For an example of this technique as applied to finding quoted passages in Chinese text, compare Paul Vierthaler and Mees Gelein, &ldquo;A BLAST-Based, Language-Agnostic Text Reuse Algorithm with a MARKUS Implementation and Sequence Alignment Optimized for Large Chinese Corpora,&rdquo; <em>Journal of Cultural Analytics</em> 4, no. 2 (2019), <a href=https://doi.org/10.22148/16.034>https://doi.org/10.22148/16.034</a>; this inspired <a href=https://github.com/direct-phonology/dphon>our dphon tool</a>.&#160;<a href=#fnref:23 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li></ol></div></div></div></article></main><footer><nav aria-label="footer links"><ul><li><a class=highlight-focus href=/about/>About</a></li><li><a class=highlight-focus href=/authors/>Authors</a></li></ul></nav><div class=icons><a class="license highlight-focus" rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons Attribution 4.0 International License" src=/img/logos/license.svg width=38 height=20></a>
<a class=highlight-focus href=/ aria-label=Startwords><div class=logo id=startwords></div></a><a class=highlight-focus href=https://cdh.princeton.edu/ aria-label="The Center for Digital Humanities at Princeton"><div class=logo id=cdh></div></a></div></footer></body></html>