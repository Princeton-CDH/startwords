---
type: issue
layout: single
title: Número 3
number: 3
theme: Loros
date: 2022-08-01
slug: 3
num_features: 3
translators:
    - David Rivera
summary: "Para cuando la publicación de Emily Bender, Timmit Gebru, Angelina McMillan-Major y Margaret Mitchell “Sobre los peligros de los loros estocásticos: ¿pueden los modelos del lenguaje ser demasiado grandes?” fue publicada en marzo de 2021, ya había estado causando conmoción en el mundo de la inteligencia artificial desde hacía algún tiempo."
---

Para cuando la publicación de Emily Bender, Timmit Gebru, Angelina McMillan-Major y Margaret Mitchell "[Sobre los peligros de los loros estocásticos: ¿pueden los modelos del lenguaje ser demasiado grandes?](https://doi.org/10.1145/3442188.3445922)" fue publicada en marzo de 2021, ya había estado causando conmoción en el mundo de la inteligencia artificial desde hacía algún tiempo. Dos de sus autoras fueron [despedidas de Google](https://www.emergingtechbrew.com/stories/2021/03/29/one-biggest-advancements-ai-also-sparked-fierce-debate-heres) y la comunidad de procesamiento del lenguaje natural (PLN) estaba enfrentándose a las verdades incómodas que el artículo había puesto de manifiesto con respecto a los perjuicios causados por los algoritmos que, muchos sostenían, iban a transformar la vida moderna. Aquellos de nosotros que estábamos trabajando en las humanidades computacionales también tomamos nota de los loros de aquel artículo. Mientras que las tareas de investigación cotidiana de muchos humanistas pueden no implicar directamente grandes modelos de lengua (LMs en inglés), las preocupaciones suscitadas por las autoras --- acerca de los riesgos éticos, sociales y medioambientales de las tecnologías emergentes --- eran un terreno familiar. El artículo también nos ayudó a revisitar los principios humanistas que defendemos en nuestras aproximaciones a los textos, a la lengua y al significado, y a considerar qué es lo que sucede cuando estos factores intersecan otras herramientas que emergen de una cultura tecnológica obsesionada con perseguir lo más grande y rápido.

La historia del PLN en humanidades se remonta mucho más atrás de lo que la mayoría de las personas pensaría. Hubo un tiempo --- en los sesentas o setentas, durante los primeros años de la informática humanística y el apogeo de la lingüística Chomskiana --- cuando el PLN tenía un sentido más o menos claro para el académico promedio en humanidades. En gran parte esto era así porque el PLN estaba basado en normas. Los científicos informáticos y lingüistas construyeron complejos sistemas basados en reglas explícitas (y excepciones, por supuesto) que, por lo menos en teoría, incluirían todas las estructuras gramaticales y sintácticas de los lenguajes naturales. Estos sistemas podrían entonces ser utilizados en la traducción automática, el resumen de textos, las preguntas y respuestas, y otras tareas similares. El PLN basado en normas tenía un sentido intuitivo para los humanistas porque esta es la manera en la que muchos de nosotros aprendimos lenguas extranjeras (por lo menos aquellos pertenecientes a cierta generación que asistió al colegio antes de internet): aprendiendo y siguiendo ciertas reglas explícitas. En efecto, si se piensa en la gramática como un sistema de declinaciones y conjugaciones que solamente puede ser dominado por medio de la recitación grupal y la repetición intensa de ejercicios eso significa que ya se es bastante veterano.

Pero la aproximación dominante en el PLN por estos días no tiene nada que ver con normas explícitas: por el contrario, está basada en modelos estadísticos. El PLN estadístico infiere normas a partir de textos existentes y anotaciones al convertir las palabras en vectores dentro de un espacio multidimensional. Estos modelos impenetrables --- por lo menos para la mente humana --- son usados para realizar predicciones en la información nueva. Esto funciona bastante bien para ciertos tipos de tareas. Pero, al mismo tiempo, se siente un poco como magia.

En principio, la mayoría de los humanistas llega al análisis cuantitativo con una saludable dosis de escepticismo: estamos entrenados para reconocer que el contexto lo es todo, que el significado es siempre irreductiblemente complejo, que los textos con frecuencia son inherentemente contradictorios y que no existe algo así como un espacio libre de ideología. Así que no debe causar sorpresa el que los humanistas sean especialmente sensibles a los retos que imponen las dinámicas de poder, la disponibilidad de los datos y la especificidad de los campos, así como los sesgos estructurales y representacionales en modelos estadísticos del lenguaje, basados en amplios conjuntos de datos. Mientras presenciamos cómo los modelos estadísticos transforman no solamente la investigación basada en datos, sino la manera en la que la economía mundial funciona, el cuidado de nuestra salud es manejado y nosotros mismos somos vigilados, vemos a lo humano y a la experiencia humana ser apartados progresivamente hacia las márgenes.

Al mismo tiempo que la mayoría de nosotros asentíamos vigorosamente al leer el artículo sobre los loros, también sabíamos que una discusión sustancial más allá de las fronteras disciplinares de las humanidades y las ciencias de datos y computación puede sentirse como algo inalcanzable. ¿Cómo poder hablar los unos con los otros en esta época de intensa sobre especialización académica? ¿Cómo prevenimos el que nuestras disciplinas segregadas nos tornen en misántropos metodológicos, epistemológicos e ideológicos? ¿Existe un camino para combinar aproximaciones empíricas o positivistas del lenguaje con aquellas afincadas en el idealismo humanista?

Queríamos reunir perspectivas diversas para discutir "Sobre los peligros de los loros estocásticos" y considerar cómo la visión humanista puede ayudar a forjar un camino para mitigar los riesgos impuestos por tecnologías emergentes como los LMs grandes. Invitamos a tres destacadas figuras de las humanidades digitales --- Gimena del Rio Riande, Lauren Klein y Ted Underwood --- para compartir sus ideas, y le pedimos a dos de las coautoras del artículo original --- McMillan-Major y Mitchell --- asistir a [una mesa redonda en Zoom](https://cdh.princeton.edu/updates/join-us-for-a-roundtable-on-machine-predictions-and-synthetic-text/) a finales de octubre de 2021.

Los artículos de los tres humanistas forman parte de este número de *Starwords.* En "Mapeando los espacios latentes de cultura" Underwood reconoce los serios riesgos impuestos por LMs grandes, pero también nos pide adoptar una perspectiva amplia sobre cómo funciona el lenguaje, cómo los modelos producen significado y cómo las tecnologías disruptivas siempre han jugado un papel generativo en transformar prácticas culturales.

El texto de Del Rio Riande, "Sobre los loros que hablan español", examina el rol de la lengua al poner en primer plano otro complejo problema en el PLN: su falta de diversidad lingüística. Ella discute el proyecto BERTIN, que no solo produjo un gran modelo de lengua para el español, sino que, como un esfuerzo colaborativo y basado en la comunidad, ejemplificó una alternativa más ética a los modelos tecnopositivistas y centrados en recursos que son el foco de la atención de las autoras de los loros. (La aproximación de "pequeño lote" para crear datos anotados y modelos de entrenamiento para lenguas nuevas también ha sido la aproximación adoptada por el CDH en nuestro proyecto [Nuevas lenguas para NLP: construyendo diversidad lingüística en el Instituto de Humanidades Digitales](https://newnlp.princeton.edu/), patrocinado por NEH y realizado en colaboración con DARIAH-EU.)

Finalmente, en "¿Son los modelos de lengua nuestro caso límite?", Klein se pregunta de manera provocativa si todos nosotros --- en la industria, en la academia, o en nuestras vidas personales --- que continuamente nos hallamos intentando lidiar con estas configuraciones asimétricas de poder y recursos, deberíamos tal vez adoptar un rechazo radical y, por el contrario, trabajar en pro de cambiar nuestros sistemas.